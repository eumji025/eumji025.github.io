{"pages":[{"title":"404 Not Found：该页无法显示","date":"2018-01-01T08:52:14.476Z","updated":"2018-01-01T08:52:14.476Z","comments":false,"path":"/404.html","permalink":"http://www.eumji025.com//404.html","excerpt":"","text":""},{"title":"About","date":"2017-12-31T16:08:16.299Z","updated":"2017-09-16T11:09:26.071Z","comments":false,"path":"about/index.html","permalink":"http://www.eumji025.com/about/index.html","excerpt":"","text":"个人简介"},{"title":"Books","date":"2017-12-31T16:08:16.343Z","updated":"2017-09-16T11:09:26.074Z","comments":false,"path":"books/index.html","permalink":"http://www.eumji025.com/books/index.html","excerpt":"","text":""},{"title":"Categories","date":"2017-12-31T16:08:16.379Z","updated":"2017-09-16T11:09:26.077Z","comments":false,"path":"categories/index.html","permalink":"http://www.eumji025.com/categories/index.html","excerpt":"","text":""},{"title":"Links","date":"2018-02-03T11:09:29.448Z","updated":"2017-09-16T11:09:26.081Z","comments":true,"path":"links/index.html","permalink":"http://www.eumji025.com/links/index.html","excerpt":"","text":""},{"title":"Repository","date":"2017-12-31T16:08:16.107Z","updated":"2017-09-16T11:09:26.085Z","comments":false,"path":"repository/index.html","permalink":"http://www.eumji025.com/repository/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-12-31T16:08:16.163Z","updated":"2017-09-16T11:09:26.090Z","comments":false,"path":"tags/index.html","permalink":"http://www.eumji025.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"cors-second","slug":"cors-second","date":"2018-06-02T13:25:08.000Z","updated":"2018-06-17T15:27:37.352Z","comments":true,"path":"2018/06/02/cors-second/","link":"","permalink":"http://www.eumji025.com/2018/06/02/cors-second/","excerpt":"","text":"前言在上一篇我们分析了spring MVC中如何通过配置全局的CORS配置，使我们的浏览器支持跨域的访问。这一篇我们将介绍另外通过注解的方式实现CORS跨域访问，当然你也可以理解为本篇是个性化配置的一篇。这篇 主要是介绍@CrossOrigin的使用和原理解析。@CrossOrigin的作用方法非常类似@RequestMapping注解。所以@CrossOrigin注解主要作用于当前类和当前方法的一种配置方式。 @CrossOrigin示例下面我们使用@CrossOrigin注解演示一个案例 1234567891011@Controller@CrossOrigin(maxAge = 3600)public class DemoController &#123; @CrossOrigin(methods = &#123;RequestMethod.DELETE&#125;,origins = &#123;\"http://localhost:9090\"&#125;) @PostMapping(\"hello\") @ResponseBody public String objectValue(@RequestParam Map&lt;String,String&gt; values)&#123; System.out.println(values); return \"OK\"; &#125;&#125; 当我们使用postman模拟一个请求，然后就可以验证我们的配置是否生效。当然我们要在请求头上加上Origin参数，不然是不会生效的。上一篇应该也有说过。这里我们同时设置了类级别的CrossOrigin和方法级别的CrossOrigin。使用起来还是很简单的，其主要目的是让特定的方法有自己个性化的设置。 @CorssOrign解析首先都是作用于Controller的注解，那么猜想也觉得是和Handler绑定到一起的。而且之前我们也说过，只有当header中包含Orgin的时候才会进行CORS的处理。所以我们可以大概定位到其加载的位置还是在getHandler方法中。 123456789101112public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; Object handler = getHandlerInternal(request); ...省略 HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; 我们可以看到globalConfig对应的是全局，那么这里我猜想handlerConfig肯定是对应Controller上的注解。之前在介绍的时候并没有详细说明这一块的内容，主要还是为了在这里更加清晰的介绍。 CorssOrign的加载那么我们就看一下getCorsConfiguration方法的实现，其主要目的就是加载CorsConfi。 1234567891011121314protected CorsConfiguration getCorsConfiguration(Object handler, HttpServletRequest request) &#123; CorsConfiguration corsConfig = super.getCorsConfiguration(handler, request);//判断handler是否为CorsConfigurationSource对象 if (handler instanceof HandlerMethod) &#123;//判断Handler是否为HandlerMethod HandlerMethod handlerMethod = (HandlerMethod) handler; if (handlerMethod.equals(PREFLIGHT_AMBIGUOUS_MATCH)) &#123;//是否为EmptyHandler return AbstractHandlerMethodMapping.ALLOW_CORS_CONFIG; //允许所以 &#125; else &#123; CorsConfiguration corsConfigFromMethod = this.mappingRegistry.getCorsConfiguration(handlerMethod);//从mappingRegistry获取corsConfig corsConfig = (corsConfig != null ? corsConfig.combine(corsConfigFromMethod) : corsConfigFromMethod);//如果有组合，没有就使用corsConfigFromMethod &#125; &#125; return corsConfig;&#125; 这里主要做的事情就是合并已有的corsConfig和这个方法对应的corsConfig。可以认为cors是可以铁架的。mappingRegistry.getCorsConfiguration方法主要目的就是获取当前方法拥有的CORSConfig。 1234public CorsConfiguration getCorsConfiguration(HandlerMethod handlerMethod) &#123; HandlerMethod original = handlerMethod.getResolvedFromHandlerMethod(); return this.corsLookup.get(original != null ? original : handlerMethod);&#125; 这里的corsLookup是个map。通过HandlerMethod看能否匹配合适的CorsConfig。到这里又回到了同一个问题，那就是corsLookup是怎么注册的，requestMapping其实也是同样的道理，到底是怎么以方法为单位进行注册的。 CorssOrign的初始化通过Debug CorsConfig的put方法我们发现，其实corsLookup的注册是通过RequestMappingHandlerMapping的afterPropertiesSet方法实现的。我们都知道afterPropertiesSet是InitializingBean接口定义的方法。而我们也应该知道一个类实现了InitializingBean接口后，在初始化这个bean的时候就会调用这个类的afterPropertiesSet方法。那我们看看afterPropertiesSet方法到底做了什么事情。 123456789101112@Overridepublic void afterPropertiesSet() &#123; this.config = new RequestMappingInfo.BuilderConfiguration(); this.config.setUrlPathHelper(getUrlPathHelper()); //url处理 this.config.setPathMatcher(getPathMatcher()); //地址转换 this.config.setSuffixPatternMatch(this.useSuffixPatternMatch);//使用后缀匹配模式 this.config.setTrailingSlashMatch(this.useTrailingSlashMatch);//后缀/匹配模式 this.config.setRegisteredSuffixPatternMatch(this.useRegisteredSuffixPatternMatch); this.config.setContentNegotiationManager(getContentNegotiationManager());//处理内容的 super.afterPropertiesSet();&#125; 这里主要是为BuilderConfiguration准备一些默认的相关参数，主要是用来处理我们的请求和参数匹配等，处理逻辑还要看父类的afterPropertiesSet方法 12345678910111213141516171819public void afterPropertiesSet() &#123; initHandlerMethods();&#125;protected void initHandlerMethods() &#123; String[] beanNames = (this.detectHandlerMethodsInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(getApplicationContext(), Object.class) : getApplicationContext().getBeanNamesForType(Object.class));//感觉是获取了所有的bean for (String beanName : beanNames) &#123;//遍历 if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; Class&lt;?&gt; beanType = null; beanType = getApplicationContext().getType(beanName); if (beanType != null &amp;&amp; isHandler(beanType)) &#123; detectHandlerMethods(beanName);//进行具体的处理 &#125; &#125; &#125; handlerMethodsInitialized(getHandlerMethods()); //初始化&#125; 其实这个方法还是包装方法，目的是为了获取注册的bean，然后遍历每一个bean进行检测和处理，如果对spring bean机制熟悉的话应该一看就明白了。然后筛选是Controller的Bean。其实就看是否包含Controller或者RequestMapping注解。如果是合适的bean，就进行具体的处理。最后han的方法dlerMethodsInitialized默认是为空的，什么事都没做。 接下来看看detectHandlerMethods是怎么解析Controller的bean的。 123456789101112131415161718protected void detectHandlerMethods(final Object handler) &#123; Class&lt;?&gt; handlerType = (handler instanceof String ? getApplicationContext().getType((String) handler) : handler.getClass()); final Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType);//获取真是的class，因为有可能是代理对象 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, new MethodIntrospector.MetadataLookup&lt;T&gt;() &#123; @Override public T inspect(Method method) &#123; return getMappingForMethod(method, userType); //这里其实是回调方法，进行过滤 &#125;fangfa &#125;);//筛选满足条件的 for (Map.Entry&lt;Method, T&gt; entry : methods.entrySet()) &#123;//遍历每一个满足条件的方法 Method invocableMethod = AopUtils.selectInvocableMethod(entry.getKey(), userType); T mapping = entry.getValue(); registerHandlerMethod(handler, invocableMethod, mapping); &#125; &#125; 上述方法做的事情还是很明确的，首先通过bean找到真实的class，然后筛选出所有符合条件的方法。当然这里的符合条件还需要我们看下文的分析才知道。然后注册每一个方法。 第一步我们看一下筛选方法getMappingForMethod的逻辑 12345678910protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123; RequestMappingInfo info = createRequestMappingInfo(method);//获取RequestMappingInfo if (info != null) &#123; RequestMappingInfo typeInfo = createRequestMappingInfo(handlerType);//再取一次，我还没太明白什么情况会产生这样的操作 if (typeInfo != null) &#123; info = typeInfo.combine(info); //组合 &#125; &#125; return info;&#125; 这里就是根据获取到的RequestMappingInfo进行组合。组合就是把属性否加起来没什么好看的，应该要知道有那些属性才比较重要。如果没找到就返回空，不过为什么取两次，暂时我还没想明白。 RequestMappingInfo构建接下来我们需要看createRequestMappingInfo方法里做了什么。怎么取RequestMappingInfo很关键。 123456private RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123; RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class); RequestCondition&lt;?&gt; condition = (element instanceof Class ? getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element)); return (requestMapping != null ? createRequestMappingInfo(requestMapping, condition) : null);&#125; 神秘面纱被解开。这里主要就是通过方法上的RequestMapping注解，如果存在则继续构建createRequestMappingInfo，getCustomMethodCondition和getCustomMethodCondition都是返回null，如果包含requestMapping注解则调用createRequestMappingInfo方法，否则直接返回null。 123456789101112131415protected RequestMappingInfo createRequestMappingInfo( RequestMapping requestMapping, RequestCondition&lt;?&gt; customCondition) &#123; return RequestMappingInfo .paths(resolveEmbeddedValuesInPatterns(requestMapping.path())) .methods(requestMapping.method()) .params(requestMapping.params()) .headers(requestMapping.headers()) .consumes(requestMapping.consumes()) .produces(requestMapping.produces()) .mappingName(requestMapping.name()) .customCondition(customCondition) .options(this.config) .build();&#125; createRequestMappingInfo方法无非就是把RequestMapping注解里面设置的内容通过builer模式放在RequestMappingInfo中。我们误打误撞的就把RequestMapping怎么被加载的逻辑给找到了。 我们这时候就要回到我们之前的遍历满足条件的方法detectHandlerMethods看后续的逻辑。 123protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method);&#125; 是不是有种熟悉的感觉，我们在之前就从mappingRegistry获取过Handler。继续看register方法的内容 1234567891011121314151617181920212223242526272829public void register(T mapping, Object handler, Method method) &#123; this.readWriteLock.writeLock().lock();//获取写锁 try &#123; HandlerMethod handlerMethod = createHandlerMethod(handler, method);//构造HandlerMethod assertUniqueMethodMapping(handlerMethod, mapping);//确保唯一 this.mappingLookup.put(mapping, handlerMethod); List&lt;String&gt; directUrls = getDirectUrls(mapping);//获取对应的url for (String url : directUrls) &#123; this.urlLookup.add(url, mapping); &#125; String name = null; if (getNamingStrategy() != null) &#123;//这个适配暂时还没懂 name = getNamingStrategy().getName(handlerMethod, mapping); addMappingName(name, handlerMethod); &#125; CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping);//加载Cors if (corsConfig != null) &#123; this.corsLookup.put(handlerMethod, corsConfig); &#125; this.registry.put(mapping, new MappingRegistration&lt;T&gt;(mapping, handlerMethod, directUrls, name)); &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125;&#125; 可以看到上面的方法注册了几样东西1.构造HandlerMethod2.注册url到urlLookup相当于做个默认的映射3.通过策略添加合适的名称映射？4.解析方法对应的CorsConfiguration，并注册 到这里又看到了加载CORS的方法，所以直接看下initCorsConfiguration方法的实现，需要看实现类 1234567891011121314151617181920protected CorsConfiguration initCorsConfiguration(Object handler, Method method, RequestMappingInfo mappingInfo) &#123; HandlerMethod handlerMethod = createHandlerMethod(handler, method);//有创建了一次 CrossOrigin typeAnnotation = AnnotatedElementUtils.findMergedAnnotation(handlerMethod.getBeanType(), CrossOrigin.class);//类注解 CrossOrigin methodAnnotation = AnnotatedElementUtils.findMergedAnnotation(method, CrossOrigin.class);//方法上的注解 if (typeAnnotation == null &amp;&amp; methodAnnotation == null) &#123; return null; &#125; CorsConfiguration config = new CorsConfiguration(); updateCorsConfig(config, typeAnnotation);//将配置的信息放到config中 updateCorsConfig(config, methodAnnotation); if (CollectionUtils.isEmpty(config.getAllowedMethods())) &#123;//没过没有配置允许的方法，则全部 for (RequestMethod allowedMethod : mappingInfo.getMethodsCondition().getMethods()) &#123; config.addAllowedMethod(allowedMethod.name()); &#125; &#125; return config.applyPermitDefaultValues();&#125; 到这里我们终于知道了CrossOrigin的加载，同时会加载类和方法上的CrossOrigin注解。然后就是将注解的内容组合起来，具体细节无非就是遍历注解中的每一个元素进行设值。如果没有设置就取默认值。 看到这里我们也终于见到了cors配置加载的庐山真面目。配置和HandlerMethod绑定。 小结到这里我么也讲完了CrossOrign使用注解方式的加载，同时我们还知道了HandlerMapping的加载过程。spring中，对这些配置大多都是以组合的方式进行处理。然后回到之前的加载配置也是，如果存在多种Cros配置的时候就会组合在一起使用。 CORS使用使用和之前的逻辑都是一模一样的，就不继续在看了。 待续从本文中接触到了RequestMappingHandlerMaping的部分内容，也了解到了RequestMapping的是如何被加载的。当然这还只是冰山一角，后续还要对HandlerMaping做更深入的分析。 结语到此CROS的在Spring MVC中的加载和使用基本也算告一段落了，通过本文我们了解了如何使用CROS以及他的几种实现方式。另外我们也跟着源代码追踪了CORS在spring中具体是怎么被加载以及如何被使用的。另外通过本文，当然不仅仅只是看到CORS的实现，我们也应该去思考整个关于HandlerMapp或者整个spring mvc几大组件的实现原理。当然本人的实力有限，很多地方并没有很详细的介绍。欢迎交流和反馈 与君共勉！！！","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"CORS","slug":"CORS","permalink":"http://www.eumji025.com/tags/CORS/"}]},{"title":"CORS在spring mvc中的使用","slug":"cors-init","date":"2018-05-28T04:45:00.000Z","updated":"2018-06-17T15:26:08.236Z","comments":true,"path":"2018/05/28/cors-init/","link":"","permalink":"http://www.eumji025.com/2018/05/28/cors-init/","excerpt":"","text":"前言在上一篇我们简单的分析了Spring MVC的DispatcherServlet一次请求所做的事情。并分析了很多相关的组件和处理过程。不过也留下了很多的疑点。本篇主要是在上篇的基础上分析CORS的作用和原理。 什么是CORSCORS全称Cross-Origin Resource Sharing，表示跨源资源共享。表示一种允许当前域的资源被其他域直接访问。通俗的例子就是localhost：8081使用httpclient调用localhost：8082. 两个是在不同的web服务下。此时就存在跨域域进行访问的情况。我想在很久以前，那时候由于同域安全策略（the same-origin security policy）浏览器会禁止这种跨域请求。那是还是用iframe进行这种跨域的访问方式。 不过由于CORS的规范出台，使得我们不必正再使用jsoup或者iframe等不优雅的方式实现跨域。而是通过服务器和客户端的协调和配合就可以进行跨域配合。 具体有关CORS相关的内容参考这篇文章https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS 怎么使用本文将结合一个spring boot的demo进行演示，其主要目的是为了进行我们spring CORS的原理探究。 123456789101112131415@Configuration@EnableWebMvcpublic class CORSWebConfig extends WebMvcConfigurerAdapter &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping(\"/*\") .allowedOrigins(\"http://localhost:8888\") .allowedMethods(\"PUT\", \"DELETE\") .allowedHeaders(\"header1\", \"header2\", \"header3\") .exposedHeaders(\"header1\", \"header2\") .allowCredentials(true).maxAge(3600); &#125;&#125; 全局CORS配置原理首先我们就使用上面的CORSWebConfig拦截所有的请求，并且允许的域为http://localhost:8888，允许的方法类型是put类型等请求拦截信息。 然后我们在编写一个测试的Controller方法 123456@PostMapping(\"object\")@ResponseBodypublic String objectValue(@RequestParam Map&lt;String,String&gt; values)&#123; System.out.println(values); return \"OK\";&#125; 然后我们使用postman工具模拟一个header【Origin:localhost8080】，然后在发一些参数。调用之后会出现如下的结果： 1Invalid CORS request 因为我们测试的条件和cors配置的不符合，可见我们这个不满足要求的方法被拦截下来了。如果我们想正确的让方法被执行需要使用正确的Origin还有method。那么这个方法将正确的被 如果我们想正确的让方法被执行需要使用正确的Origin 放行。 到这里我们已经简单的介绍了如何使用一个CORS配置。但是目前比较大的问题就是这配置是如何被加载和生效的。 CORS加载注册WebMvcConfigurer首先我们需要看一下配置上的注解EnableWebMvc 123@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;&#125; 这个注解引入了DelegatingWebMvcConfiguration这个配置类。 1234567@Autowired(required = false)public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); &#125;&#125; 在这个类的开头我们很容易就发现了这么一个自动装配的方法。WebMvcConfigurer好像似曾相识，没错这个类就是WebMvcConfigurerAdapter的父接口，也就是我们CORSWebConfig的父接口。 这里就是将我们声明的WebMvcConfigurer记录到configurers中。 引入WebMvcConfigurer上面我们已经将WebMvcConfigurer顺利的记录到configurers中去了。那么接下来我们要去找在哪里这个WebMvcConfigurer被使用。这里其实是在声明requestMappingHandlerMapping时候被调用。 12345678910@Beanpublic RequestMappingHandlerMapping requestMappingHandlerMapping() &#123; RequestMappingHandlerMapping handlerMapping = createRequestMappingHandlerMapping(); handlerMapping.setOrder(0); handlerMapping.setInterceptors(getInterceptors()); handlerMapping.setContentNegotiationManager(mvcContentNegotiationManager()); handlerMapping.setCorsConfigurations(getCorsConfigurations());//这里 ... return handlerMapping;&#125; 我们重点放在getCorsConfigurations方法。 12345678protected final Map&lt;String, CorsConfiguration&gt; getCorsConfigurations() &#123; if (this.corsConfigurations == null) &#123;//默认是为空 CorsRegistry registry = new CorsRegistry(); addCorsMappings(registry);//给CORSRegisty添加Mapping this.corsConfigurations = registry.getCorsConfigurations();//构建一个corsConfiguration &#125; return this.corsConfigurations;&#125; 这里主要是构建一个corsConfiguration，然后附属条件构造CorsRegistry对象以及加载配置到CorsRegistry中。 123protected void addCorsMappings(CorsRegistry registry) &#123; this.configurers.addCorsMappings(registry);&#125; 这里就是我们之前上面声明configurers对象配置类的方法。然后调用addCorsMappings追加Mapping 12345public void addCorsMappings(CorsRegistry registry) &#123; for (WebMvcConfigurer delegate : this.delegates) &#123; delegate.addCorsMappings(registry); &#125;&#125; 然后就是遍历每一个WebMvcConfigurer，将其配置加载到CorsRegistry中。就是我们之前自定义类中重写的addCorsMappings方法。 可以看出整个方法主要目的就是把自定义配置的所有WebMvcConfigurer都添加到CorsRegistry中。然后我们在上面this.corsConfigurations = registry.getCorsConfigurations()就是拿出我们所有的配置。 然后同时我们也知道了RequestMappingHandlerMapping是存有corsConfigurations这个对象的。 使用corsConfigurations上节我们在分析spring MVC整体流程时候，当时也遇到了校验CORS信息的地方，只是当时没 有重点介绍，这里我们再次回到这里AbstractHandlerMapping类中获取Handler的方法。 1234567891011public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; Object handler = getHandlerInternal(request); HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123;//CORS处理 CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request);//通过路径匹配拿到CorsConfiguration CorsConfiguration handlerConfig = getCorsConfiguration(handler, request);//request已经配置了私有的CorsConfiguration CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig);//默认使用全局的配置 executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain; &#125; 首先判断当前请求是否为一个CorsRequest。就是判断请求的header中是否包含Origin。通过 请求的路径去找到匹配的CorsConfiguration。然后选择合适的包装executioChain。到这里我们算是明白了之前为什么知道是requestMappingHandlerMapping方法引入了webMvcConfigurer。 接着我们看getCorsHandlerExecutionChain方法的实现。 123456789101112protected HandlerExecutionChain getCorsHandlerExecutionChain(HttpServletRequest request, HandlerExecutionChain chain, CorsConfiguration config) &#123; if (CorsUtils.isPreFlightRequest(request)) &#123;//判断是否为PreFlightRequest HandlerInterceptor[] interceptors = chain.getInterceptors(); chain = new HandlerExecutionChain(new PreFlightHandler(config), interceptors); &#125; else &#123; chain.addInterceptor(new CorsInterceptor(config)); &#125; return chain;&#125; 首先判断是否为PreFlightRequest，即是否为OPTIONS类型的方法，相当于前置通信方法。 如果是的话就需要再包装成HandlerExecutionChain，并将拦截器设置进去。 如果不是的话，就需要往chain中加入一个新的插件CorsInterceptor。 到这里我们明白了，在获取Handler的时候会将cors引入，并且是通过插件的形式。 ###CorsInterceptor拦截 前面我们已经通过加载Handler的时候加载了CORS的配置信息，并把他们包装在CorsInterceptor中。 然后那我们必然可以猜测在preHandle中会进行CORS的校验。 1234public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return corsProcessor.processRequest(this.config, request, response);&#125; 这里的CORSProcess是DefaultCorsProcessor对象。 然后通过DefaultCorsProcessor的processRequest进行处理 1234567891011121314151617181920public boolean processRequest(CorsConfiguration config, HttpServletRequest request, HttpServletResponse response) throws IOException &#123; if (!CorsUtils.isCorsRequest(request)) &#123; return true; &#125; ... boolean preFlightRequest = CorsUtils.isPreFlightRequest(request); if (config == null) &#123; if (preFlightRequest) &#123; rejectRequest(serverResponse); return false; &#125; else &#123; return true; &#125; &#125; return handleInternal(serverRequest, serverResponse, config, preFlightRequest); &#125; 这里只是个前置方法，主要校验请求是否为CorsRequest，PreFlightRequest等请求。如果没有满足那些条件 调用handleInternal方法进行最后的判断 1234567891011121314151617181920212223242526272829303132333435363738394041424344protected boolean handleInternal(ServerHttpRequest request, ServerHttpResponse response, CorsConfiguration config, boolean preFlightRequest) throws IOException &#123; String requestOrigin = request.getHeaders().getOrigin();//获取Origin String allowOrigin = checkOrigin(config, requestOrigin);//获取匹配的Origin名 HttpMethod requestMethod = getMethodToUse(request, preFlightRequest);//获取htpp方法 List&lt;HttpMethod&gt; allowMethods = checkMethods(config, requestMethod);//获取匹配的方法 List&lt;String&gt; requestHeaders = getHeadersToUse(request, preFlightRequest); List&lt;String&gt; allowHeaders = checkHeaders(config, requestHeaders);//得到允许通过的请求头 if (allowOrigin == null || allowMethods == null || (preFlightRequest &amp;&amp; allowHeaders == null)) &#123;//不满足条件则直接返回 rejectRequest(response); return false; &#125; HttpHeaders responseHeaders = response.getHeaders();//装配响应头信息 responseHeaders.setAccessControlAllowOrigin(allowOrigin); responseHeaders.add(HttpHeaders.VARY, HttpHeaders.ORIGIN); if (preFlightRequest) &#123; responseHeaders.setAccessControlAllowMethods(allowMethods); &#125; if (preFlightRequest &amp;&amp; !allowHeaders.isEmpty()) &#123; responseHeaders.setAccessControlAllowHeaders(allowHeaders); &#125; if (!CollectionUtils.isEmpty(config.getExposedHeaders())) &#123; responseHeaders.setAccessControlExposeHeaders(config.getExposedHeaders()); &#125; if (Boolean.TRUE.equals(config.getAllowCredentials())) &#123; responseHeaders.setAccessControlAllowCredentials(true); &#125; if (preFlightRequest &amp;&amp; config.getMaxAge() != null) &#123; responseHeaders.setAccessControlMaxAge(config.getMaxAge()); &#125; response.flush(); return true;&#125; 上述的方法虽然比较长，但是其实逻辑很简单，第一步获取请求头的各种参数和CORS配置的进行对比，如果不能满足其条件，则直接返回验证不通过。 如果验证通过，则将这些信息记录到ResponseHeader中去。 小结到这里我们总算知道CORS是怎么被加载和被注册到Handler中拦截不合法的请求的，但是需要注意一点的是如果是想请求能被CORS进行拦截，就一定要在requestHeader中加入Origin参数。这是必备的。不然CORS配置的拦截并不能对这次请求生效。 局部注解方式上面我们讲解的是通过一个全局的配置来进行CORS配置，但是我想就行我们做其他的事情一样都需要有个性化的配置。当然Spring也为这种方式提供了对应的注解去实现这个功能。 @CrossOrigin示例下面我们使用@CrossOrigin注解演示一个案例1234567@CrossOrigin(methods = &#123;RequestMethod.DELETE&#125;,origins = &#123;\"http://localhost:9090\"&#125;)@PostMapping(\"hello\")@ResponseBodypublic String objectValue(@RequestParam Map&lt;String,String&gt; values)&#123; System.out.println(values); return \"OK\";&#125; 当我们使用postman模拟一个请求，然后就可以验证我们的配置是否生效。当然我们须在请求头上加上Origin参数，不然是不会生效的。当然@CorssOrign注解可以同时作用于方法和类上的。可以自己进行简单的测试。和requestMapping有点相似。 @CorssOrign解析首先都是作用于Controller的注解，那么猜想也觉得是和Handler绑定到一起的。而且之前我们也说过，只有当header中包含Orgin的时候才会进行CORS的处理。所以我们可以大概定位到其加载的位置还是在getHandler方法中。123456789101112public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; Object handler = getHandlerInternal(request); ...省略 HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; 我们可以看到globalConfig对应的是全局，那么这里我猜想handlerConfig肯定是对应方法上的注解。之前在介绍的时候并没有详细说明这一块的内容，主要还是为了在这里更加清晰的介绍。那么我们就看一下getCorsConfiguration方法的实现1234567891011121314protected CorsConfiguration getCorsConfiguration(Object handler, HttpServletRequest request) &#123; CorsConfiguration corsConfig = super.getCorsConfiguration(handler, request);//判断handler是否为CorsConfigurationSource对象 if (handler instanceof HandlerMethod) &#123;//判断Handler是否为HandlerMethod HandlerMethod handlerMethod = (HandlerMethod) handler; if (handlerMethod.equals(PREFLIGHT_AMBIGUOUS_MATCH)) &#123;//是否为EmptyHandler return AbstractHandlerMethodMapping.ALLOW_CORS_CONFIG; //允许所以 &#125; else &#123; CorsConfiguration corsConfigFromMethod = this.mappingRegistry.getCorsConfiguration(handlerMethod);//从mappingRegistry获取corsConfig corsConfig = (corsConfig != null ? corsConfig.combine(corsConfigFromMethod) : corsConfigFromMethod);//如果有组合，没有就使用corsConfigFromMethod &#125; &#125; return corsConfig;&#125; 这里主要做的事情就是合并已有的corsConfig和这个方法对应的corsConfig。mappingRegistry.getCorsConfiguration方法主要目的就是获取当前方法拥有的CORSConfig。1234public CorsConfiguration getCorsConfiguration(HandlerMethod handlerMethod) &#123; HandlerMethod original = handlerMethod.getResolvedFromHandlerMethod(); return this.corsLookup.get(original != null ? original : handlerMethod);&#125; 这里的corsLookup是个map。通过HandlerMethod看能否匹配合适的CorsConfig。到这里又回到了同一个问题，那就是corsLookup是怎么注册的，requestMapping其实也是一个到底，到底是怎么以方法为单位进行注册的。 通过Debug CorsConfig的put方法我们发现，其实corsLookup的注册是通过RequestMappingHandlerMapping的afterPropertiesSet方法实现的。我们都知道afterPropertiesSet是InitializingBean接口定义的方法。而我们也应该知道一个类实现了InitializingBean接口后，在初始化这个bean的时候就会调用这个类的afterPropertiesSet方法。那我们看看afterPropertiesSet方法到底做了什么事情。123456789101112@Overridepublic void afterPropertiesSet() &#123; this.config = new RequestMappingInfo.BuilderConfiguration(); this.config.setUrlPathHelper(getUrlPathHelper()); //url处理 this.config.setPathMatcher(getPathMatcher()); //地址转换 this.config.setSuffixPatternMatch(this.useSuffixPatternMatch);//使用后缀匹配模式 this.config.setTrailingSlashMatch(this.useTrailingSlashMatch);//后缀/匹配模式 this.config.setRegisteredSuffixPatternMatch(this.useRegisteredSuffixPatternMatch); this.config.setContentNegotiationManager(getContentNegotiationManager());//处理内容的 super.afterPropertiesSet();&#125; 这里主要是为BuilderConfiguration准备一些，默认的相关参数，处理逻辑还要看父类的afterPropertiesSet方法12345678910111213141516171819202122public void afterPropertiesSet() &#123; initHandlerMethods();&#125;protected void initHandlerMethods() &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Looking for request mappings in application context: \" + getApplicationContext()); &#125; String[] beanNames = (this.detectHandlerMethodsInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(getApplicationContext(), Object.class) : getApplicationContext().getBeanNamesForType(Object.class));//感觉是获取了所有的bean for (String beanName : beanNames) &#123;//遍历 if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123; Class&lt;?&gt; beanType = null; beanType = getApplicationContext().getType(beanName); if (beanType != null &amp;&amp; isHandler(beanType)) &#123; detectHandlerMethods(beanName);//检测每个bean？ &#125; &#125; &#125; handlerMethodsInitialized(getHandlerMethods()); //初始化 &#125; 其实这个方法还是包装方法，目的是为了获取注册的bean，然后遍历每一个bean进行检测和处理123456789101112131415161718protected void detectHandlerMethods(final Object handler) &#123; Class&lt;?&gt; handlerType = (handler instanceof String ? getApplicationContext().getType((String) handler) : handler.getClass()); final Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType);//获取真是的class，因为有可能是代理对象 Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType, new MethodIntrospector.MetadataLookup&lt;T&gt;() &#123; @Override public T inspect(Method method) &#123; return getMappingForMethod(method, userType); //这里其实是回调方法，进行过滤 &#125;fangfa &#125;);//筛选满足条件的 for (Map.Entry&lt;Method, T&gt; entry : methods.entrySet()) &#123;//遍历每一个满足条件的方法 Method invocableMethod = AopUtils.selectInvocableMethod(entry.getKey(), userType); T mapping = entry.getValue(); registerHandlerMethod(handler, invocableMethod, mapping); &#125; &#125; 上述方法做的事情还是很明确的，首先通过bean找到真是的class，然后筛选出所有符合条件的方法。当然这里的符合条件还需要我们看下文的分析才知道。然后注册每一个方法。 第一步我们看一下筛选方法getMappingForMethod的逻辑12345678910protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) &#123; RequestMappingInfo info = createRequestMappingInfo(method);//获取RequestMappingInfo if (info != null) &#123; RequestMappingInfo typeInfo = createRequestMappingInfo(handlerType);//再取一次，我还没太明白什么情况会产生这样的操作 if (typeInfo != null) &#123; info = typeInfo.combine(info); //组合 &#125; &#125; return info;&#125; 这里就是根据获取到的RequestMappingInfo进行组合。组合就是把属性否加起来没什么好看的，应该要知道有那些属性才比较重要。那我们需要看createRequestMappingInfo方法里做了什么。123456private RequestMappingInfo createRequestMappingInfo(AnnotatedElement element) &#123; RequestMapping requestMapping = AnnotatedElementUtils.findMergedAnnotation(element, RequestMapping.class); RequestCondition&lt;?&gt; condition = (element instanceof Class ? getCustomTypeCondition((Class&lt;?&gt;) element) : getCustomMethodCondition((Method) element)); return (requestMapping != null ? createRequestMappingInfo(requestMapping, condition) : null);&#125; 神秘面纱被解开。这里主要就是通过方法上的RequestMapping注解，如果存在则继续构建createRequestMappingInfo，否则直接返回null。123456789101112131415protected RequestMappingInfo createRequestMappingInfo( RequestMapping requestMapping, RequestCondition&lt;?&gt; customCondition) &#123; return RequestMappingInfo .paths(resolveEmbeddedValuesInPatterns(requestMapping.path())) .methods(requestMapping.method()) .params(requestMapping.params()) .headers(requestMapping.headers()) .consumes(requestMapping.consumes()) .produces(requestMapping.produces()) .mappingName(requestMapping.name()) .customCondition(customCondition) .options(this.config) .build();&#125; 最终的构建，无非就是把RequestMapping注解里面设置的内容通过builer模式放在RequestMappingInfo中。这道理我们误打误撞的就把RequestMapping怎么被加载的逻辑给找到了。 我们这时候就要回到我们之前的遍历满足条件的方法进行注册了。123protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method);&#125; 是不是有种熟悉的感觉，我们在之前就从mappingRegistry获取过Handler。继续看register方法的内容1234567891011121314151617181920212223242526272829public void register(T mapping, Object handler, Method method) &#123; this.readWriteLock.writeLock().lock();//获取写锁 try &#123; HandlerMethod handlerMethod = createHandlerMethod(handler, method);//构造HandlerMethod assertUniqueMethodMapping(handlerMethod, mapping);//确保唯一 this.mappingLookup.put(mapping, handlerMethod); List&lt;String&gt; directUrls = getDirectUrls(mapping);//获取对应的url for (String url : directUrls) &#123; this.urlLookup.add(url, mapping); &#125; String name = null; if (getNamingStrategy() != null) &#123;//这个适配暂时还没懂 name = getNamingStrategy().getName(handlerMethod, mapping); addMappingName(name, handlerMethod); &#125; CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping);//加载Cors if (corsConfig != null) &#123; this.corsLookup.put(handlerMethod, corsConfig); &#125; this.registry.put(mapping, new MappingRegistration&lt;T&gt;(mapping, handlerMethod, directUrls, name)); &#125; finally &#123; this.readWriteLock.writeLock().unlock(); &#125;&#125; 可以看到上面的方法注册了几样东西1.构造HandlerMethod2.注册url到urlLookup3.通过策略添加合适的名称映射？4.解析方法对应的CorsConfiguration 其实这里我们重点就是来分析CorsConfiguration的，所以直接看下initCorsConfiguration方法的实现，需要看实现类 1234567891011121314151617181920protected CorsConfiguration initCorsConfiguration(Object handler, Method method, RequestMappingInfo mappingInfo) &#123; HandlerMethod handlerMethod = createHandlerMethod(handler, method); CrossOrigin typeAnnotation = AnnotatedElementUtils.findMergedAnnotation(handlerMethod.getBeanType(), CrossOrigin.class);//类注解 CrossOrigin methodAnnotation = AnnotatedElementUtils.findMergedAnnotation(method, CrossOrigin.class);//方法上的注解 if (typeAnnotation == null &amp;&amp; methodAnnotation == null) &#123; return null; &#125; CorsConfiguration config = new CorsConfiguration(); updateCorsConfig(config, typeAnnotation);//将配置的信息放到config中 updateCorsConfig(config, methodAnnotation); if (CollectionUtils.isEmpty(config.getAllowedMethods())) &#123;//没过没有配置允许的方法，则全部 for (RequestMethod allowedMethod : mappingInfo.getMethodsCondition().getMethods()) &#123; config.addAllowedMethod(allowedMethod.name()); &#125; &#125; return config.applyPermitDefaultValues();&#125; 到这里我们终于知道了CrossOrigin的加载，同时会加载类和方法的配置。当然具体细节无非就是遍历注解中的每一个元素进行设值。 小结到这里我么也讲完了CrossOrign使用注解方式的加载，同时我们还知道了HandlerMapping的加载过程。spring中，对这些配置大多都是以组合的方式进行处理。然后回到之前的加载配置也是，如果存在多种Cros配置的时候就会组合在一起使用。 结语到此CROS的在Spring MVC中的加载和使用基本也算告一段落了，通过本文我们了解了如何使用CROS以及他的几种实现方式。另外我们也跟着源代码追踪了CORS在spring中具体是怎么被加载以及如何被使用的。另外通过本文，当然不仅仅只是看到CORS的实现，我们也应该去思考整个关于HandlerMapp或者整个spring mvc几大组件的实现原理。当然本人的实力有限，很多地方并没有很详细的介绍。欢迎交流和反馈 与君共勉！！！","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"CORS","slug":"CORS","permalink":"http://www.eumji025.com/tags/CORS/"}]},{"title":"springMVC-DispatcherServlet源码初探","slug":"springmvc-review","date":"2018-05-27T00:45:00.000Z","updated":"2018-05-27T01:56:01.572Z","comments":true,"path":"2018/05/27/springmvc-review/","link":"","permalink":"http://www.eumji025.com/2018/05/27/springmvc-review/","excerpt":"","text":"前言最近频繁的看到关于Spring MVC请求流程的相关文章，所以今天详细分析一波Spring MVC请求流程的源码。 在分析之前我们首先要回顾一下在我们普通的servlet中，我们一个请求过来首先会到达我们的service方法中，然后根据请求的不同选择doGet获取doPost方法进行不同的处理。 由于我们的Spring MVC也是基于servlet进行的，所以我们就从查找一下service方法的实现。通过我们在web.xml中的配置我们也不能发现，Spring MVC中，所有的请求都是被DispatcherServlet所拦截的，没错DispatcherServlet就是我们的一个httpServlet实现类。 左边的httpServlet系列就是javax包下的servlet，而右边则是我们熟悉的Spring MVC相关实现。 HttpServletBean -&gt; 主要重写了httpServlet的init方法； FrameworkServlet -&gt; 主要重写service，doGet，doPost等等关于请求的方法，这些方法都要调用processRequest方法，而processRequest方法又调用了doService这个关键方法，这个方法在FrameworkServlet中是抽象的，所以会在DispatcherServlet中被实现。 DispatcherServlet -&gt; 真正的逻辑处理类，也包含了Spring MVC基础条件的加载。 Service方法追踪上面其实也简单的介绍了Service方法的过程，不过在这里还是继续追踪一下。 123456789101112//FrameworkServlet.service方法protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; HttpMethod httpMethod = HttpMethod.resolve(request.getMethod()); if (HttpMethod.PATCH == httpMethod || httpMethod == null) &#123; processRequest(request, response); //patch方法直接调用processRequest &#125; else &#123; super.service(request, response); //其他的回到父类的Service方法 &#125;&#125; 在父类的Service方法中，httpServlet会根据不同的HttpMethod的请求方法重新再次回到FrameworkServlet类中，具体我们就以doPost方法为例 1234protected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; processRequest(request, response);&#125; 其实和直接调用processRequest方法没什么区别。 123456789101112131415161718192021222324protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; long startTime = System.currentTimeMillis(); Throwable failureCause = null; //构建localContext LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext(); LocaleContext localeContext = buildLocaleContext(request); //构建requestAttributes RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes(); ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); //asyncManager注册拦截器 WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor()); initContextHolders(request, localeContext, requestAttributes); //初始化上下文 try &#123; doService(request, response); //关键在这里 &#125; ...&#125; 上面方法主要是做一些准备工作，获取请求的相关属性，设置拦截器等，最后调用doService进行逻辑处理。回到DispatcherServlet类 12345678910111213141516171819202122232425262728@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; ... // 设置常用的一些解析器到request中 request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125;&#125; 可以看到方法还是包装的方法，主要目的是为了把一些必要信息放到request中，然后调用doDispatch处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); //检查是不是带有文件上传的请求 multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); //获取请求的mapperHandler if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); //如果找不到 return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());//通过Handler获取包装的HandlerAdapter // Process last-modified header, if supported by the handler. String method = request.getMethod(); //获取请求的方法 boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123;//get或者head方法 long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); //-1 if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123;//repHandle拦截方法 return; &#125; // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler());//真正的处理 if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); //处理view mappedHandler.applyPostHandle(processedRequest, response, mv); //方法后的拦截 &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); //处理结果 &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125; &#125; 好的上面的方法比较长，但是从中我们也看到了SpringMVC的核心请求过程，下面用一张图去总结一下。 具体的步骤 第一步：发起请求到前端控制器(DispatcherServlet) 第二步：前端控制器请求HandlerMapping查找 Handler （可以根据xml配置、注解进行查找） 第三步：处理器映射器HandlerMapping向前端控制器返回Handler，HandlerMapping会把请求映射为HandlerExecutionChain对象（包含一个Handler处理器（页面控制器）对象，多个HandlerInterceptor拦截器对象），通过这种策略模式，很容易添加新的映射策略 第四步：前端控制器调用处理器适配器去执行Handler 第五步：处理器适配器HandlerAdapter将会根据适配的结果去执行Handler 第六步：Handler执行完成给适配器返回ModelAndView 第七步：处理器适配器向前端控制器返回ModelAndView （ModelAndView是springmvc框架的一个底层对象，包括 Model和view） 第八步：前端控制器请求视图解析器去进行视图解析 （根据逻辑视图名解析成真正的视图(jsp)），通过这种策略很容易更换其他视图技术，只需要更改视图解析器即可 第九步：视图解析器向前端控制器返回View 第十步：前端控制器进行视图渲染 （视图渲染将模型数据(在ModelAndView对象中)填充到request域），然后通过通过模板进行变量填充 第十一步：前端控制器向用户响应结果 详情处理Handler装配123456789protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; for (HandlerMapping hm : this.handlerMappings) &#123; HandlerExecutionChain handler = hm.getHandler(request); if (handler != null) &#123; return handler; &#125; &#125; return null;&#125; 这里的handlerMappings是在init方法中构造的，就是找到所有HandlerMapping类型的bean、主要包含以下几种 我们应该很容易知道当前的请求应该是符合第二个RequestMappingHandlerMapping。然后我们继续往里面看 1234567891011121314151617181920212223public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; Object handler = getHandlerInternal(request);//第一步就是通过mapping中注册的url进行匹配 if (handler == null) &#123; //没有匹配的情况下构建默认的 handler = getDefaultHandler(); &#125; if (handler == null) &#123; //如果还是为空，直接返回 return null; &#125; // Bean name or resolved handler? if (handler instanceof String) &#123; String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); //构建HandlerExecutionChain if (CorsUtils.isCorsRequest(request)) &#123;//CORS处理 CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; 上面的方法做的事情比较简单，首先就是通过request的url和requestMapping中注册的url进行配对，如果存在匹配的就是进行参数设置并返回对对应的handler对象。 然后在通过Handler获取HandlerExecutionChain对象。HandlerExecutionChain主要是为了加载拦截器。 然后在判断是否当前的请求是否为CORS请求，如果是继续包装设置CorsConfiguration。 由于路径匹配比较简单就不介绍了，其实就是从map中查找。我们主要看一下getHandlerExecutionChain中做的事情。 123456789101112131415161718protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler));//包装成HandlerExecutionChain String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); for (HandlerInterceptor interceptor : this.adaptedInterceptors) &#123;//遍历拦截器添加到chain中 if (interceptor instanceof MappedInterceptor) &#123; MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor; if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; else &#123; chain.addInterceptor(interceptor); &#125; &#125; return chain;&#125; getHandlerExecutionChain方法很简单，首先就是把Handler包装成HandlerExecutionChain对象。然后遍历所有的插件，并记录到chain中。 CORS在这里就不着重说了不是今天的重点。获取Handler的方法到这里也就算结束了。其中的事情还是比较简单的。 HandlerAdapter装配其实HandlerAdapter和或者HandlerMapping差不多，找到requestMappingHandlerAdapter。 1234567protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException &#123; for (HandlerAdapter ha : this.handlerAdapters) &#123; if (ha.supports(handler)) &#123; return ha; &#125; &#125;&#125; HandlerAdapter是通过重写support方法看是否能进行适配的。requestMappingHandlerAdapter默认返回true，所以说默认都是交给requestMappingHandlerAdapter进行适配处理 然后经过中间步骤后，我们得到了requestMappingHandlerAdapter。 requestMappingHandlerAdapter处理获得HandlerAdapter之后，使用handle方法处理 1234public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return handleInternal(request, response, (HandlerMethod) handler);&#125; 上面只是个包装方法，真正的处理还是在handleInternal方法。 1234567891011121314151617181920212223242526protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ModelAndView mav; checkRequest(request); //校验方法类型是否支持，是否需要Session // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) &#123;//是否Session同步 HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) &#123;//给Session上锁 mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No HttpSession available -&gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); &#125; return mav;&#125; 从上面可以看到这里只是做部分校验还有是否需要同步处理的设置，最终实现还是在invokeHandlerMethod方法中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &#123; WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); //包装handlerMethod ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); invocableMethod.setDataBinderFactory(binderFactory); invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); modelFactory.initModel(webRequest, mavContainer, invocableMethod); mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); //异步请求 AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); if (logger.isDebugEnabled()) &#123; logger.debug(\"Found concurrent result value [\" + result + \"]\"); &#125; invocableMethod = invocableMethod.wrapConcurrentResult(result); &#125; //真正的执行 invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &#123; return null; &#125; //获取modelAndView return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125;&#125; 上面的方法比较长。其实大部分目前我们都不用关心，暂时不要管那些东西的作用，都是为后续的invoke做准备的。主要还是看invokeAndHandle方法。 1234567891011121314151617181920212223242526272829public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); //执行方法并返回结果 if (returnValue == null) &#123;//返回为空的处理 if (isRequestNotModified(webRequest) || hasResponseStatus() || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true);//设置标识后续有用 return; &#125; &#125; else if (StringUtils.hasText(this.responseReason)) &#123; mavContainer.setRequestHandled(true); return; &#125; mavContainer.setRequestHandled(false); try &#123; this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest);//处理结果 &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex); &#125; throw ex; &#125;&#125; 从上面的方法我们主要可以看见两件关键的事情，一是调用其他的方法执行真正的内容，二是对返回值进行处理。 首先来看一下invokeForRequest方法。 123456789101112131415public Object invokeForRequest(NativeWebRequest request, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);//获取方法的参数 if (logger.isTraceEnabled()) &#123; logger.trace(\"Invoking '\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"' with arguments \" + Arrays.toString(args)); &#125; Object returnValue = doInvoke(args); //执行 if (logger.isTraceEnabled()) &#123; logger.trace(\"Method [\" + ClassUtils.getQualifiedMethodName(getMethod(), getBeanType()) + \"] returned [\" + returnValue + \"]\"); &#125; return returnValue;&#125; 主要做了两件事，第一件事是进行方法的参数适配，第二件事调用doInvoke执行对应的Controller方法。 参数处理首先看一下getMethodArgumentValues里面是怎么做的。 12345678910111213141516171819202122private Object[] getMethodArgumentValues(NativeWebRequest request, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; MethodParameter[] parameters = getMethodParameters(); //方法对应的参数列表包装对象 Object[] args = new Object[parameters.length]; for (int i = 0; i &lt; parameters.length; i++) &#123;//遍历参数 MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer);//给参数包装类注册一个命名发现器 args[i] = resolveProvidedArgument(parameter, providedArgs); //适配parameter if (args[i] != null) &#123; continue; &#125; if (this.argumentResolvers.supportsParameter(parameter)) &#123;//适配不成功，则看参数解析器能否支持这个参数 try &#123; args[i] = this.argumentResolvers.resolveArgument( parameter, mavContainer, request, this.dataBinderFactory);//再次解析参数 continue; &#125; ... &#125; return args;&#125; 首先是遍历每一个参数，通过providedArgs进行适配，如果不成功，则使用argumentResolvers进行处理。 接下来看看argumentResolvers的resolveArgument方法到底怎么处理的。 123456public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); //还是取parameter对应的MethodArgumentResolver，=&gt; requestparamMapMethodArgumentResolver return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);//策略处理&#125; 其实这里相当于策略模式，选择合适的resolver进行处理。因为我们接收的是个map，所以这里就以mapResover为例进行处理 12345678910111213141516171819202122232425public Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception &#123; Class&lt;?&gt; paramType = parameter.getParameterType(); Map&lt;String, String[]&gt; parameterMap = webRequest.getParameterMap(); if (MultiValueMap.class.isAssignableFrom(paramType)) &#123;//判断是否MultiValueMap MultiValueMap&lt;String, String&gt; result = new LinkedMultiValueMap&lt;String, String&gt;(parameterMap.size()); for (Map.Entry&lt;String, String[]&gt; entry : parameterMap.entrySet()) &#123; for (String value : entry.getValue()) &#123; result.add(entry.getKey(), value); &#125; &#125; return result; &#125; else &#123; Map&lt;String, String&gt; result = new LinkedHashMap&lt;String, String&gt;(parameterMap.size()); for (Map.Entry&lt;String, String[]&gt; entry : parameterMap.entrySet()) &#123; if (entry.getValue().length &gt; 0) &#123; result.put(entry.getKey(), entry.getValue()[0]); &#125; &#125; return result; &#125;&#125; 其实这里做的事情很简单，判断map是否为MultiValueMap，然后进行包装处理,关于参数的包装这里已经介绍了。 方法调用我们在看上面说的第二件事doInvoke方法的逻辑 1234protected Object doInvoke(Object... args) throws Exception &#123; ReflectionUtils.makeAccessible(getBridgedMethod());//反射设置方法是可用的 return getBridgedMethod().invoke(getBean(), args);//然后真正调用invoke方法执行方法&#125; 后面的事情就是Controller做的了，到此我们也粗略的看完了。如何通过url查找一个handler，并包装成一个chain，最后由handlerAdapter处理handler，适配参数然后进行真正方法的处理。 结果处理这里我们接着看是如何处理返回值的。 12345678910@Overridepublic void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception &#123; HandlerMethodReturnValueHandler handler = selectHandler(returnValue, returnType);//和之前一样选择合适的ReturnHandler if (handler == null) &#123; throw new IllegalArgumentException(\"Unknown return value type: \" + returnType.getParameterType().getName()); &#125; handler.handleReturnValue(returnValue, returnType, mavContainer, webRequest);&#125; 由于我们现在加了一个@ResponseBody注解，所以这里选择的应该是RequestResponseBodyMethodProcessor。选择的理由是在进行是否匹配方法的时候进行筛选的。 1234public boolean supportsReturnType(MethodParameter returnType) &#123; return (AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ResponseBody.class) || returnType.hasMethodAnnotation(ResponseBody.class));&#125; 因为包含这个注解所以选择了这个Handler，然后我接着以RequestResponseBodyMethodProcessor为例看看内部如何实现的。 1234567891011public void handleReturnValue(Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123; mavContainer.setRequestHandled(true); ServletServerHttpRequest inputMessage = createInputMessage(webRequest); ServletServerHttpResponse outputMessage = createOutputMessage(webRequest); // Try even with null return value. ResponseBodyAdvice could get involved. writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage);&#125; 首先是构造request和Response的对象，然后 writeWithMessageConverters方法进行转换，这段代码比较长但是表简单 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495protected &lt;T&gt; void writeWithMessageConverters(T value, MethodParameter returnType, ServletServerHttpRequest inputMessage, ServletServerHttpResponse outputMessage) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException &#123;Object outputValue;Class&lt;?&gt; valueType;Type declaredType;//返回结果的类型判断和处理if (value instanceof CharSequence) &#123; outputValue = value.toString(); valueType = String.class; declaredType = String.class;&#125;else &#123; outputValue = value; valueType = getReturnValueType(outputValue, returnType); declaredType = getGenericType(returnType);&#125;HttpServletRequest request = inputMessage.getServletRequest(); //获取支持的MediaTypeList&lt;MediaType&gt; requestedMediaTypes = getAcceptableMediaTypes(request);List&lt;MediaType&gt; producibleMediaTypes = getProducibleMediaTypes(request, valueType, declaredType);if (outputValue != null &amp;&amp; producibleMediaTypes.isEmpty()) &#123; throw new IllegalArgumentException(\"No converter found for return value of type: \" + valueType);&#125;//进行MediaType匹配Set&lt;MediaType&gt; compatibleMediaTypes = new LinkedHashSet&lt;MediaType&gt;();for (MediaType requestedType : requestedMediaTypes) &#123; for (MediaType producibleType : producibleMediaTypes) &#123; if (requestedType.isCompatibleWith(producibleType)) &#123; compatibleMediaTypes.add(getMostSpecificMediaType(requestedType, producibleType)); &#125; &#125;&#125;if (compatibleMediaTypes.isEmpty()) &#123; if (outputValue != null) &#123; throw new HttpMediaTypeNotAcceptableException(producibleMediaTypes); &#125; return;&#125;List&lt;MediaType&gt; mediaTypes = new ArrayList&lt;MediaType&gt;(compatibleMediaTypes);MediaType.sortBySpecificityAndQuality(mediaTypes);//排序//选择合适的mediaTypeMediaType selectedMediaType = null;for (MediaType mediaType : mediaTypes) &#123; if (mediaType.isConcrete()) &#123; selectedMediaType = mediaType; break; &#125; else if (mediaType.equals(MediaType.ALL) || mediaType.equals(MEDIA_TYPE_APPLICATION)) &#123; selectedMediaType = MediaType.APPLICATION_OCTET_STREAM; break; &#125;&#125;//进行消息的转换，这点我们应该都很熟悉，经常在项目里自定义messageConverterif (selectedMediaType != null) &#123; selectedMediaType = selectedMediaType.removeQualityValue(); for (HttpMessageConverter&lt;?&gt; messageConverter : this.messageConverters) &#123; if (messageConverter instanceof GenericHttpMessageConverter) &#123;//GenericHttpMessageConverter类型的处理 if (((GenericHttpMessageConverter) messageConverter).canWrite( declaredType, valueType, selectedMediaType)) &#123; outputValue = (T) getAdvice().beforeBodyWrite(outputValue, returnType, selectedMediaType, (Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) messageConverter.getClass(), inputMessage, outputMessage); if (outputValue != null) &#123; addContentDispositionHeader(inputMessage, outputMessage); ((GenericHttpMessageConverter) messageConverter).write( outputValue, declaredType, selectedMediaType, outputMessage); if (logger.isDebugEnabled()) &#123; logger.debug(\"Written [\" + outputValue + \"] as \\\"\" + selectedMediaType + \"\\\" using [\" + messageConverter + \"]\"); &#125; &#125; return; &#125; &#125; else if (messageConverter.canWrite(valueType, selectedMediaType)) &#123;//在判断是否可以写 outputValue = (T) getAdvice().beforeBodyWrite(outputValue, returnType, selectedMediaType, (Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) messageConverter.getClass(), inputMessage, outputMessage);//获取输出的值 if (outputValue != null) &#123; addContentDispositionHeader(inputMessage, outputMessage);//响应头处理 ((HttpMessageConverter) messageConverter).write(outputValue, selectedMediaType, outputMessage);//消息处理 if (logger.isDebugEnabled()) &#123; logger.debug(\"Written [\" + outputValue + \"] as \\\"\" + selectedMediaType + \"\\\" using [\" + messageConverter + \"]\"); &#125; &#125; return; &#125; &#125;&#125; 这里再总结一下做的事情： 1.通过响应结果选择合适的Handler 2.装配参数进行消息的转换 3.在通过mediaType选择合适的messageConverter进行消息转换 modelAndView消息的转换我们也已经看完，接着看之前的modelAndView处理。 12345678910111213141516171819private ModelAndView getModelAndView(ModelAndViewContainer mavContainer, ModelFactory modelFactory, NativeWebRequest webRequest) throws Exception &#123; modelFactory.updateModel(webRequest, mavContainer);//更新model的值 if (mavContainer.isRequestHandled()) &#123; return null; &#125; ModelMap model = mavContainer.getModel(); ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model, mavContainer.getStatus());//构建ModelAndView对象 if (!mavContainer.isViewReference()) &#123; mav.setView((View) mavContainer.getView()); &#125; if (model instanceof RedirectAttributes) &#123;//如果是重定向 Map&lt;String, ?&gt; flashAttributes = ((RedirectAttributes) model).getFlashAttributes(); HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class); RequestContextUtils.getOutputFlashMap(request).putAll(flashAttributes);//将数据传递 &#125; return mav;&#125; 这里主要做的事情就是解析，然后包装在modelAndView对象中，如果是重定向则把数据传递到request中。 视图处理然后我们回到最完成也就是dispatcherServlet中，继续看后面的applyDefaultViewName方法、 12345private void applyDefaultViewName(HttpServletRequest request, ModelAndView mv) throws Exception &#123; if (mv != null &amp;&amp; !mv.hasView()) &#123; mv.setViewName(getDefaultViewName(request)); &#125;&#125; 如果没有视图设置个默认的视图，这一步没做什么然后就是进行拦截器的后置操作，这里就不介绍了。 最后看看processDispatchResult做了什么事情。其实猜也能猜到主要是解析视图 1234567891011121314151617private void processDispatchResult(HttpServletRequest request, HttpServletResponse response,HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception &#123; // Did the handler return a view to render? if (mv != null &amp;&amp; !mv.wasCleared()) &#123; render(mv, request, response); //关键还是这里 if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Concurrent handling started during a forward return; &#125; if (mappedHandler != null) &#123; mappedHandler.triggerAfterCompletion(request, response, null); &#125; &#125; 其实这一层只是包装方法，做一些条件判断。最重要的实现在render方法中。 1234567891011121314151617181920protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // Determine locale for request and apply it to the response. Locale locale = this.localeResolver.resolveLocale(request); response.setLocale(locale); View view; if (mv.isReference()) &#123;//判断viw是否为string类型 // We need to resolve the view name. view = resolveViewName(mv.getViewName(), mv.getModelInternal(), locale, request);//解析view &#125; // Delegate to the View object for rendering. if (logger.isDebugEnabled()) &#123; logger.debug(\"Rendering view [\" + view + \"] in DispatcherServlet with name '\" + getServletName() + \"'\"); &#125; if (mv.getStatus() != null) &#123;//设置Response状态 response.setStatus(mv.getStatus().value()); &#125; view.render(mv.getModelInternal(), request, response);//设计到模板的实现就不分析了。 &#125;&#125; 第一件事是解析view对应的视图，然后第二件事是将model的属性和视图进行装配。这里我们就看一下是如何匹配解析模板就行了。 1234567891011protected View resolveViewName(String viewName, Map&lt;String, Object&gt; model, Locale locale, HttpServletRequest request) throws Exception &#123; for (ViewResolver viewResolver : this.viewResolvers) &#123; View view = viewResolver.resolveViewName(viewName, locale); if (view != null) &#123; return view; &#125; &#125; return null;&#125; 主要就是通过遍历已有的viewResolvers，然后寻找合适的视图。具体后续如何 进行值绑定这里就不多做介绍了。 到此Spring MVC的整个流程就结束了。通过简单的代码追踪对之前的概念有了更深刻的认识，当然本文确实分析的不够细致，只是走马观花的看了整体的大概流程，很多细节还是值得去推敲。 结语与君共勉！！！","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://www.eumji025.com/tags/Spring-MVC/"}]},{"title":"mysql8.0解压版本安装和配置","slug":"mysql-8-install","date":"2018-05-01T04:28:14.000Z","updated":"2018-05-27T01:50:47.944Z","comments":true,"path":"2018/05/01/mysql-8-install/","link":"","permalink":"http://www.eumji025.com/2018/05/01/mysql-8-install/","excerpt":"","text":"前言因为最近MySQL8.0.11版本已经发布，而且从网上公布的数据来看，MySQL8有较多的改善，具体大家可以参看这篇文章MySQL 8.0 正式版 8.0.11 发布：比 MySQL 5.7 快 2 倍 所以个人直接就下载了一个8.0.11版本。准备尝试一下新版本的MySQL。因为我是在公司的新机上测试的，可能后面记录的东西对升级的同学有帮助。 过程记录下面是详细的过程记录。 下载和解压下载地址：https://dev.mysql.com/downloads/mysql/然后解压到你喜欢的位置。 配置由于在新版的MySQL中，是没有提供默认的配置文件的，所以我们需要在解压的根目录下新建一个配置文件my.ini。下面是配置文件中具体的内容123456789101112131415161718192021[client]default-character-set=utf8[mysqld]port=3306basedir =&quot;D:/soft/mysql8/&quot;datadir =&quot;D:/soft/mysql8/data/&quot;tmpdir =&quot;D:/soft/mysql8/data/&quot;socket =&quot;D:/soft/mysql8/data/mysql.sock&quot;log-error=&quot;D:/soft/mysql8/data/mysql_error.log&quot;character-set-server=utf8collation-server=utf8_unicode_ci 其中 D:/soft/mysql8 替换成自己解压的目录。 然后通过命令行进入到D:/soft/mysql8，注意需要管理员权限。 首先是初始化数据，这一步很重要，不然后面会玩不了的。 mysqld –initialize-insecure 注意，要使用mysqld –initialize-insecure 而不是 mysqld –initialie。前者初始化的时候不会给root账户一个初始化密码。而后者会给一个随机的密码。 具体的说明参看官方文档： https://dev.mysql.com/doc/refman/8.0/en/data-directory-initialization-mysqld.html 然后就是常规的几个步骤 mysqld installnet start mysqlmysql -u root -p 然后直接回车进入到mysql中，然后我们需要修改一个新的密码 ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘new_password’; 然后退除mysql重启服务就可以了。 小结和MySQL5.6版本的操作还是有很大的不同哈，需要自己新建配置文件，还要初始化，并且初始化一定使用mysqld –initialize-insecure命令 最后就是修改密码也变得简单了。 结语近期打算看一下高性能这本书，后续有机会分享更多的知识点。 与君共勉！！","categories":[{"name":"数据库","slug":"数据库","permalink":"http://www.eumji025.com/categories/数据库/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://www.eumji025.com/tags/mysql/"}]},{"title":"Java8 - 时间API记录","slug":"localdatetime-api","date":"2018-03-19T11:15:51.000Z","updated":"2018-03-21T14:38:26.800Z","comments":true,"path":"2018/03/19/localdatetime-api/","link":"","permalink":"http://www.eumji025.com/2018/03/19/localdatetime-api/","excerpt":"","text":"前言JAVA8的新特性之一就是DATE/TIME的改善,之前的时间API确实不够好用,JAVA8借鉴了Joda-Time的精华对旧的API进行了改善和升级API,正好最近工作中常常使用到时间,简单的记录一下java时间API的用法,不涉及非常高深的东西. 结构介绍 LocalTimeLocalTime 顾名思义就是介绍具体的时间的类. ####创建时间对象 123456789// current time 11:34:53.201LocalTime currentTime = LocalTime.now();//of重载了多个方法,可以根据自己的需求选择合适的方法// 12:00LocalTime midday = LocalTime.of(12, 0);// 13:10:15LocalTime afterMidday = LocalTime.of(13, 10, 15);// 10:00:01LocalTime fromSecondsOfDay = LocalTime.ofSecondOfDay(36001); 获取时间的某一部分接下来看一下如何通过LocalTime 对象获取具体的时分秒 12345678//11int hour = currentTime.getHour();//34int minute = currentTime.getMinute();//53int second = currentTime.getSecond();//733int nano = currentTime.getNano(); 另外补充 withXXX方法为通过改变当前时间的时或分或秒生成新时间 plusXXX方法为在当前时间对象的基础上加多少小时或者多少分钟或者多少秒生成新时间对象 minusXXX方法则为在当前时间对象的基础上减多少小时或者多少分钟或者多少秒生成新时间对象 格式化时间12345678910111213//格式化时间 11:34:53.201String basic = currentTime.format(DateTimeFormatter.ISO_LOCAL_TIME);//12:00:00String middayFormat = midday.format(DateTimeFormatter.ISO_LOCAL_TIME);//自定义格式化时间 11:34:53String custom = currentTime.format(DateTimeFormatter.ofPattern(\"HH:mm:ss\"));//解析时间LocalTime basicTime = LocalTime.parse(basic);//12:00LocalTime middayParse = LocalTime.parse(middayFormat);//自定义格式解析时间LocalTime customTime = LocalTime.parse(custom, DateTimeFormatter.ofPattern(\"HH:mm:ss\")); 我们不需要关系DateTimeFormatter只需要关心我们格式化和解析的格式就可以了,中间还添加不完整格式的时间进行格式化. ##LocalDate LocalDate顾名思义就是本地日期的类,用来专门处理日期相关的操作 创建日期12345678910111213// the current dateLocalDate currentDate = LocalDate.now();// 2017-11-25LocalDate day1 = LocalDate.of(2017, Month.NOVEMBER, 25);// 2014-05-11LocalDate day2 = LocalDate.of(2014, 5, 11);// 2010的第65天LocalDate day3 = LocalDate.ofYearDay(2010, 65);//1970-01-02 从1970的第一天加1天LocalDate epochDay = LocalDate.ofEpochDay(1); 修改日期会生成新的日期,本演示结果省略 123456789101112131415day1.withYear(1993);//修改年份并创建日期day1.withMonth(3); //会自动更新天数越界的问题day1.withDayOfYear(23);//年份不变,改为当前年的第23天day1.withDayOfMonth(3);//当前月的第三天day1.plusDays(3); //当前日期加3天day1.plusYears(3); //加3年day1.plusWeeks(3); //加3周day1.plusMonths(3); //加三个月 获取日期12345678910//=============================获取日期================================int year = day1.getYear();//获取年份Month month = day1.getMonth(); //获取月份 --为枚举类int dayOfYear = day1.getDayOfYear(); //当前年的多少天int dayOfMonth = day1.getDayOfMonth(); //当前月的多少天DayOfWeek dayOfWeek = day1.getDayOfWeek(); //当前周的第几天 --枚举类 格式化日期和格式化时间类似 1234String format = day1.format(DateTimeFormatter.ISO_LOCAL_DATE);String customDate = day1.format(DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"));LocalDate parse = LocalDate.parse(format);LocalDate.parse(customDate,DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); LocalDateTime顾名思义就是具体的日期+时间的类,可以理解为localDate和localTime的结合体. 创建时间1234567891011// 当前日期+时间LocalDateTime currentDateTime = LocalDateTime.now();// 2017-10-12 12:30LocalDateTime localDateTime1 = LocalDateTime.of(2017, 10, 12, 12, 30);// 2014-11-4 12:10:05LocalDateTime localDateTime2 = LocalDateTime.of(2014, Month.NOVEMBER, 4, 12, 10,5);//日期+时间拼接LocalDateTime localDateTime3= LocalDateTime.of(currentDate, currentTime); 其他也有和LocalDate和LocalTime类似的 getXXX方法,包括年月日时分秒 withXXX方法,更改局部生成新对象,包括年月日时分秒 plusXXX方法,在当前的基础上加一定的时间 minusXXX方法,当前时间基础上减一定的时间 format和parse方法格式化对象 汇总1.equals,isBefore,isAfter方法1234567public static void compare()&#123; LocalDate date1 = LocalDate.now(); LocalDate date2 = LocalDate.now(); System.out.println(date1.equals(date1)); //true System.out.println(date1.isBefore(date2)); //false System.out.println(date1.isAfter(date2)); //false&#125; 这里没有大于等于和小于等于，所以只能使用equals和isBefore，equals和isAfter做组合才行。 2.对象转换 1234567//通过localDateTime获取localDateLocalDate localDate = currentDateTime.toLocalDate();//通过localDateTime获取localTimeLocalTime localTime = currentDateTime.toLocalTime();//通过localTime+localDate生产localDateTimeLocalDateTime localDateTime4 = localDate.atTime(localTime);LocalDateTime localDateTime5 = localTime.atDate(localDate); TimeZone时区的时间操作,将本地时间转化为对应时区的时间 ZoneId类 记录时区信息和转换时区的操作 1ZonedDateTime berlinDateTime = ZonedDateTime.of(dateTime, ZoneId.of(\"Europe/Berlin\")); 时间戳时间戳,在JAVA8中使用Instant作为时间戳类 123456//当前时间戳Instant now = Instant.now();// 1262334567秒转化为时间戳Instant.ofEpochSecond(1262334567);//时间戳转成毫秒的数字 long toEpochMillis = now.toEpochMilli(); 在看一下之前的时间戳类TimeStamp12345678public static void timestamp()&#123; Timestamp timestamp = new Timestamp(System.currentTimeMillis()); LocalDateTime localDateTime = timestamp.toLocalDateTime(); Timestamp valueTime = Timestamp.valueOf(localDateTime); Instant instant = timestamp.toInstant(); Timestamp instantTime = Timestamp.from(instant);&#125; Timestamp只能直接和这两类进行转换。 时间间距前面我们已经介绍了几个新时间类的常用API，包括构造，类型之间转化，格式化，时间处理等操作。但是我们没有介绍两个时间类之间的间隔该怎么求。 默认的方式，使用本身的unit方法123456final LocalDate before = LocalDate.of(2018, 2, 10);final LocalDate now = LocalDate.now();final LocalTime localTime = LocalTime.now();final LocalDateTime localDateTime = LocalDateTime.now();final long month = localDateTime.until(localTime, ChronoUnit.MONTHS);final long hours = localDateTime.until(now, ChronoUnit.HOURS); ChronoUnit借助工具类，ChronoUnit的between方法。12345678public static void chronoUnitTest()&#123; final LocalDate before = LocalDate.of(2018, 2, 10); final LocalDate now = LocalDate.now(); final long between = ChronoUnit.DAYS.between(before, now); System.out.println(between); System.out.println(ChronoUnit.MONTHS.between(before,now)); System.out.println(ChronoUnit.WEEKS.between(before,now));&#125; ChronoUnit里面有年月日时分秒等等枚举的，其实between方法用的还是上面的unit。只是进行了包装看起来更加的直白。 格式化补充前面我们介绍了Java8中如何进行时间格式化，但是有一些细节问题我们没有讲到，这里进行补充。 超出范文的时间测试123456789public static void formatTime1() throws ParseException &#123; String time1 = \"2013-14-12\"; final SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd\"); final Date parse = sf.parse(time1); System.out.println(parse); final LocalDate parse1 = LocalDate.parse(time1, DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); System.out.println(parse1);&#125; 可以猜一下上面的结果，首先sf会自动给你转换，升级时间为2014-02-12.不可思议把，之前的使用中还真没注意到。但是使用DateTimeFormatter直接抛出异常Text &#39;2013-14-12&#39; could not be parsed: Invalid value for MonthOfYear (valid values 1 - 12): 14。会直接校验各个值的合理性 格式问题123456789101112public static void formatTime2() throws ParseException &#123; String time1 = \"2013-1-1\"; String time2 = \"2013-01-01\"; //final SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd\"); final SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-M-d\"); final Date parse = sf.parse(time2); System.out.println(parse); //final LocalDate parse1 = LocalDate.parse(time1, DateTimeFormatter.ofPattern(\"yyyy-MM-dd\")); final LocalDate parse1 = LocalDate.parse(time2, DateTimeFormatter.ofPattern(\"yyyy-M-d\")); System.out.println(parse1); &#125; SimpleDateFormat对于 2013-1-1 这样的格式依然可以用yyyy-MM-ddDateTimeFormatter则不可以 Text ‘2013-1-1’ could not be parsed at index 5SimpleDateFormat和DateTimeFormatter都可以yyyy-M-d格式兼容 2013-01-01这样的时间格式，说明yyyy-M-d才是真爱 小结时间类型我没测试，可以自己进行测试。不过我感觉应该差不多。总体上来说，DateTimeFormatter会要求的更加严格，SimpleDateFormat则会在越界的时间上依然提供转换的可能性。也不知道是好是坏。 不过DateTimeFormatter是线程安全的。而且Java8中的时间API好用不少，之后会写一篇如何在Java8中使用LocalDate适配Jackson和Mybatis的映射。 结语就简单介绍到这里了，目前用的东西也就这么多，等需要的时候再补充！！ 与君共勉!!!","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"LocalDateTime","slug":"LocalDateTime","permalink":"http://www.eumji025.com/tags/LocalDateTime/"}]},{"title":"ThreadLocal扩展 - InheritableThreadLocal的原理","slug":"inheritableThreadLocal","date":"2018-03-18T02:15:35.000Z","updated":"2018-03-18T02:18:58.934Z","comments":true,"path":"2018/03/18/inheritableThreadLocal/","link":"","permalink":"http://www.eumji025.com/2018/03/18/inheritableThreadLocal/","excerpt":"","text":"前言我们应该都知道ThreadLocal是为了解决同一线程内，多个地方可以共享同一个变量，而线程间可以起隔离一个非常有用的工具类。具体可以参看我的文章Java基础 - ThreadLocal分析篇文章中对threadLocal中的分析。 本文则是在ThreadLocal的基础上，分析其子类InheritableThreadLocal。从名称应该也可以看出，其作用是为了继承ThreadLocal里的东西。简单来说就是为了在子线程中继承父线程中设置的值。举个很简单的例子，如果我想传递父线程的某个对象，我不用为每个子线程都设置构造函数，而子线程的任何地方都可以获取。不过需要注意的是，一旦子线程初始化，父线程再更换对象，子线程将不受影响。 示例来举一个简单的例子演示一下。 123456789public class InheritableThreadLocalDemo &#123; private static ThreadLocal&lt;String&gt; local = new InheritableThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException &#123; local.set(\"aaaaa\"); new Thread(()-&gt;&#123; System.out.println(local.get()); &#125;).start();&#125; 在这个例子中，子线程见输出aaaaa。 剖析我们都知道ThreadLocal是线程隔离的，但是为什么InheritableThreadLocal就可以传递，并且还是有限制条件的，那么一个很大的玄机肯定在线程初始化的时候。 具体让我们跟随代码来看看其中的逻辑。首先还是看一下InheritableThreadLocal的代码变化 12345678910111213public class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; &#123; protected T childValue(T parentValue) &#123; return parentValue; &#125; ThreadLocalMap getMap(Thread t) &#123; return t.inheritableThreadLocals; &#125; void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); &#125;&#125; 可以看到变化是非常少的，只是将threadLocals上的操作转到了inheritableThreadLocals之上。 1234567891011121314151617181920public Thread(Runnable target) &#123; init(null, target, \"Thread-\" + nextThreadNum(), 0);&#125;private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null, true);////inheritThreadLocals默认为true&#125;private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) &#123; ...//省略 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)//关键默认都满足 this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);//看这里 /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID();&#125; 从上文中可以看出，我们在线程初始化的时候有部分就是将父线程的inheritableThreadLocals设置到子线程中来，当然是要处理，因为两个默认使用的线程不同。接着向下看 123456789101112131415161718192021222324252627static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) &#123; return new ThreadLocalMap(parentMap);&#125;private ThreadLocalMap(ThreadLocalMap parentMap) &#123; Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) &#123;//遍历父线程的threadLocal里的table 数组 Entry e = parentTable[j]; if (e != null) &#123; @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) &#123; Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; &#125; &#125; &#125;&#125; 可以看到做的事情也很简单，就是把父线程的中threadLocalMap复制一份到子线程中。由于取值还是用的同一个ThreadLocal对象，所以自然 能从子类中取到值。 结合上面这两段代码，我们可以看到，在子线程创建的时候会把父线程的inheritableThreadLocals复制一份，又因为InheritableThreadLocals在调用createMap时候已经被重写了。 123void createMap(Thread t, T firstValue) &#123; t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);&#125; 但是这里做的并不是替换引用，而是复制一份。所以当父类之后在修改的时候，子线程取得还是自己线程里取的值，所以两者在创建之后是无法相互影响的。 总结InheritableThreadLocal主要目的为了父子线程间能够自动传递变量，所以这里的变量不适合变化，也就是传递的应该是不会发生变化的东西，就比如说我想传入一个全局的Id一样，将所有记录都记录到这个全局Id下。 所以当我们有时候需要传递一些标识或者不可变的东西，又不想自己写对象和构造函数一级级的传递时候，InheritableThreadLocal就是一个非常不错的选择。 多注意积累，非常nice。 与君共勉！！！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.eumji025.com/tags/ThreadLocal/"}]},{"title":"MyBatis分析 - SQL参数绑定【初稿】","slug":"mybatis-paramter-binder","date":"2018-03-08T14:49:12.000Z","updated":"2018-03-13T12:25:39.064Z","comments":true,"path":"2018/03/08/mybatis-paramter-binder/","link":"","permalink":"http://www.eumji025.com/2018/03/08/mybatis-paramter-binder/","excerpt":"","text":"前言相信我们在使用过mybatis多参数查询时，又不使用@param注释的时候，将无法和我们xml中参数绑定的情况，因为mybatis在我们没有使用param注解时候，默认使用的arg0,arg1,param1，param2等名称表示我们的请求参数。今天主要追要追踪一下mybatis到底是怎么进行处理的。 示例先通过一个错误的例子来看一下发生的异常信息。1UserInfo getUserByName(int id,String name); 看一下异常信息，我相信也许还有印象。123Caused by: org.apache.ibatis.binding.BindingException:Parameter 'id' not found. Available parameters are [arg1, arg0, param1, param2] at org.apache.ibatis.binding.MapperMethod$ParamMap.get(MapperMethod.java:202) 分析当然在这里依旧不讲解mybatis的流程了，如果还不是很懂的话最好看一下我之前的文章，大概的了解一下Mybatis的流程，这里就直接简明扼要的进入主题，首先看一下MapperMethod构造过程中做了什么，因为有我们关心的东西。至于为什么知道是MapperMethod有重要东西，其实是我根据代码倒推的。 parameter解析我们直接看一下构造MapperMethod对象的类MapperProxy，在invoke方法就能找到。 12345678910111213public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); //重点 return mapperMethod.execute(sqlSession, args);//后续的重点 &#125; 从cachedMapperMethod方法继续跟进MapperMethod的构造方法，然后继续到MethodSignature构造方法 123456789101112131415161718public MethodSignature(Configuration configuration, Class&lt;?&gt; mapperInterface, Method method) &#123; Type resolvedReturnType = TypeParameterResolver.resolveReturnType(method, mapperInterface); //获取返回类型，根据不同类型设置具体的返回类型 if (resolvedReturnType instanceof Class&lt;?&gt;) &#123; this.returnType = (Class&lt;?&gt;) resolvedReturnType; &#125; else if (resolvedReturnType instanceof ParameterizedType) &#123; this.returnType = (Class&lt;?&gt;) ((ParameterizedType) resolvedReturnType).getRawType(); &#125; else &#123; this.returnType = method.getReturnType(); &#125; this.returnsVoid = void.class.equals(this.returnType); //是否为void this.returnsMany = (configuration.getObjectFactory().isCollection(this.returnType) || this.returnType.isArray());//返回的是否为集合 this.returnsCursor = Cursor.class.equals(this.returnType); //是否返回的为cursor this.mapKey = getMapKey(method); //mapkey注解解析 this.returnsMap = (this.mapKey != null); //获取map this.rowBoundsIndex = getUniqueParamIndex(method, RowBounds.class); this.resultHandlerIndex = getUniqueParamIndex(method, ResultHandler.class); this.paramNameResolver = new ParamNameResolver(configuration, method); //重点 &#125; 这里主要的功能就是包装一些方法对应的参数，包括返回类型，请求参数等信息，我们需要区分不同的返回类型。但是我觉得这里不太好的地方就是没有设置假设为集合的时候，集合里具体的类型是什么，只是记录了返回的类型。 记录这些信息我相信大家都知道是为了后续的使用。 我们现在再看一下ParamNameResolver构造函数的内容，从名字也可以看出来是为了解析请求的参数 12345678910111213141516171819202122232425262728293031323334public ParamNameResolver(Configuration config, Method method) &#123; final Class&lt;?&gt;[] paramTypes = method.getParameterTypes(); final Annotation[][] paramAnnotations = method.getParameterAnnotations();//获取包含的注解 final SortedMap&lt;Integer, String&gt; map = new TreeMap&lt;Integer, String&gt;(); int paramCount = paramAnnotations.length; // get names from @Param annotations for (int paramIndex = 0; paramIndex &lt; paramCount; paramIndex++) &#123; if (isSpecialParameter(paramTypes[paramIndex])) &#123;//跳过rowBonds和resultHandler这样的特殊参数 // skip special parameters continue; &#125; String name = null; for (Annotation annotation : paramAnnotations[paramIndex]) &#123; if (annotation instanceof Param) &#123; hasParamAnnotation = true; name = ((Param) annotation).value(); //param对应的名称 break; &#125; &#125; if (name == null) &#123;//没有注解名称 // @Param was not specified. if (config.isUseActualParamName()) &#123;//如果允许使用默认名称 name = getActualParamName(method, paramIndex);//使用默认的名称arg0，arg1 &#125; if (name == null) &#123;//使用数字下标 // use the parameter index as the name (\"0\", \"1\", ...) // gcode issue #71 name = String.valueOf(map.size()); &#125; &#125; map.put(paramIndex, name);//下表和对应的名称记录下来 &#125; names = Collections.unmodifiableSortedMap(map); &#125; 从上面的代码中可以看出，假如我们并没有使用@param注解，则我们首先会尝试把名称设置为默认的arg0，arg1形式，如果默认的是不被允许的，则我们会设置成为0,1,2下标这样的形式。 MapperMethod的构造到此我们也算是弄明白了，其主要作用把我们的请求和响应的相关信息包装成一个对象，并对请求参数的名称进行了修饰。 接下来我们需要看一下MapperMethod的execute方法干了些什么事情。这里主要介绍一下execute方法里面我们最关心代码 1Object param = method.convertArgsToSqlCommandParam(args); 不管是什么类型的sql语句，都需要执行上面的这段代码。其主要作用我们也可以从名字看出来，将参数和sql具体绑定。 123456789101112131415161718192021222324252627public Object convertArgsToSqlCommandParam(Object[] args) &#123; return paramNameResolver.getNamedParams(args); //之前构造的paramResolver &#125;public Object getNamedParams(Object[] args) &#123; final int paramCount = names.size(); if (args == null || paramCount == 0) &#123;//没有参数直接结束 return null; &#125; else if (!hasParamAnnotation &amp;&amp; paramCount == 1) &#123;//没有注解或者只有一个参数的时候，直接返回第一个 return args[names.firstKey()]; &#125; else &#123; //遍历内容 final Map&lt;String, Object&gt; param = new ParamMap&lt;Object&gt;(); int i = 0; for (Map.Entry&lt;Integer, String&gt; entry : names.entrySet()) &#123; param.put(entry.getValue(), args[entry.getKey()]); //现在把名称设为key，value设置真正的值 // add generic param names (param1, param2, ...) final String genericParamName = GENERIC_NAME_PREFIX + String.valueOf(i + 1); // ensure not to overwrite parameter named with @Param if (!names.containsValue(genericParamName)) &#123;//同时还会尝试以param1，param2为key的方式也设置一份 param.put(genericParamName, args[entry.getKey()]); &#125; i++; &#125; return param; &#125;&#125;&#125; 从上面的可以看出，当我们参数只有一个或者0个的时候就会尝试直接返回，否则的话都会按照之前设置的名称包装成map，并且此处还会设置一份默认的param1，param2这样形式的参数。到此我想我们应该已经明白之前异常为什么会有param0,param1这样的值了。 然后我们省略中间一系列步骤看到DefaultSQLSession的selectList方法，这里会进一步包装我们的请求参数 1return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); 在这里wrapCollection会包装集合类型的参数，其实就是我们只有一个参数的时候可能会需要包装。 123456789101112131415private Object wrapCollection(final Object object) &#123; if (object instanceof Collection) &#123;//如果是集合，首先会默认记录一份key为collution的map StrictMap&lt;Object&gt; map = new StrictMap&lt;Object&gt;(); map.put(\"collection\", object); if (object instanceof List) &#123; map.put(\"list\", object); &#125; return map; &#125; else if (object != null &amp;&amp; object.getClass().isArray()) &#123;//数组记录成key为array的map StrictMap&lt;Object&gt; map = new StrictMap&lt;Object&gt;(); map.put(\"array\", object); return map; &#125; return object; //否则直接返回&#125; 这里主要是针对一个参数且为集合类型或者数组类型的时候包装成map。到此我们已经知道我们的参数会被最终包装成什么样子了。 SqlSource构建前面介绍了参数构建过程，我们现在需要了解一下我们的Sql是怎么构建到MappedStatement中去的，所以我们需要再次回到XMLStatementBuilder的parseStatementNode方法中，看一看sqlSource是如何被构建的。 12345public void parseStatementNode() &#123; ... LanguageDriver langDriver = getLanguageDriver(lang); SqlSource sqlSource = langDriver.createSqlSource(configuration, context, parameterTypeClass); ... 上述的代码中我们省略了很多我们此时不关心的代码，直接看一下我们关心的createSqlSource方法，默认langDriver是XMLLanguageDriver对象。 123456789101112131415public SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType) &#123; XMLScriptBuilder builder = new XMLScriptBuilder(configuration, script, parameterType); return builder.parseScriptNode(); //重点 &#125;public SqlSource parseScriptNode() &#123; List&lt;SqlNode&gt; contents = parseDynamicTags(context); //sql内容 MixedSqlNode rootSqlNode = new MixedSqlNode(contents); //获取根sql SqlSource sqlSource = null; if (isDynamic) &#123;//是不是动态sql sqlSource = new DynamicSqlSource(configuration, rootSqlNode); &#125; else &#123; sqlSource = new RawSqlSource(configuration, rootSqlNode, parameterType);//我们直接看一下普通sql &#125; return sqlSource; &#125; 上述的方法主要是找到我们的根sql，然后根据是否为动态sql选择不同的方法进行初始化、我们此处以普通sql为例子查看一下实现。 12345678public RawSqlSource(Configuration configuration, SqlNode rootSqlNode, Class&lt;?&gt; parameterType) &#123; this(configuration, getSql(configuration, rootSqlNode), parameterType); &#125;public RawSqlSource(Configuration configuration, String sql, Class&lt;?&gt; parameterType) &#123; SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration);//构建sqlSourceBuild Class&lt;?&gt; clazz = parameterType == null ? Object.class : parameterType; //请求参数类型，默认为null sqlSource = sqlSourceParser.parse(sql, clazz, new HashMap&lt;String, Object&gt;()); //关键 &#125; 上述代码中有一个getSql方法，其主要目的是解析我们sql中出现的各种标签，如foreach，if，trims等等的标签类型，不过我们以最简单的方法分析，假设上述的条件都没有继续向下看 123456public SqlSource parse(String originalSql, Class&lt;?&gt; parameterType, Map&lt;String, Object&gt; additionalParameters) &#123; ParameterMappingTokenHandler handler = new ParameterMappingTokenHandler(configuration, parameterType, additionalParameters); GenericTokenParser parser = new GenericTokenParser(\"#&#123;\", \"&#125;\", handler); //替换变量 String sql = parser.parse(originalSql); //将变量替换为？，并记录parameter的信息 return new StaticSqlSource(configuration, sql, handler.getParameterMappings());//这里我们也就知道了sql期待的parameter是什么了。 &#125; 上文还是包装方法，主要的作用就是设置parse的格式是替换#{}为？，并记录其中的参数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public String parse(String text) &#123; if (text == null || text.isEmpty()) &#123; return \"\"; &#125; char[] src = text.toCharArray(); int offset = 0; // search open token int start = text.indexOf(openToken, offset); //找到开始的坐标 if (start == -1) &#123; return text; &#125; final StringBuilder builder = new StringBuilder(); //记录整个sql StringBuilder expression = null; //记录目标表达式 while (start &gt; -1) &#123; if (start &gt; 0 &amp;&amp; src[start - 1] == '\\\\') &#123; // this open token is escaped. remove the backslash and continue. builder.append(src, offset, start - offset - 1).append(openToken); offset = start + openToken.length(); //位置 &#125; else &#123; // found open token. let's search close token. if (expression == null) &#123; expression = new StringBuilder(); &#125; else &#123; expression.setLength(0); &#125; builder.append(src, offset, start - offset); offset = start + openToken.length(); int end = text.indexOf(closeToken, offset); //介绍的下标 while (end &gt; -1) &#123; if (end &gt; offset &amp;&amp; src[end - 1] == '\\\\') &#123; // this close token is escaped. remove the backslash and continue. expression.append(src, offset, end - offset - 1).append(closeToken); //找到一个待匹配的表达式 offset = end + closeToken.length(); end = text.indexOf(closeToken, offset); &#125; else &#123; expression.append(src, offset, end - offset); offset = end + closeToken.length(); break; &#125; &#125; if (end == -1) &#123; // close token was not found. builder.append(src, start, src.length - start); offset = src.length; &#125; else &#123; builder.append(handler.handleToken(expression.toString())); //处理我们变量中的东西 offset = end + closeToken.length(); &#125; &#125; start = text.indexOf(openToken, offset); &#125; if (offset &lt; src.length) &#123; builder.append(src, offset, src.length - offset); &#125; return builder.toString(); &#125; 上文中所做的事情很简单，就是替换#{…}为？，并且记录我们的参数，记录信息到parameter中，详情可以看handler.handleToken方法。 1234public String handleToken(String content) &#123; parameterMappings.add(buildParameterMapping(content)); return \"?\";&#125; buildParameterMapping这里面也比较复杂，在此就不展示和讲解了，其实我们也能想到具体做了什么，根据内容，设置parameter的jdbcType，javaType，等相关信息。这些就是为了和我们之前的paramter进行匹配。 参数匹配上面我们介绍了sqlSource的构建以及方法参数的封装，那么接下来我们就需要看一下两边是怎么匹配的。 我们直接看到baseExecutor中的query方法 12345public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameter); //使用$&#123;&#125;会在这里被匹配 CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); //这里会尝试匹配 return query(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; 上述方法中的getBoundSql方法就会把我们的sql和参数匹配起来，这里只会匹配使用${}包装的不用预编译的sql。我们来追踪一下实现 123456789101112public BoundSql getBoundSql(Object parameterObject) &#123; DynamicContext context = new DynamicContext(configuration, parameterObject); rootSqlNode.apply(context); //此处是关键 SqlSourceBuilder sqlSourceParser = new SqlSourceBuilder(configuration); Class&lt;?&gt; parameterType = parameterObject == null ? Object.class : parameterObject.getClass(); SqlSource sqlSource = sqlSourceParser.parse(context.getSql(), parameterType, context.getBindings()); BoundSql boundSql = sqlSource.getBoundSql(parameterObject); for (Map.Entry&lt;String, Object&gt; entry : context.getBindings().entrySet()) &#123; boundSql.setAdditionalParameter(entry.getKey(), entry.getValue()); &#125; return boundSql;&#125; 我们可以从上文中看到先构建包含parameterObject的上下文，然后把sql进行解析。 12345678 public boolean apply(DynamicContext context) &#123; GenericTokenParser parser = createParser(new BindingTokenParser(context, injectionFilter));//设置解析的parser context.appendSql(parser.parse(text)); //再次回到parse方法 return true; &#125;private GenericTokenParser createParser(TokenHandler handler) &#123; return new GenericTokenParser(\"$&#123;\", \"&#125;\", handler); &#125; 上述中和我们之前构建预编译的sql有点类似，还是回到了进行参数替换的步骤，但是我们这里的替换和之前的使用的不是同一个Handler。此处使用的BindingTokenParser对象。 1234567891011121314@Overridepublic String handleToken(String content) &#123; Object parameter = context.getBindings().get(\"_parameter\"); if (parameter == null) &#123; context.getBindings().put(\"value\", null); &#125; else if (SimpleTypeRegistry.isSimpleType(parameter.getClass())) &#123; context.getBindings().put(\"value\", parameter); &#125; Object value = OgnlCache.getValue(content, context.getBindings());//可以理解为从map找到对应的值 String srtValue = (value == null ? \"\" : String.valueOf(value)); // issue #274 return \"\" instead of \"null\" checkInjection(srtValue); return srtValue;&#125; 所以通过上述的代码也很容易理解了，我们使用${}时候，boundSql时候就会直接替换为对应的值，但是我们使用#{}会被替换成?，等待后面statement的预编译。这里是非常重要的对比，反复体会一下。 然后我们接着看在构建cacheKey时候，会尝试把预编译的参数进行匹配以构成cacheKey。 1234567891011121314151617181920212223242526272829303132333435public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) &#123; if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; CacheKey cacheKey = new CacheKey(); cacheKey.update(ms.getId()); cacheKey.update(rowBounds.getOffset()); cacheKey.update(rowBounds.getLimit()); cacheKey.update(boundSql.getSql()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();//maper中的parameter TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry();//typeHandler // mimic DefaultParameterHandler logic for (ParameterMapping parameterMapping : parameterMappings) &#123; if (parameterMapping.getMode() != ParameterMode.OUT) &#123;//表示是输入的参数 Object value; String propertyName = parameterMapping.getProperty();//获取名称 if (boundSql.hasAdditionalParameter(propertyName)) &#123;//是否已经匹配过 value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123;//判断方法是否有请求参数，没有直接返回 value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject);//构建请求参数的metaObject value = metaObject.getValue(propertyName); //去匹配参数，找不到会抛异常 &#125; cacheKey.update(value); &#125; &#125; if (configuration.getEnvironment() != null) &#123; // issue #176 cacheKey.update(configuration.getEnvironment().getId()); &#125; return cacheKey;&#125; 上文的方法做的事情也很简单，就是匹配我们的参数并更新缓存key，如果匹配不到会直接抛异常，具体实现在metaObject.getValue方法中，此处省略中间步骤直接到MapperMethod的get方法 123456public V get(Object key) &#123; if (!super.containsKey(key)) &#123; throw new BindingException(\"Parameter '\" + key + \"' not found. Available parameters are \" + keySet()); &#125; return super.get(key);&#125; 所以我们平时看到的参数不匹配就是上述的异常信息。当然上述的内容在构建statement的时候还是会再进行一下，跟着代码我们看到simpleExecutor的doQuery方法 1234567891011public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //构建statement stmt = prepareStatement(handler, ms.getStatementLog());//这里就会编译时匹配值 return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125; &#125; 上面主要做的事情就是构造statement对象然后编译sql 1234567private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; Connection connection = getConnection(statementLog); //获取链接 stmt = handler.prepare(connection, transaction.getTimeout()); //预编译 handler.parameterize(stmt); //设置值 return stmt; &#125; 我们就跳过中间的包装层直接看到PreparedStatementHandler的parameterize方法 123456789101112131415161718192021222324252627282930313233343536373839public void parameterize(Statement statement) throws SQLException &#123; parameterHandler.setParameters((PreparedStatement) statement); &#125;//DefaultParameterHandler.setParameters方法public void setParameters(PreparedStatement ps) &#123; ErrorContext.instance().activity(\"setting parameters\").object(mappedStatement.getParameterMap().getId()); List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings(); if (parameterMappings != null) &#123; for (int i = 0; i &lt; parameterMappings.size(); i++) &#123; ParameterMapping parameterMapping = parameterMappings.get(i); if (parameterMapping.getMode() != ParameterMode.OUT) &#123; Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) &#123; // issue #448 ask first for additional params value = boundSql.getAdditionalParameter(propertyName); &#125; else if (parameterObject == null) &#123; value = null; &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123; value = parameterObject; &#125; else &#123; MetaObject metaObject = configuration.newMetaObject(parameterObject); value = metaObject.getValue(propertyName); &#125; TypeHandler typeHandler = parameterMapping.getTypeHandler(); JdbcType jdbcType = parameterMapping.getJdbcType(); if (value == null &amp;&amp; jdbcType == null) &#123; jdbcType = configuration.getJdbcTypeForNull(); &#125; try &#123; typeHandler.setParameter(ps, i + 1, value, jdbcType); //又可以回到自定义typeHandler的设值方法 &#125; catch (TypeException e) &#123; throw new TypeException(\"Could not set parameters for mapping: \" + parameterMapping + \". Cause: \" + e, e); &#125; catch (SQLException e) &#123; throw new TypeException(\"Could not set parameters for mapping: \" + parameterMapping + \". Cause: \" + e, e); &#125; &#125; &#125; &#125; &#125; 上文中的内容和createCacheKey方法中的颇为相似，再次我就不在过多的讲解了。到此我们也基本上走完了mybatis的参数绑定过程。 总结1.通过本文的分析，我们就可以知道mybatis是如何进行xml文件和mapper接口的参数匹配的。 2.我们还知道了#{}和${}参数匹配时候的不同处理。 3.我们还应该知道mybatis默认会把接口中的参数转成param1，param2这样的格式，当然不推荐使用，一点也不直观。 4.我们还要知道当只是一个参数的时候，或者为集合参数会进行不同的处理。 当然本文不是科普文，很多内容和我之前写的文章有关联，需要自己去体会一下。 结语本文只是出自个人阅读mybatis源码的笔记，如果有表述不清晰或者存在错误的地方，欢迎指正。 与君共勉！！！","categories":[{"name":"Mybatis解析专栏","slug":"Mybatis解析专栏","permalink":"http://www.eumji025.com/categories/Mybatis解析专栏/"}],"tags":[{"name":"Mybatis参数","slug":"Mybatis参数","permalink":"http://www.eumji025.com/tags/Mybatis参数/"}]},{"title":"Mybatis分析 - 插件的加载和使用","slug":"mybatis-interceptor-analysis","date":"2018-03-02T12:17:43.000Z","updated":"2018-03-02T12:24:15.444Z","comments":true,"path":"2018/03/02/mybatis-interceptor-analysis/","link":"","permalink":"http://www.eumji025.com/2018/03/02/mybatis-interceptor-analysis/","excerpt":"","text":"前言前面也陆陆续续的介绍了一些mybatis相关的内容，今天介绍一点mybatis里非常有用的拓展功能插件，我们都知道mybatis的pagehelper分页插件，可是有没有想过是怎么实现的呢，大概的我想应该就是在查询之前拦截mybatis的sql加上分页的语句。今天抱着学习的态度一起来探究一下mybatis插件原理。 文档说明在mybatis的官方文档中，有对于插件的使用场景和注意事项。 MyBatis允许你在已映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括： Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 这些类中方法的细节可以通过查看每个方法的签名来发现，或者直接查看 MyBatis 的发行包中的源代码。 假设你想做的不仅仅是监控方法的调用，那么你应该很好的了解正在重写的方法的行为。 因为如果在试图修改或重写已有方法的行为的时候，你很可能在破坏 MyBatis 的核心模块。 这些都是更低层的类和方法，所以使用插件的时候要特别当心。 实现插件本文就依照官网所给的例子实现一个简单输出的插件，纯粹是为了演示开发插件的流程。 要实现插件首先要实现Interceptor接口，并且通过@Intercepts指定是一个插件，然后通过@Signature注解数组指明要拦截的方法信息。 插件类具体可以看下面的示例。 123456789101112131415161718192021222324@Intercepts( &#123; @Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;), @Signature(type = Executor.class, method = \"query\", args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class&#125;), &#125;)public class OutInterceptor implements Interceptor &#123; private static Logger logger = LoggerFactory.getLogger(OutInterceptor.class); @Override public Object intercept(Invocation invocation) throws Throwable &#123;//插件真正的逻辑 logger.info(\"I hand interceptor this query method:&#123;&#125; , and the param is:[&#123;&#125;]\",invocation.getMethod().getName(), Arrays.asList(invocation.getArgs())); return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; //插件包装方法 return Plugin.wrap(target, this); &#125; @Override public void setProperties(Properties properties) &#123;//初始化插件后调用，用于设置一些属性 &#125;&#125; 到目前为止，我们只需要明确intercept方法是插件的关键，我们所有的插件逻辑应该在这里面体现，至于其他的方法后续再去理解。 上面的插件将会拦截在 Executor 实例中对应的 “query” 方法调用， 这里的 Executor 是负责执行低层映射语句的内部对象。 配置然后我们需要在mybatis-conf.xml配置文件中指明插件。 123&lt;plugins&gt; &lt;plugin interceptor=\"com.eumji.date.plugin.OutInterceptor\"&gt;&lt;/plugin&gt;&lt;/plugins&gt; 结果然后运行一个查询的方法就可以看到我的控制台会出现如下的日志输出 12018-02-21 15:36:44.891 |-INFO [main] com.eumji.date.plugin.OutInterceptor [32] -| I hand interceptor this query method:query , and the param is:[[org.apache.ibatis.mapping.MappedStatement@3458eca5, 1, org.apache.ibatis.session.RowBounds@1e0fdb2f, null, -1785846667:3372372170:com.eumji.date.mapper.DateMapper.getUser:0:2147483647:select * from user_info where id = ?:1:SqlSessionFactoryBean, org.apache.ibatis.mapping.BoundSql@56e9a474]] 原理剖析在解析插件之前，我们首先要思考插件是如何被调用的，为什么能被调用的？当然此时我们不一定能想明白，想明白了也就不用看了。。。 首先就讲一下插件是如何被加载的。 插件的加载在我之前的文章中有几处都介绍到了插件，在此我们重新回顾一下插件的加载，具体内容在Configuration类中 1234567891011121314151617181920212223242526272829303132333435public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler;&#125;public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler;&#125;public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler;&#125;public Executor newExecutor(Transaction transaction, ExecutorType executorType) &#123; executorType = executorType == null ? defaultExecutorType : executorType; executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; if (ExecutorType.BATCH == executorType) &#123; executor = new BatchExecutor(this, transaction); &#125; else if (ExecutorType.REUSE == executorType) &#123; executor = new ReuseExecutor(this, transaction); &#125; else &#123; executor = new SimpleExecutor(this, transaction); &#125; if (cacheEnabled) &#123; executor = new CachingExecutor(executor); &#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor;&#125; 和官方文档中描述的一样，mybatis在初始化这几个对应对象的时候都会将对象包装成插件对象。但是我们需要的注意的是，几个方法调用pluginAll方法后为什么可以强转成不同的对象？至于为什么，具体我们从代码一步步入手去看。 ###pluginAll方法 从方法的名称也应该知道，其目的就是为了加载所有的插件。 123456public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target;&#125; 可以看到上文中只是遍历了所有的插件并调用plugin方法，这时候就要回到我们之前写插件的plugin方法了 123public Object plugin(Object target) &#123; return Plugin.wrap(target, this);&#125; Plugin是Mybatis提供给我们的一个JDK动态代理类，用来包装我们的插件，看一下Plugin类具体的逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class Plugin implements InvocationHandler &#123; private Object target; private Interceptor interceptor; private Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap; private Plugin(Object target, Interceptor interceptor, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123; //构造方法 this.target = target; this.interceptor = interceptor; this.signatureMap = signatureMap; &#125; public static Object wrap(Object target, Interceptor interceptor) &#123; Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); //获取插件所有的拦截信息 Class&lt;?&gt; type = target.getClass(); Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); //获取所有的接口 if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); //构造代理对象，记住这几个参数 &#125; return target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; Set&lt;Method&gt; methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &#123;//如果方法匹配则使用插件 return interceptor.intercept(new Invocation(target, method, args)); &#125; return method.invoke(target, args); //不匹配 则使用原来的方法 &#125; catch (Exception e) &#123; throw ExceptionUtil.unwrapThrowable(e); &#125; &#125; private static Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; getSignatureMap(Interceptor interceptor) &#123;//获取插件所有的拦截信息 Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class);//判断插件类是否有@Intercepts注解 // issue #251 if (interceptsAnnotation == null) &#123; throw new PluginException(\"No @Intercepts annotation was found in interceptor \" + interceptor.getClass().getName()); &#125; Signature[] sigs = interceptsAnnotation.value();//获取@Signature注解 Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = new HashMap&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt;(); for (Signature sig : sigs) &#123; Set&lt;Method&gt; methods = signatureMap.get(sig.type()); if (methods == null) &#123; methods = new HashSet&lt;Method&gt;(); signatureMap.put(sig.type(), methods);//记录 &#125; try &#123; Method method = sig.type().getMethod(sig.method(), sig.args()); methods.add(method); //将拦截的方法添加到set中 &#125; catch (NoSuchMethodException e) &#123; throw new PluginException(\"Could not find method on \" + sig.type() + \" named \" + sig.method() + \". Cause: \" + e, e); &#125; &#125; return signatureMap; &#125; private static Class&lt;?&gt;[] getAllInterfaces(Class&lt;?&gt; type, Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap) &#123;//获取所有拦截类实现的接口 Set&lt;Class&lt;?&gt;&gt; interfaces = new HashSet&lt;Class&lt;?&gt;&gt;(); while (type != null) &#123; for (Class&lt;?&gt; c : type.getInterfaces()) &#123; if (signatureMap.containsKey(c)) &#123; interfaces.add(c); &#125; &#125; type = type.getSuperclass(); &#125; return interfaces.toArray(new Class&lt;?&gt;[interfaces.size()]); &#125;&#125; 总结一下Plugin类所做的事情， 1.首先通过wrap方法，生成一个包含目标对象和插件的代理类，其中需要通过注解获取拦截的方法和实现的接口，这就是为什么不同的方法里都可以强转的原因； 2.当被调用的时候则会进行方法判断，如果是要被拦截的方法则调用interceptor的intercept方法，否则执行目标类的方法。 在第二点中我们需要注意一下，假如我调用了intercept方法，然后我还想调用目标对象自己的方法，我们就可以使用Invocation类中proceed方法 123public Object proceed() throws InvocationTargetException, IllegalAccessException &#123; return method.invoke(target, args); //这里的target也可能是代理类&#125; 这个方法的目的就是为了让我还可以继续调用后续的方法。 补充说明不知道大家有没有考虑pluginAll方法执行完后，target是一个什么样子，也就是假如我有三个插件，那么最后一个的target就是前一个插件对象，那么前一个插件对象的target就是再前面一个插件对象，最前面插件对象的target才是真正的目标对象。 所以要理解其中的执行顺序，我们就以A，B，C作为名称进行代理对象调用过程。 C.intercept - &gt; C.proceed -&gt; B.intercept - &gt; B.proceed -&gt; A.intercept - &gt; A.proceed -&gt; target.method -&gt; A 结束 - &gt; B 结束 -&gt; C 结束 这里也用到了设计模式中的责任链模式，举个简单的例子就是在学校或者公司请1个月的假，需要层层的传递。 重要的事重复三遍这个过程一定要理解，非常的重要。假如某一个插件不调用proceed的方法了或者不调用target的对象方法，那么后续的插件就没办法被执行。 这个过程一定要理解，非常的重要。假如某一个插件不调用proceed的方法了或者不调用target的对象方法，那么后续的插件就没办法被执行。 这个过程一定要理解，非常的重要。假如某一个插件不调用proceed的方法了或者不调用target的对象方法，那么后续的插件就没办法被执行。 而且很有可能会破坏mybatis的生态，就以查询的方法为例，假如此时我们使用了插件拦截Executor，而且我们不调用后续的方法，则会造成mybatis无法为我们进行一系列后续操作的问题。 小结本文首先从官网的文档中了解了插件的能力范围和实现插件的方法，然后通过源码追踪的方法了解多插件是如何调用的以及注意事项。 当然本文中只是介绍了Mybatis插件的实现逻辑和简单demo。更强大更高效的插件需要我们自己去充分利用Mybatis的各种配置和特性去进行。 结语本文都是基于个人的观点，如果存在什么不恰当或者纰漏的地方欢迎指正！！！ 与君共勉！！","categories":[{"name":"Mybatis解析专栏","slug":"Mybatis解析专栏","permalink":"http://www.eumji025.com/categories/Mybatis解析专栏/"}],"tags":[{"name":"Mybatis 插件","slug":"Mybatis-插件","permalink":"http://www.eumji025.com/tags/Mybatis-插件/"}]},{"title":"聊聊cglib动态代理的实现","slug":"cglib-proxy-analysis","date":"2018-02-23T02:18:22.000Z","updated":"2018-03-17T02:47:22.771Z","comments":true,"path":"2018/02/23/cglib-proxy-analysis/","link":"","permalink":"http://www.eumji025.com/2018/02/23/cglib-proxy-analysis/","excerpt":"","text":"简介cglib是另外一种动态代理的方法，他和jdk动态代理的实现是有区别的，我们在之前见过jdk动态代理类是必须实现了接口的，而cglib不需要实现接口，但是必须保证类不含有final关键字，否则是无法代理的。本文是从个人不小心遇到的cglib的死循环问题从而展开的分析。 cglib案例下面我们来展示一个cglib的死循环案例。首先是要被代理的类，还是和常规的一样，声明自己的方法就行，但是要确保类和方法没有被final关键字修饰。用final关键字修饰类会直接报异常，但是修饰方法不会抛异常，但是此方法不会被代理，但是不影响其他方法被代理。 12345public class InfoDemo &#123; public void welcome (String person)&#123; System.out.println(\"welcome :\" + person); &#125;&#125; 下面是具体的代理类实现 12345678910111213141516171819202122232425public class CglibInfoProxy implements MethodInterceptor&#123; private Object target; public Object newInstance(Object source)&#123; target = source; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.target.getClass()); enhancer.setCallback(this); return enhancer.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"before method!!!\"); Object value = methodProxy.invoke(o, objects); //Object value = methodProxy.invoke(this.target, objects); //Object value = methodProxy.invokeSuper(o, objects); return value; &#125; public static void main(String[] args) &#123; //System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, \"D:\\\\\\\\classes\"); InfoDemo instance = (InfoDemo) new CglibInfoProxy().newInstance(new InfoDemo()); instance.welcome(\"zhangsan\"); &#125;&#125; 和我们的jdk动态代理看起来十分相似，只是两个类实现的接口不同，并且生成对象的方法也不同。这里非常坑的是invoke方法和invokeSuper的区别，如果是用invoke方法一定要使用被代理的对象也就是上文中的target，而如果调用invokeSuper方法，则一定要使用被代理后的o对象。 上述这个例子就会引发死循环，导致StackOverflowFlow，嘿嘿，学没有，栈溢出的场景 具体为什么会这样，可以先思考一下，后面我们在源码实现中再去讲解。现在我们先看一下运行结果 1234567891011121314151617181920...before method!!!before method!!!before method!!!Exception in thread \"main\" java.lang.StackOverflowError at java.nio.CharBuffer.&lt;init&gt;(CharBuffer.java:281) at java.nio.HeapCharBuffer.&lt;init&gt;(HeapCharBuffer.java:70) at java.nio.CharBuffer.wrap(CharBuffer.java:373) at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:265) at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:125) at java.io.OutputStreamWriter.write(OutputStreamWriter.java:207) at java.io.BufferedWriter.flushBuffer(BufferedWriter.java:129) at java.io.PrintStream.write(PrintStream.java:526) at java.io.PrintStream.print(PrintStream.java:669) at java.io.PrintStream.println(PrintStream.java:806) at com.eumji.proxy.cglib.CglibInfoProxy.intercept(CglibInfoProxy.java:30) at com.eumji.proxy.cglib.InfoDemo$$EnhancerByCGLIB$$870a84d7.welcome(&lt;generated&gt;) at com.eumji.proxy.cglib.InfoDemo$$FastClassByCGLIB$$2e560a7d.invoke(&lt;generated&gt;) at net.sf.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)... 此处只展示部分的效果，具体可以自己试一下。 假如我们换成其余他两条语句将会是正确的输出，具体结果如下 12before method!!!welcome :zhangsan 原理解析要想弄清楚的这到底是怎么回事，首先我们要看一下cglib代理后的类是怎样的，要想生成代理类的文件，我们只需要在我们的main方法中取消掉这句方法的注释 System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, “D:\\\\classes”); 就会在D盘的classes文件下生成对应的代理class文件，需要注意的是生成的代理class是有三个的，我们首先介绍一下我们最关心的InfoDemo代理类，其他的稍后合适的时机在描述其他两个。 InfoDemo反编译代码其实就是将class文件直接拖到IDEA中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class InfoDemo$$EnhancerByCGLIB$$870a84d7 extends InfoDemo implements Factory &#123; private boolean CGLIB$BOUND; private static final ThreadLocal CGLIB$THREAD_CALLBACKS; private static final Callback[] CGLIB$STATIC_CALLBACKS; private MethodInterceptor CGLIB$CALLBACK_0; private static final Method CGLIB$welcome$0$Method; private static final MethodProxy CGLIB$welcome$0$Proxy; private static final Object[] CGLIB$emptyArgs; private static final Method CGLIB$finalize$1$Method; private static final MethodProxy CGLIB$finalize$1$Proxy; private static final Method CGLIB$equals$2$Method; private static final MethodProxy CGLIB$equals$2$Proxy; private static final Method CGLIB$toString$3$Method; private static final MethodProxy CGLIB$toString$3$Proxy; private static final Method CGLIB$hashCode$4$Method; private static final MethodProxy CGLIB$hashCode$4$Proxy; private static final Method CGLIB$clone$5$Method; private static final MethodProxy CGLIB$clone$5$Proxy; static void CGLIB$STATICHOOK1() &#123; CGLIB$THREAD_CALLBACKS = new ThreadLocal(); CGLIB$emptyArgs = new Object[0]; Class var0 = Class.forName(\"com.eumji.proxy.cglib.InfoDemo$$EnhancerByCGLIB$$870a84d7\"); Class var1; Method[] var10000 = ReflectUtils.findMethods(new String[]&#123;\"finalize\", \"()V\", \"equals\", \"(Ljava/lang/Object;)Z\", \"toString\", \"()Ljava/lang/String;\", \"hashCode\", \"()I\", \"clone\", \"()Ljava/lang/Object;\"&#125;, (var1 = Class.forName(\"java.lang.Object\")).getDeclaredMethods()); CGLIB$finalize$1$Method = var10000[0]; CGLIB$finalize$1$Proxy = MethodProxy.create(var1, var0, \"()V\", \"finalize\", \"CGLIB$finalize$1\"); CGLIB$equals$2$Method = var10000[1]; CGLIB$equals$2$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/Object;)Z\", \"equals\", \"CGLIB$equals$2\"); CGLIB$toString$3$Method = var10000[2]; CGLIB$toString$3$Proxy = MethodProxy.create(var1, var0, \"()Ljava/lang/String;\", \"toString\", \"CGLIB$toString$3\"); CGLIB$hashCode$4$Method = var10000[3]; CGLIB$hashCode$4$Proxy = MethodProxy.create(var1, var0, \"()I\", \"hashCode\", \"CGLIB$hashCode$4\"); CGLIB$clone$5$Method = var10000[4]; CGLIB$clone$5$Proxy = MethodProxy.create(var1, var0, \"()Ljava/lang/Object;\", \"clone\", \"CGLIB$clone$5\"); CGLIB$welcome$0$Method = ReflectUtils.findMethods(new String[]&#123;\"welcome\", \"(Ljava/lang/String;)V\"&#125;, (var1 = Class.forName(\"com.eumji.proxy.cglib.InfoDemo\")).getDeclaredMethods())[0]; CGLIB$welcome$0$Proxy = MethodProxy.create(var1, var0, \"(Ljava/lang/String;)V\", \"welcome\", \"CGLIB$welcome$0\"); &#125; final void CGLIB$welcome$0(String var1) &#123; super.welcome(var1); &#125; public final void welcome(String var1) &#123; MethodInterceptor var10000 = this.CGLIB$CALLBACK_0; if (this.CGLIB$CALLBACK_0 == null) &#123; CGLIB$BIND_CALLBACKS(this); var10000 = this.CGLIB$CALLBACK_0; &#125; if (var10000 != null) &#123; var10000.intercept(this, CGLIB$welcome$0$Method, new Object[]&#123;var1&#125;, CGLIB$welcome$0$Proxy); &#125; else &#123; super.welcome(var1); &#125; &#125; ...&#125; 看代码就可以看出来cglib还是很复杂的，现在我们暂且可以看一下我们关心的welcome方法，从上面的代码中可以看到cglib是会为被代理类的方法同时生成两个代理方法的，一个是同名的welcome方法和CGLIB$welcome$0方法 1.CGLIB$welcome$0方法直接调用被代理的方法，也就是啥都没干。 2.welcome方法首先判断有没有设置callback，很明显我们在代码中有设置即为CglibInfoProxy，所以就会调用CglibInfoProxy.intercept方法。 本来想分析一波生成代理类的过程，看了一下有点复杂，暂时就不分析了。。。。 invokeSuper方法前面也提及了invoke和invokeSuper方法稍不注意就会出问题的问题，在这里我们从代码的层面去追踪一下，产生问题的原因。 我们看一下代理类方法invokeSuper的执行流程 123456789public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; this.init(); //初始化fastInfo MethodProxy.FastClassInfo fci = this.fastClassInfo; return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException var4) &#123; throw var4.getTargetException(); &#125;&#125; invokeSuper在这里主要的作用就是初始化fastClassInfo。 init方法1234567891011121314151617private void init() &#123; if (this.fastClassInfo == null) &#123; Object var1 = this.initLock; synchronized(this.initLock) &#123; if (this.fastClassInfo == null) &#123; MethodProxy.CreateInfo ci = this.createInfo; MethodProxy.FastClassInfo fci = new MethodProxy.FastClassInfo(); fci.f1 = helper(ci, ci.c1); fci.f2 = helper(ci, ci.c2); fci.i1 = fci.f1.getIndex(this.sig1); fci.i2 = fci.f2.getIndex(this.sig2); this.fastClassInfo = fci; this.createInfo = null; &#125; &#125; &#125;&#125; 上面的方法主要是加载methodProxy.FastClassInfo。ci是之前就初始化好的，其中c1指的就是被代理的类InfoDemo，c2则是com.eumji.proxy.cglib.InfoDemo$$EnhancerByCGLIB$$efe38465这个代理类。 然后生成对应的f1和f2以及方法的下标i1和i2，i1和i2对应的就是在最前面所说的welcome方法和CGLIB$welcome$0方法，后面代码可以看出。 而f1则是对应InfoDemo$$FastClassByCGLIB$$2e560a7d代理类，f2则对应InfoDemo$$EnhancerByCGLIB$$efe38465$$FastClassByCGLIB$$38345933代理类。这些都可以在生成的代理class中去查看。 当然这里并没有说到底什么生成的，有兴趣的可以自己看一下字节码是怎么生成的。个人没太看懂。 invoke和invokeSuper区别为什么要生成两个代理类f1和f2，我相信你看过之前的方法应该注意到了，在上面我们提及到了invoke方法和invokeSuper方法，我们来对比一下invoke方法和invokeSuper方法的区别 12345public Object invoke(Object obj, Object[] args) throws Throwable &#123; this.init(); MethodProxy.FastClassInfo fci = this.fastClassInfo; return fci.f1.invoke(fci.i1, obj, args);&#125; 我们可以看到invoke使用的是f1.invoke方法，而invokeSuper则是使用f2.invoke方法。 首先看一下f1对应的invoke方法逻辑 1234567891011public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; InfoDemo var10000 = (InfoDemo)var2; int var10001 = var1; try &#123; switch(var10001) &#123; case 0: var10000.welcome((String)var3[0]); return null; ....&#125; 直接调用InfoDemo对象的welcome方法。 所以这也就能解释为什么我们之前会发生循环调用invoke的方法了，因为我们传入的var2是InfoDemo的代理对象，看最前面的代理类代码就可以看出，又会回到invoke方法，造成死循环。 再看一下f2中对应invoke的实现 1234567891011121314public Object invoke(int var1, Object var2, Object[] var3) throws InvocationTargetException &#123; efe38465 var10000 = (efe38465)var2; int var10001 = var1; try &#123; switch(var10001) &#123; .... var10000.CGLIB$finalize$1(); return null; case 16: var10000.CGLIB$welcome$0((String)var3[0]); return null; .... &#125; 因为我们此时我们传入的var2是InfoDemo代理对象，所以最终会调用代理类中的CGLIB$welcome$0方法。 小结只是一次失败的源码分析尝试，不过弄清楚了造成调用死循环的原因，只能说cglib比jdk的动态代理复杂很多，主要体现在生成代码的逻辑和生成的代码上，还有待深入的学习。 而且是有两种invoke方法即invoke和invokeSuper方法，所以使用的时候必须要谨慎。 结语本文出自个人笔记，如有表述不当或者纰漏的地方欢迎指正。 与君共勉！！！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"proxy","slug":"proxy","permalink":"http://www.eumji025.com/tags/proxy/"}]},{"title":"Mybatis分析 - Mapper加载使用分析","slug":"mybatis-mapper-info","date":"2018-02-21T07:01:30.000Z","updated":"2018-03-05T23:43:43.684Z","comments":true,"path":"2018/02/21/mybatis-mapper-info/","link":"","permalink":"http://www.eumji025.com/2018/02/21/mybatis-mapper-info/","excerpt":"","text":"简介本文主要讲述mybatis的mapper加载和使用流程。在之前的配置文件加载分析中我们已经讲解了在mybatis构建sqlSessionFactory的时候就会加载mybatis的配置文件，其中当然包含了mybatis的alias，typeHandler，settings，mapper。但是我们并没有对其深入的去讲解，本文则主要通过细节去了解到底是如何进行mapper实例化。 mapper流程要了解mapper的加载流程，我们首先要明白在mybatis中，mapper到底是如何工作的，本文不再赘述Mybatis的整体加载-执行流程，而则主要细致的讲解mapper相关的内容。 我相信详细学习过mybatis的朋友也许都会熟悉类似这样的操作，当然长时间使用mybatis-spring的整合则可能几乎已经忘记这样写的方法。。。 12DateMapper mapper = sqlSession.getMapper(DateMapper.class);UserInfo user = mapper.getUser(1); 我们可以看到通过sqlSession可以加载一个mapper的代理类，毫无疑问的mybatis肯定是用的动态代理技术。具体是什么情况，我们通过追踪源码来弄清楚把。 为了我们更加的清楚了解getMapper的加载过程，所以这里使用的是mybatis原生的方式，其实整合spring的也很类似，只是入口将不会是上述的代码，而是通过@Autowired注解来加载bean，会先找到MapperFactoryBean，然后调用getObject方法来到和上文相似的代码。 getMapper方法下面我们看一下getMapper方法到底做了什么。 1234567891011121314151617public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return configuration.&lt;T&gt;getMapper(type, this);&#125;public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; return mapperRegistry.getMapper(type, sqlSession); //mapperRegistry加载mybatis配置的时候就已经初始化了，记录mapper&#125;public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123;//mapperRegistry.getMapper final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); //knownMappers记录已经加载了的mapperProxyFactory if (mapperProxyFactory == null) &#123; throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125;&#125; 我相信通过上面的代码都很清楚，首先我们需要从knownMappers中取出MapperProxyFactory，关于knownMappers是何时被初始化的我们稍后再说，然后构造出mapperProxy对象 1234567public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);&#125;protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);&#125; 注意，这里使用了JDK动态代理，生成的是mapperProxy代理对象。 addMapper方法那么我们现在的首要任务就是要找到knownMappers初始化的地方，很容易就在MapperRegistry类中找到addMapper的方法。 123456789101112131415161718public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; //判断是否为接口 if (hasMapper(type)) &#123; //是否已经加载 throw new BindingException(\"Type \" + type + \" is already known to the MapperRegistry.\"); &#125; boolean loadCompleted = false; try &#123; knownMappers.put(type, new MapperProxyFactory&lt;T&gt;(type)); //包装放入 MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); //解析信息 loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125;&#125; 从上文我们就可以看到mapper接口是会被包装成MapperProxyFactory的，里面存放着我们实际的类型。 那么现在肯定要知道addMapper是从哪里被调用的，debug一下就可以发现调用过程如下 在这里说明一下的是本文使用的spring boot + mybatis的环境，所以我们也能到加载其实是从MybatisAutoConfiguration类中创建sqlSessionFactory对象中开始的，这个方法主要还是加载一些配置信息，主要的方法是在buildSqlSessionFactory中构建sqlSessionFactory中，这个方法内容比较多，主要包括加载别名，插件，typeHandler等信息，就是加载mybatis-conf.xml，其中也包括加载mapper。 本文主要在意的是mapper代理相关的内容，其他的就不做介绍了，还是回到上面的方法，看一下buildSqlSessionFactory方法中关于mapper解析的片段 123456789101112131415161718192021if (!isEmpty(this.mapperLocations)) &#123;//mapperLocaltions表示扫描到deep所有mapper.xml for (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), configuration, mapperLocation.toString(), configuration.getSqlFragments()); xmlMapperBuilder.parse(); //解析mapper &#125; catch (Exception e) &#123; throw new NestedIOException(\"Failed to parse mapping resource: '\" + mapperLocation + \"'\", e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; if (LOGGER.isDebugEnabled()) &#123; LOGGER.debug(\"Parsed mapper file: '\" + mapperLocation + \"'\"); &#125; &#125;&#125; 这里面干的最重要的一件事就是解析mapper， parse方法1234567891011public void parse() &#123;if (!configuration.isResourceLoaded(resource)) &#123; configurationElement(parser.evalNode(\"/mapper\")); //加载mapper节点及子节点 configuration.addLoadedResource(resource); bindMapperForNamespace(); //绑定mapper信息&#125;parsePendingResultMaps();parsePendingCacheRefs();parsePendingStatements();&#125; 通过configurationElement方法看一下如何加载mapper下的标签和到底加载了那些内容的， 1234567891011121314151617private void configurationElement(XNode context) &#123; try &#123; String namespace = context.getStringAttribute(\"namespace\"); if (namespace == null || namespace.equals(\"\")) &#123; throw new BuilderException(\"Mapper's namespace cannot be empty\"); &#125; builderAssistant.setCurrentNamespace(namespace); cacheRefElement(context.evalNode(\"cache-ref\")); cacheElement(context.evalNode(\"cache\")); parameterMapElement(context.evalNodes(\"/mapper/parameterMap\")); resultMapElements(context.evalNodes(\"/mapper/resultMap\")); sqlElement(context.evalNodes(\"/mapper/sql\")); buildStatementFromContext(context.evalNodes(\"select|insert|update|delete\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing Mapper XML. Cause: \" + e, e); &#125;&#125; 在我之前的mybatis缓存相关的文章中已经已经提及，具体的细节就不描述了，如果有需要再细看那一部分，主要的目的就是将mapper标签下的所有内容都加载出来，最终通过buildStatementFromContext方法将具体的sql包装成statement对象放在configuration中。 下面具体看一下bindMapperForNamespace方法，通过mapper的命名空间找到对应的mapper接口。 1234567891011121314151617private void bindMapperForNamespace() &#123; String namespace = builderAssistant.getCurrentNamespace(); if (namespace != null) &#123; Class&lt;?&gt; boundType = null; try &#123; boundType = Resources.classForName(namespace); //加载mapper接口 &#125; catch (ClassNotFoundException e) &#123; //ignore, bound type is not required &#125; if (boundType != null) &#123; if (!configuration.hasMapper(boundType)) &#123; configuration.addLoadedResource(\"namespace:\" + namespace); configuration.addMapper(boundType); //就会回到前面说的addMapper方法了 &#125; &#125; &#125;&#125; 在configuration中注册mapper信息和resource信息。从上面可以看到又回到了addMapper方法中了。 parse方法里面的逻辑 。 12345678910111213141516171819202122public void parse() &#123; String resource = type.toString(); if (!configuration.isResourceLoaded(resource)) &#123; //查看是否加载过，和前面用的类型不同哦，所以这里第一次到这里是没有被加载额 loadXmlResource(); configuration.addLoadedResource(resource); assistant.setCurrentNamespace(type.getName()); parseCache(); //加载CacheNamespace注解 parseCacheRef(); //加载CacheNamespaceRef注解 Method[] methods = type.getMethods(); for (Method method : methods) &#123; //遍历所有的方法 try &#123; // issue #237 解决java8中重写方法的问题 if (!method.isBridge()) &#123; parseStatement(method); &#125; &#125; catch (IncompleteElementException e) &#123; configuration.addIncompleteMethod(new MethodResolver(this, method)); &#125; &#125; &#125; parsePendingMethods();&#125; 总结一下上面的逻辑， 1.首先判断是否被加载过，如果没有则加载xml内容，此处用的string类型，和前面的类型不用 2.加载xml内容，以及注解加载，遍历方法判断是否需要 下面看一下loadXmlResource方法 123456789101112131415private void loadXmlResource() &#123; if (!configuration.isResourceLoaded(\"namespace:\" + type.getName())) &#123; //判断是否被加载，前面已经加载过，所以跳过 String xmlResource = type.getName().replace('.', '/') + \".xml\"; InputStream inputStream = null; try &#123; inputStream = Resources.getResourceAsStream(type.getClassLoader(), xmlResource); &#125; catch (IOException e) &#123; // ignore, resource is not required &#125; if (inputStream != null) &#123; XMLMapperBuilder xmlParser = new XMLMapperBuilder(inputStream, assistant.getConfiguration(), xmlResource, configuration.getSqlFragments(), type.getName()); xmlParser.parse(); &#125; &#125;&#125; 执行我们从MapperProxy方法中可以看到，使用了jdk动态代理的技术实现了InvocationHandler接口。也就是说这个类的所有方法都会先调用invoke方法，具体看一下其中做的事情 1234567891011121314public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; //如果是object类的方法直接调用 if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; //是否为默认方法 return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); //从缓存中取，取不到就构建一个 return mapperMethod.execute(sqlSession, args);//否则被代理&#125; 所以此处做的事情就是判断此方法是否要被特殊处理，要过滤object类中的方法，具体的执行还是mapperMethod的execute方法，这里又用到了设计模式中的命令模式，可以自己了解一下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; //获取方法对应mapper中的标签 case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(\"Mapper method '\" + command.getName() + \" attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\"); &#125; return result;&#125; 又回到了我们熟悉的一幕，根据方法对应mapper中的标签名称来确定到底做什么操作，最终执行还是通过sqlSession去执行的， 这里需要注意下的是select方法里的操作，上面的方法根据返回结果的类型不同会执行不同的策略。 总结mapper的加载和使用其实也不是很复杂，都是通过我们在mybatis-conf.xml这个配置文件中指定mapper接口和mapper.xml的位置，或者和spring整合通过spring配置文件指定了位置。然后在初始化的时候通过指定的位置找接口和mapper.xml记录下来，最后我们构造mapper代理对象然后进行我们的操作。 当然本文没有具体分析比如解析mapper.xml中每个具体节点的逻辑，非常多也没有必要，我们现在知道了这些内容是在哪里被加载的，如果我们有需要的话再通过这个入口进行具体的代码分析就可以了。 结语本文出自个人的学习笔记，可能有部分内容表述的不是很清晰或者存在错误的地方，欢迎指正！！ 与君共勉！！！","categories":[{"name":"Mybatis解析专栏","slug":"Mybatis解析专栏","permalink":"http://www.eumji025.com/categories/Mybatis解析专栏/"}],"tags":[{"name":"Mybatis Mapper加载","slug":"Mybatis-Mapper加载","permalink":"http://www.eumji025.com/tags/Mybatis-Mapper加载/"}]},{"title":"Mybatis分析 - 二级缓存","slug":"mybatis-second-cache","date":"2018-02-16T03:29:18.000Z","updated":"2018-03-02T12:35:03.424Z","comments":true,"path":"2018/02/16/mybatis-second-cache/","link":"","permalink":"http://www.eumji025.com/2018/02/16/mybatis-second-cache/","excerpt":"","text":"前言上次通过个人的案例也分析了mybatis一级缓存的实现，今天趁热打铁来看一下mybatis二级缓存的实现原理。 我们都知道mybatis的二级缓存是以mapper为单位。 只需要在mapper.xml中加入如下代码，就可以开启二级缓存。 1&lt;cache eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\"/&gt; cache的相关信息在这里说一下 映射语句文件中的所有 select 语句将会被缓存。 映射语句文件中的所有 insert,update 和 delete 语句会刷新缓存。 缓存方式使用eviction属性设置，默认使用 Least Recently Used(LRU,最近最少使用的)算法来收回。 flushInterval属性表示缓存时间，默认缓存不会以任何时间顺序来刷新。 size属性表示缓存的个数。 readOnly设为true意味着对象检索不是共享的,而且可以安全地被调用者修改,而不干扰其他调用者或线程所做的潜在修改。 这里再说一下回收的策略 LRU – 最近最少使用的:移除最长时间不被使用的对象。 FIFO – 先进先出:按对象进入缓存的顺序来移除它们。 SOFT – 软引用:移除基于垃圾回收器状态和软引用规则的对象。 WEAK – 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。 默认是LRU。 自定义缓存当然我们现有的缓存做的事情是有限的，如果有额外的需要可以选择自定义缓存。在自定义的缓存类中接入第三方缓存框架如ehcache，redis等。 此处就以redis作为缓存载体，写一个简单的demo。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class MybatisRedisCache implements Cache &#123; private static Logger logger = LoggerFactory.getLogger(MybatisRedisCache.class); private volatile RedisTemplate&lt;Object,Object&gt; redisTemplate; private String cacheId; private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); public MybatisRedisCache(String id)&#123; cacheId = id; &#125; @Override public String getId() &#123; return cacheId; &#125; @Override public void putObject(Object key, Object value) &#123; redisTemplate.opsForValue().set(key, value); logger.info(\"save key[&#123;&#125;],value[&#123;&#125;] into redis success\",key,value); &#125; @Override public Object getObject(Object key) &#123; if (redisTemplate == null)&#123; synchronized (MybatisRedisCache.class) &#123; if (redisTemplate == null) &#123; redisTemplate = SpringUtil.getBean(\"redisTemplate\", RedisTemplate.class); &#125; &#125; &#125; Object value = redisTemplate.opsForValue().get(key); logger.info(\"get key[&#123;&#125;] cache from redis is:[&#123;&#125;]\",key,value); return value; &#125; @Override public Object removeObject(Object key) &#123; Object value = redisTemplate.opsForValue().get(key); redisTemplate.delete(key); logger.info(\"remove key[&#123;&#125;] cache from redis success\",key); return value; &#125; @Override public void clear() &#123; redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; redisConnection.flushDb(); return \"ok\"; &#125;); &#125; @Override public int getSize() &#123; return redisTemplate.execute((RedisCallback&lt;Integer&gt;) redisConnection -&gt; Math.toIntExact(redisConnection.dbSize())); &#125; @Override public ReadWriteLock getReadWriteLock() &#123; return readWriteLock; &#125;&#125; 这里是无法直接使用redisTemplate的，因为没法初始化，spring的上下文还问构建完成，所以我们只能选择进行懒加载。顺便说一下这里还要构造一个springUtil专门用来通过上下文和class等信息获取bean的方法，比较简单就不做展示了。 我们只需要在设置cache标签的时候指定type就可以了，就如下图所示 1&lt;cache type=\"com.eumji.mybatis.MybatisRedisCache\"/&gt; 到此我们的实验到这里就算完了。 缓存初始化但是我们还是不知道我们的cache是怎么被初始化的，而且还是带参数的构造函数。我们就需要通过debug找一下。 我相信熟悉流程的朋友应该都知道这里是通过在扫描mapper.xml时，如果发现有cache标签则进行初始化。所以此处我们就直接看cacheElement方法 1234567891011121314private void cacheElement(XNode context) throws Exception &#123; if (context != null) &#123; String type = context.getStringAttribute(\"type\", \"PERPETUAL\"); Class&lt;? extends Cache&gt; typeClass = typeAliasRegistry.resolveAlias(type); String eviction = context.getStringAttribute(\"eviction\", \"LRU\"); Class&lt;? extends Cache&gt; evictionClass = typeAliasRegistry.resolveAlias(eviction); Long flushInterval = context.getLongAttribute(\"flushInterval\"); Integer size = context.getIntAttribute(\"size\"); boolean readWrite = !context.getBooleanAttribute(\"readOnly\", false); boolean blocking = context.getBooleanAttribute(\"blocking\", false); Properties props = context.getChildrenAsProperties(); builderAssistant.useNewCache(typeClass, evictionClass, flushInterval, size, readWrite, blocking, props); &#125;&#125; 我们也可以看出来这里就是加载一些cache的属性，这里都给定了默认值。默认的缓存是PerpetualCache。 我们接着向下面看。 1234567891011121314public Cache useNewCache(Class&lt;? extends Cache&gt; typeClass,Class&lt;? extends Cache&gt; evictionClass,Long flushInterval,Integer size,boolean readWrite,boolean blocking,Properties props) &#123; Cache cache = new CacheBuilder(currentNamespace) .implementation(valueOrDefault(typeClass, PerpetualCache.class)) .addDecorator(valueOrDefault(evictionClass, LruCache.class)) .clearInterval(flushInterval) .size(size) .readWrite(readWrite) .blocking(blocking) .properties(props) .build(); //构建cache configuration.addCache(cache); //将缓存对象添加到configuration currentCache = cache; //所以这里指向的是loggingcache return cache;&#125; 从上文中可以清楚的看出，这里使用了builder模式（网上五花八门的翻译）。前面这些就是设置参数，所以重点还是build方法 12345678910111213141516public Cache build() &#123; setDefaultImplementations(); Cache cache = newBaseCacheInstance(implementation, id); setCacheProperties(cache); // issue #352, do not apply decorators to custom caches if (PerpetualCache.class.equals(cache.getClass())) &#123;//默认的缓存处理 for (Class&lt;? extends Cache&gt; decorator : decorators) &#123; cache = newCacheDecoratorInstance(decorator, cache); setCacheProperties(cache); &#125; cache = setStandardDecorators(cache); &#125; else if (!LoggingCache.class.isAssignableFrom(cache.getClass())) &#123; //其他缓存被包装成LoggingCache型缓存处理 cache = new LoggingCache(cache); &#125; return cache;&#125; 从上文可以看到，build方法又贴心的为我们的参数进行了再一次的检查。。。然后调用newBaseCacheInstance方法创建，创建完成之后会根据缓存的类型进行不一样的处理，我们自定义的缓存最终都会被包装成loggingCache对象。下面具体看一下newBaseCacheInstance方法的实现。 12345678private Cache newBaseCacheInstance(Class&lt;? extends Cache&gt; cacheClass, String id) &#123; Constructor&lt;? extends Cache&gt; cacheConstructor = getBaseCacheConstructor(cacheClass); try &#123; return cacheConstructor.newInstance(id); &#125; catch (Exception e) &#123; throw new CacheException(\"Could not instantiate cache implementation (\" + cacheClass + \"). Cause: \" + e, e); &#125;&#125; 这里做的方法也很简单，通过反射拿到cacheClass类的Constructor对象，然后通过Constructor对象创建具体的实例。从参数看也能知道会调用一个有id参数的构造方法。 然后值得一提的是缓存初始化完成后通过buildStatementFromContext方法，将缓存对应每个方法的select|insert|update|delete信息构建好。为什么要提到这里应该后面有用。然后经过层层调用到addMappedStatement方法，看一下具体的实现。 123456789101112131415161718192021222324252627282930313233343536public MappedStatement addMappedStatement(...) &#123; if (unresolvedCacheRef) &#123; throw new IncompleteElementException(\"Cache-ref not yet resolved\"); &#125; id = applyCurrentNamespace(id, false); boolean isSelect = sqlCommandType == SqlCommandType.SELECT; MappedStatement.Builder statementBuilder = new MappedStatement.Builder(configuration, id, sqlSource, sqlCommandType) .resource(resource) .fetchSize(fetchSize) .timeout(timeout) .statementType(statementType) .keyGenerator(keyGenerator) .keyProperty(keyProperty) .keyColumn(keyColumn) .databaseId(databaseId) .lang(lang) .resultOrdered(resultOrdered) .resultSets(resultSets) .resultMaps(getStatementResultMaps(resultMap, resultType, id)) .resultSetType(resultSetType) .flushCacheRequired(valueOrDefault(flushCache, !isSelect)) .useCache(valueOrDefault(useCache, isSelect)) .cache(currentCache); //设置缓存 ParameterMap statementParameterMap = getStatementParameterMap(parameterMap, parameterType, id); if (statementParameterMap != null) &#123; statementBuilder.parameterMap(statementParameterMap); &#125; MappedStatement statement = statementBuilder.build(); //构建statement configuration.addMappedStatement(statement); return statement; &#125; 这里就是通过mapper中的配置文件，构建一条sql相关信息到statement中，还是build模式。 到此我们已经知道了我们自定义的缓存已经被加载进去了。接下来就到了我们具体使用的场景了。 使用缓存前面介绍了如何将自定义的缓存加载到cnfiguration中去，现在我们将来讲一讲是如何使用缓存的，我们都知道执行器加载都是在构建Sqlsession的时候就会初始化的,并且会在Executor里面包装插件。我想看到mybatis整体流程的都应该很清楚。具体可以看一下configuration.newExecutor方法。 我们还是看一下具体的执行过程query方法 123456789101112131415161718public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); //获取loggingCache if (cache != null) &#123; flushCacheIfRequired(ms); //flushcache检测 if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, parameterObject, boundSql); //暂时忽略 @SuppressWarnings(\"unchecked\") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); //从缓存获取 if (list == null) &#123; list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; 上述方法主要目的就是从缓存读数据，如果没有读到，则直接从数据库中获取并保存到缓存中。 1234567891011public Object getObject(Cache cache, CacheKey key) &#123; return getTransactionalCache(cache).getObject(key);&#125;private TransactionalCache getTransactionalCache(Cache cache) &#123; TransactionalCache txCache = transactionalCaches.get(cache); if (txCache == null) &#123; //如果没有缓存则添加一个 txCache = new TransactionalCache(cache); transactionalCaches.put(cache, txCache); &#125; return txCache;&#125; 然后就继续看TransactionalCache的getObject方法。 12345678910111213public Object getObject(Object key) &#123; // issue #116 Object object = delegate.getObject(key); //因为此处是loggingcache if (object == null) &#123; entriesMissedInCache.add(key); //用于清除无效缓存 &#125; // issue #146 if (clearOnCommit) &#123; return null; &#125; else &#123; return object; &#125; &#125; 继续往下看loggingCache.getObject方法。 1234567891011public Object getObject(Object key) &#123; requests++; final Object value = delegate.getObject(key); //此处就是真正的自定义缓存 if (value != null) &#123; hits++; &#125; if (log.isDebugEnabled()) &#123; log.debug(\"Cache Hit Ratio [\" + getId() + \"]: \" + getHitRatio()); //是否看到了熟悉的缓存日志 &#125; return value; &#125; 到此我们也基本知道了获取缓存的流程，那么加入缓存没有命中，此时就要从数据库中查询，然后保存到缓存中。 123public void putObject(Object key, Object object) &#123; entriesToAddOnCommit.put(key, object); &#125; 可以看到我们的putObject方法并没有直接像redis中进行写操作，而是将其加入到一个map中，这么做是为了后面一起提交。具体操作将会在SqlSession进行commit的方法时候层层调用到Transactionalcache方法。 1234567public void commit() &#123; if (clearOnCommit) &#123;//是否提交时先清空缓存 delegate.clear(); //清空 &#125; flushPendingEntries(); //提交 reset(); //清空&#125; 首先看一下提交的方法，其实非常的简单，就是循环的进行提交。 12345678910private void flushPendingEntries() &#123; for (Map.Entry&lt;Object, Object&gt; entry : entriesToAddOnCommit.entrySet()) &#123; delegate.putObject(entry.getKey(), entry.getValue()); &#125; for (Object entry : entriesMissedInCache) &#123; if (!entriesToAddOnCommit.containsKey(entry)) &#123; //没有命中缓存的也提交 delegate.putObject(entry, null); &#125; &#125;&#125; 然后就是清空数据，没什么难点 12345private void reset() &#123; clearOnCommit = false; entriesToAddOnCommit.clear(); entriesMissedInCache.clear();&#125; 小结本文通过自己实现一个mybatis-redis的二级缓存，然后一步步从加载到使用解析二级缓存的整体流程。通过本文，个人了解了缓存的工作原理以及mapper加载的相关知识点。并且还学了一个非常重要的设计模式 - builer模式。 结语本文纯属个人的实战和源码记录，如果有描述不清楚或者疏漏的地方，欢迎大家指正。 与君共勉！！！","categories":[{"name":"Mybatis解析专栏","slug":"Mybatis解析专栏","permalink":"http://www.eumji025.com/categories/Mybatis解析专栏/"}],"tags":[{"name":"Mybatis缓存","slug":"Mybatis缓存","permalink":"http://www.eumji025.com/tags/Mybatis缓存/"}]},{"title":"独占锁ReentrantLock分析","slug":"reentrantLock-analysis","date":"2018-02-11T11:58:18.000Z","updated":"2018-02-16T03:43:15.461Z","comments":true,"path":"2018/02/11/reentrantLock-analysis/","link":"","permalink":"http://www.eumji025.com/2018/02/11/reentrantLock-analysis/","excerpt":"","text":"前言处理好线程之间的同步问题一直都是开发界的难题,我们最常用的就是synchronized关键字,synchronized常用的就是方法上或者使用synchronized块. 而且synchronized在JDK1.6之后得到了很多性能上的改进,详细文章请参考这篇文章.当时平常我们也鼓励尽量多使用synchronized关键字,因为非常的简单,屏蔽了很多实现上和操作上的细节. 但是我不得不说作为开发人员的我们,如果想要最大化的优化或者灵活的进行控制，还是要对另外一种同步方式要有一定的了解.那就是我们今天所要讨论的重点对象lock 为什么会诞生lock,我想我们也是很容理解的,因为JDK6之前的synchronized关键字不够高效,而且synchronized不够灵活(比如无法使用尝试在规定时间内获取锁)等,所以就诞生了lock. lock改善了很多同步上的性能问题,而且有非常灵活的API. 今天我们就ReentrantLock类（一种独占式的锁）开始我们的话题. ReentrantLockReentrantLock是通过扩展AbstractQueuedSynchronizer进行锁的控制,并包含公平锁和非公平锁，此处说的公平锁和非公平锁的最大区别就体现在尝试获取锁的过程中,非公平锁立即就可以进行尝试获取锁,而公平锁不可以必须按顺序进入等待锁的队列,下面详细通过代码详细介绍一下. 首先看一下我们的代码结构图 从上图我们可以看到ReentrantLock存在三个内部类,请记住这三个内部类,Sysc继承了AbstractQueuedSynchronizer这个类,而NonfairSync和FairSync又继承了Sync类,这两个类分别是非公平和公平锁实现的关键. 下面看一下公平锁和非公平锁如何声明的 1234567//非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 默认情况下我们的声明的都是非公平锁,如果需要声明为公平锁则可以自己通过fair变量来设置. 获取锁下面我们看一下具体的差别 1234567891011//NonfairSync获取lockfinal void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125;//fairSync获取lockfinal void lock() &#123; acquire(1);&#125; 就像我们在上面说的那样,对于非公平锁首先会尝试获取一次锁,如果成功获取锁就设置当前的独占锁为当前线程,并改变状态值为1.否则都进行acquire方法. 下面看一下acquire方法的具体实现 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 这里主要做了几个事情: 1.尝试获取锁或者改变锁的数量,如果操作失败 2.如果没有获取到,则把当前线程加入到等待的链表 3.如果添加成功则设置线程中断状态为true 下面先看一下tryAcquire方法的主要内容,首先看一下非公平锁的实现 123456789101112131415161718192021222324final boolean nonfairTryAcquire(int acquires) &#123; //获取当前你线程 final Thread current = Thread.currentThread(); //获取当前的状态值 int c = getState(); //0代表还未线程抢占没有锁或者说某个线程刚释放锁 if (c == 0) &#123; //尝试获取锁 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程已经获得锁,就是重入锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; //否则就设置为false return false;&#125; 上面介绍了非公平锁的方法,其实实现很简单，首先判断是否当前时刻没有线程获得锁，如果没有则自己尝试获取锁，如果当前已经有线程获得了锁，那么就需要判断获得锁的是不是就是当前线程，如果是的话代表是重入锁，将获得锁的数量加1。 然后我们在看一下公平锁的内部实现有什么不同 12345678910111213protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; ...省略 return false;&#125; 其实公平锁差不多,只是在判断时多加了hasQueuedPredecessors方法判断当前线程是否为列表头,不为列表头且也不是表头的下一个元素，则不能获得了锁。 入队自旋当上面都没有成功的情况下,说明已经有线程获得了锁,那么我们需要把当前的线程加入到等待的队列中.具体的就不赘述了,已经在我的另外一篇文章并发 - AbstractQueuedSynchronizer分析中有讲到底是如何进入等待队列和进行自旋的,本文主要讲述ReentrantLock的相关部分. ### unlock方法 unlock是当前线程释放锁的方法,是通过调用release方法实现的 123456789101112public void unlock() &#123; sync.release(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; //尝试释放锁 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 尝试去释放锁,但是由于有重入锁的特效,所以很有可能一次无法释放所有的锁,这是非常重要和值得关注的点。 tryRelease是由sync类重写的,FairSync和NonfairSync类都没有重写，因为释放的原理都是一样的，下面看一下具体的实现 12345678910111213141516protected final boolean tryRelease(int releases) &#123; //状态值相减，因为有重入锁的情况 int c = getState() - releases; //如果当前线程并没有持有锁,抛异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //等于0,说明完全释放,不然只是释放了一层锁 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; //否则只是更新状态值 setState(c); return free;&#125; 道理很简单就是：判断当前线程获取是否获得了锁,如果是就减去releases个锁,如果状态值为0则表示已释放完,否则没有获得锁的线程调用释放锁的方法会抛出异常. unparkSuccessor也是父类AQS中的方法,主要做的事情就是解锁离head最近的那个正在等待线程.为什么这么说是因为有可能head.next已经取消了。 tryLock下面我们在看一下扩展的方法tryLock，此方法是为了线程漫长等待锁的问题,意在尝试性的获取锁,如果没获取到就退出获取，可以用来做做其他的事情，这样更能调高线程的效率（这里是以非公平锁为例）。 123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 另外tryLock还有带有时间限制的方法，表示在指定时间内进行获取锁的尝试。 123456789public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125;public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 这里带时间尝试的方法是可以中断的,没有中断的情况下首先先去尝试性的获取一次锁,如果不成功,则进行规定时间的轮询政策. 123456789101112131415161718192021222324252627282930313233private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; //超时直接返回 if (nanosTimeout &lt;= 0L) return false; //当前时间+尝试的时间 final long deadline = System.nanoTime() + nanosTimeout; //加入等待队列 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; //拿到锁了,设置信息,返回 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; //超时返回 nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; //失败后的状态处理,中断会抛出异常 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先是尝试去拿锁,如果拿到了直接返回,如果没拿到继续判断尝试的时间是否大于1000L,如果大于这么多就要把对象挂起,如果最终都没有拿到,在finnally中将此节点从同步队列中移除,以失败告终. 另外还有一个带中断获取锁方式lockInterruptibly和带时间的tryLock方法相似. 12345678910public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125;public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg);&#125; doAcquireInterruptibly和doAcquireNanos方法也几乎一样,只是doAcquireInterruptibly方法没有时间的限制,发生中断都会抛出异常. condition方法通过newCondition方法就可以获得一个condition对象,此对象主要是用来点对点的去让一个线程暂停和启用,看一下具体的方法 123456public Condition newCondition() &#123; return sync.newCondition();&#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; 这里先不介绍里面的细节了，有兴趣的可以自己看一下，也可以等我下一篇文章介绍。 小结上面我们介绍了lock和unlock以及lock的扩展方法的实现,本文并没有详细介绍AbstractQueuedSynchronizer相关的内容,因为当初笔者在看的时候就是混在一起看的,还牵涉到condition相关的内容,导致整个人的都看的很晕,分不清楚什么是什么,因此在写本文就将其内容全部分开了,上文中也给出了AbstractQueuedSynchronizer相关的内容的链接地址。我们先了解每一个部分的内容,最终在看ReentrantLock的内容,这样更容易梳理和理解. 再次总结一下本文的内容, 1.首先根据构造函数选择合适的锁方式（公平锁和非公平锁）, 2.然后我们使用lock方法尝试获取锁,如果获取到锁返回 3.假如没有获取到锁,就会被加入到一个等待的同步队列中,等待获取锁 4.当其他持有锁的方法调用signal方法,则就会从队列头部拿到下一个等待的线程,让他持有锁. 5.循环直到所有等待的线程都获得锁. 另外本文还讲述了可中断方式获取锁和指定时间内尝试获取锁，使用这些方法可以防止线程一直等待而不一定获得锁的情况，特别是非公平锁存在插队的情况。 结语本文均出自个人的观点，如果有什么表述错误或者纰漏的地方，欢迎指正。 与君共勉！！！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.eumji025.com/tags/java/"}]},{"title":"Mybatis分析 - 一级缓存","slug":"mybatis-first-cache","date":"2018-02-10T15:30:30.000Z","updated":"2018-03-11T02:26:57.622Z","comments":true,"path":"2018/02/10/mybatis-first-cache/","link":"","permalink":"http://www.eumji025.com/2018/02/10/mybatis-first-cache/","excerpt":"","text":"简介之前在做mybatis的源码总体预览的时候就发现mybatis在执行sql的时候是会进行缓存的，那时候没有具体分析，今天刚好看到讨论缓存的问题，于是也自己重新实验分析了一下，到此总结一波。 同时我相信大家也都知道mybatis有一级和二级缓存，一级缓存是针对SqlSession的，也就是每一个SqlSession都会有自己的一级缓存。二级缓存则是针对此次服务的。 小案例首先来一个一级缓存的案例来实验一下，本文中使用了spring boot + mybatis的方式，这个环境很容易搭建，我们就不一一介绍了，直接上执行的测试代码： 12345678@Testpublic void sqlsessionDemo()&#123; SqlSession sqlSession = sqlSessionTemplate.getSqlSessionFactory().openSession();//defaultSqlSession DateMapper mapper = sqlSession.getMapper(DateMapper.class); UserInfo user = mapper.getUser(1); UserInfo user2 = mapper.getUser(1); System.out.println(user);&#125; 我们不需要配置缓存，因为一级缓存默认是开启的，此时我们执行这个junit测试方法，可以想象一下结果： 12342018-02-08 21:28:12.072 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| ==&gt; Preparing: select * from user_info where id = ?2018-02-08 21:28:12.088 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| ==&gt; Parameters: 1(Integer)2018-02-08 21:28:12.096 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| &lt;== Total: 1UserInfo&#123;id=1, name='zhangsan', birthday=1994-06-18T12:12:12, age=18&#125; 从日志中就可以看出，只查询了一次数据库。产生这样的原因肯定是因为缓存生效了。因为一个他们处于同一个sqlSession中。 解析现在我们从源码的执行上看一下具体是怎么回事。 BaseExecutor执行以查询方法为例，首先看一下BaseExecutor代码上的实现（默认添加的情况下，sqlSession会将executor设置为SimpleExecutor，是BaseExecutor的实现类，目前的代码只涉及到BaseExecutor，所以此处就直接将的是BaseExecutor类的query方法）。 12345678910111213141516171819202122232425262728293031323334public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; //如果配置了flushCacheRequired，则清空缓存 clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; //查询缓存 if (list != null) &#123; //存在就直接拿 handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; //不存在则从数据库中拿 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); //假如LocalCacheScope处于STATEMENT，则清空缓存 if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 clearLocalCache(); &#125; &#125; return list; &#125; 本方法的逻辑其实很简单，主要包括一下几点 1.判断是否配置了flushCache，如果配置了就需要每次都清空缓存（这个配置位于mapper的具体语句中）。 2.如果没开启，则判断是否缓存中存在结果，如存在直接获取，不存在直接从数据库获取，并保存到本地缓存中。 3.最后判断LocalCacheScope的状态确定是否需要清空缓存（mybatis的配置文件中）。 数据库查询然后我们看一下是如何从数据库中获取的情况， 1234567891011121314private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); //占位 try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); //后续暂时就不关注了 &#125; finally &#123; localCache.removeObject(key); //移除占位 &#125; localCache.putObject(key, list); //缓存列表 if (ms.getStatementType() == StatementType.CALLABLE) &#123; //这里我们不关心，没用到callable localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; 首先在进行查询的时候先进行占位，然后查完后移除占位重新设置真正的缓存。 可以看出整体上还是很简单的，接下来我们验证上面另外两种情况下，缓存是否是真的被清除。 flushCache测试首先测试在mapper中加入flushCache参数 123&lt;select id=\"getUser\" flushCache=\"true\" resultType=\"userinfo\"&gt; select * from user_info where id = #&#123;id&#125;&lt;/select&gt; 再次执行我们的测试方法，查看结果如下， 12345672018-02-08 21:50:18.504 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| ==&gt; Preparing: select * from user_info where id = ?2018-02-08 21:50:18.519 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| ==&gt; Parameters: 1(Integer)2018-02-08 21:50:18.528 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| &lt;== Total: 12018-02-08 21:50:18.528 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| ==&gt; Preparing: select * from user_info where id = ?2018-02-08 21:50:18.529 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| ==&gt; Parameters: 1(Integer)2018-02-08 21:50:18.529 |-DEBUG [main] com.eumji.date.mapper.DateMapper.getUser [159] -| &lt;== Total: 1 UserInfo&#123;id=1, name='zhangsan', birthday=1994-06-18T12:12:12, age=18&#125; 可以看出缓存确实失效了，查询了两次。 localCacheScope测试然后我们测试另外一种方式，在mybatis-conf.xml的配置文件中加入如下语句 1&lt;setting name=\"localCacheScope\" value=\"STATEMENT\"/&gt; 结果就会和上面的一样，都会让缓存失效，说明两次请求不是S一个statement。具体可以在simpleExecutor中看出。（因为默认配置下是使用simpleExecutor） 123456789101112@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //打开一个statement stmt = prepareStatement(handler, ms.getStatementLog()); return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); //关闭 &#125;&#125; 每次语句执行都是会新创建一个statement的，所以都验证了上面的观点是正确的。 但是需要知道的但是我们通常情况下我们都是不会用上面的方式来操作mybatis的，因为我们会和spring结合使用。那么我们通常的使用套路则会如下所示： 12345678@Autowiredprivate DateMapper dateMapper;public UserInfo getUserById(int id)&#123; UserInfo userInfo = dateMapper.getUser(id); UserInfo userInfo2 = dateMapper.getUser(id); return userInfo;&#125; 那么猜一下，这样的语句在最初的什么都不配置的情况下会查询几次呢？ 恭喜您，答案就是2次。 不吹不黑，至于为什么是这样呢，刚开始我也觉得不可思议，为什么呢，看起来我们好像是在同一个SqlSession中，但是残酷的事实告诉我不是。。。（我自己开始也忘记了这么回事，哈哈） 具体为什么?我们一起看一看，spring是怎么注入mapper信息的，这里我们就需要使用到MapperRegistry.addMapper方法。 123456789101112131415161718public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; if (hasMapper(type)) &#123; throw new BindingException(\"Type \" + type + \" is already known to the MapperRegistry.\"); &#125; boolean loadCompleted = false; try &#123; knownMappers.put(type, new MapperProxyFactory&lt;T&gt;(type)); MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; knownMappers.remove(type); &#125; &#125; &#125; &#125; 从上述可以看到，addMapper是以class为key，MapperProxyFactory为value记录mapper工厂，而获取mapper则是通过同类中的另外一个方法getMapper。 1234567891011public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); //通过key获取factory if (mapperProxyFactory == null) &#123; throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); //然后构造代理类 &#125; catch (Exception e) &#123; throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); &#125;&#125; getMapper方法通过之前设置的工厂类构造出mapperProxy对象。这里的SqlSession指的是SqlSessionTemplate。并且SqlSessionTemplate初始化的时候还构造了一个sqlSessionProxy代理类指向SqlSessionInterceptor。记住这个类后面有用。 1234567891011121314public SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; notNull(sqlSessionFactory, \"Property 'sqlSessionFactory' is required\"); notNull(executorType, \"Property 'executorType' is required\"); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; this.sqlSessionProxy = (SqlSession) newProxyInstance( SqlSessionFactory.class.getClassLoader(), new Class[] &#123; SqlSession.class &#125;, new SqlSessionInterceptor()); &#125; 至于为什么会加载SqlSessionTemplate，这个问题还需要研究spring的加载过程，这里不细讲了。 我们接着看具体的MapperProxy初始化方法。 123456789public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);&#125;public MapperProxy(SqlSession sqlSession, Class&lt;T&gt; mapperInterface, Map&lt;Method, MapperMethod&gt; methodCache) &#123; this.sqlSession = sqlSession; //所以这里的sqlSession是SqlSessionTemplate this.mapperInterface = mapperInterface; this.methodCache = methodCache;&#125; 到这里我们应该明白了mybatis中mapper代理类的初始化过程了，说这么多就是为了这个SqlSessionTemplate的实例化。 那我们接着看具体的执行过程，因为被代理，所以所有的调用通过都会通过mapperProxy的invoke方法执行。 1234567891011121314151617181920212223@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; ... final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &#125;//根据mapper的方法类型选择合适的执行方法public Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case SELECT: ... else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; break; &#125; ... return result; &#125; 此处省略了很多代码，然根据我们在mapper.xml配置的方法选择合适的语句进行执行，因为我们这里是查询一条，所以应该是执行selectOne方法，但需要注意这里的sqlSession.selectOne是sqlSessionTemplate.selectOne方法，接着看在sqlSessionTemplate中干了什么。 123public &lt;T&gt; T selectOne(String statement, Object parameter) &#123; return this.sqlSessionProxy.&lt;T&gt; selectOne(statement, parameter);&#125; 此处出现了上面我们让记住的sqlSessionProxy，我们上文中提到是指向SqlSessionInterceptor类，所以接下来会到达SqlSessionTemplate内的内部类SqlSessionInterceptor的invoke方法中， 12345678910111213141516public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; SqlSession sqlSession = getSqlSession( SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); Object result = method.invoke(sqlSession, args); //执行方法 ...&#125;public static SqlSession getSqlSession(SqlSessionFactory sessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) &#123; .... session = sessionFactory.openSession(executorType); registerSessionHolder(sessionFactory, executorType, exceptionTranslator, session); return session; &#125; 我们从这里就可以看到这里就会新打开了一个sqlSession，而后面的执行逻辑其实都是通过生成的sqlSession去执行的，所以根本不可能在同一个sqlSession中，也自然使得缓存失效。 当然我们这里省略了很多的逻辑哈，想更加深入的了解还是需要自己去看代码。 总结本文本来打算一级缓存和二级缓存一起讲，但是为了篇幅精简一些所以到此为止。通过本文的分析也算是对于mybatis一级缓存有了更为深刻的理解。 反正个人之前确实没太注意和spring整合的mybatis内部实现，借此机会好好验证了一下自己的想法以及回忆起了mybatis的更多知识点。工作中确实忽略或遗忘了其实现的原理。 当然mybatis中还有很多知识点值得去关注，也许我们平时不一定能用到，但是弄懂了肯定会事半功倍。 本文纯属个人的一些见解，如有存在纰漏和表示不当的地方，欢迎指正 与君共勉！！！！","categories":[{"name":"Mybatis解析专栏","slug":"Mybatis解析专栏","permalink":"http://www.eumji025.com/categories/Mybatis解析专栏/"}],"tags":[{"name":"Mybatis缓存","slug":"Mybatis缓存","permalink":"http://www.eumji025.com/tags/Mybatis缓存/"}]},{"title":"FutureTask源码实现","slug":"futureTask-analysis","date":"2018-02-06T05:23:46.000Z","updated":"2018-02-16T03:43:19.573Z","comments":true,"path":"2018/02/06/futureTask-analysis/","link":"","permalink":"http://www.eumji025.com/2018/02/06/futureTask-analysis/","excerpt":"","text":"简介FutureTask是一种支持取消的异步任务包装类，也就是说FutureTask执行的时候不立即返回结果，自己可以通过异步调用get方法获取结果，也可以中途调用cancel方法取消任务。而且必须要知道的就是FutureTask只是任务的包装类，并不是真正的任务类。 FutureTask实现RunnableFuture接口，而RunnableFuture继承了Runnable, Future接口。 实现下面我们将介绍一下FutureTask的具体实现。 FutureTask状态正是因为FutureTask只是任务执行的包装类，所以他肯定是需要很多的状态来维护任务运行的状态，不然怎么能cancel，get呢，下面我们具体来看一下。 12345678private volatile int state;private static final int NEW = 0; //新建任务的状态private static final int COMPLETING = 1; //我觉得可以称作进行中private static final int NORMAL = 2; //正常执行完毕private static final int EXCEPTIONAL = 3; //发生异常时private static final int CANCELLED = 4; //任务取消private static final int INTERRUPTING = 5; //中断中private static final int INTERRUPTED = 6; //中断完成 根据代码注释中的描述,上述的状态很有可能发生以下四种可能性： 过程 含义 NEW -&gt; COMPLETING -&gt; NORMAL 正常的执行过程，从开始到结束 NEW -&gt; COMPLETING -&gt; EXCEPTIONAL 执行过程中发生了异常 NEW -&gt; CANCELLED 任务被取消 NEW -&gt; INTERRUPTING -&gt; INTERRUPTED 任务被中断 FutureTask构造方法FutureTask的构造方法主要有两个，和我们之前讲线程池的很相似，主要是为了针对不同的任务类型 12345678910public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125;public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 很简单，就是强行把runable包装成callble对象，并且返回值为传入的result。 run方法在FutureTask中有两种执行的方式，run方法和runAndReset方法，先看一下run方法的实现。 1234567891011121314151617181920212223242526272829public void run() &#123; //不是NEW状态的任务无法执行 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset,null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; //再次判断 if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); //执行 ran = true; //正常状态下设置状态为true &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); //发生异常时，状态修改 &#125; if (ran) //正常情况下 set(result); &#125; &#125; finally &#123; runner = null; int s = state; if (s &gt;= INTERRUPTING) //如果是有中断发生 handlePossibleCancellationInterrupt(s); &#125;&#125; 方法的逻辑非常的简单，就三件事情 1.首先就是判断任务是不是可执行的状态，如果不可以那么就结束，否则 2.执行任务，如果发生异常，进行异常状态下的设置，否则正常逻辑状态设置 3.最后在返回前进行状态设置，如果处于中断状态，设置更新状态。 异常处理接下来我们需要看一下异常状态下的处理。 12345678protected void setException(Throwable t) &#123; //尝试设置到COMPLETING状态 if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = t; //设置outcome为异常对象 UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // 最终的状态 finishCompletion(); &#125;&#125; 这里就满足了我们在上面表格中介绍到的异常状态下的状态的变化过程。发生异常后还需要执行finishCompletion方法，finishCompletion的主要目的其实是唤醒所有等待获取结果的线程，所以我们把放在get方法的后面再讲。 正常结束下面我们看一下set方法的干的事情，根据我们之前在表格中的介绍应该很容易才出来。 1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); finishCompletion(); &#125;&#125; set方法逻辑和setException逻辑类似，只是他们设置的最终状态值和outcome值不同而已。就不多说了。 发生中断我们接着看run方法中finally中的方法 12345private void handlePossibleCancellationInterrupt(int s) &#123; if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield();&#125; 这里做的事情很简单，就是假如发生了中断的事件，那么此时就是释放锁，一直重试到状态变成了INTERRUPTED。 runAndReset方法我们再看一下runAndReset方法和run方法的异同。 123456789101112131415161718192021222324protected boolean runAndReset() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset,null, Thread.currentThread())) return false; boolean ran = false; int s = state; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) &#123; try &#123; c.call(); // don't set result ran = true; &#125; catch (Throwable ex) &#123; setException(ex); &#125; &#125; &#125; finally &#123; runner = null; s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; return ran &amp;&amp; s == NEW;&#125; 很容易看出，runAndReset在正常执行结束后是不会更改状态的，这样的话势必会造成正常情况下是无法获取程序的结果的。之所以这么做也是因为任务是要复用的，因为这个方法是用来做周期循环调度的。所以也不会改变状态，也不会设置结果值。具体的体现我们可以再ScheduleThreadPoolExecutor中具体查看。 cancel方法上面我们介绍了中断时的状态的改变，但是我们没介绍到底是怎么产生中断的，接下来我们看一下，先说明一下其实中断和取消的方法是使用同一个方法，只是状态值不同 1234567891011121314151617181920212223public boolean cancel(boolean mayInterruptIfRunning) &#123; //mayInterruptIfRunning true代表中断，false代表取消 //如果是NEW状态又执行了中断或取消，跳过，否则直接结束 if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; //中断的情况，设置线程中断 if (mayInterruptIfRunning) &#123; try &#123; Thread t = runner; if (t != null) t.interrupt(); &#125; finally &#123; // final state UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); &#125; &#125; &#125; finally &#123; finishCompletion(); &#125; return true;&#125; 我们可以看到，cancel同时具有取消和中断两种功能， 1.当我们的任务还是NEW状态，又改变状态成功，这说明任务已经无法执行了，设置线程状态，如果不处于NEW状态，或者修改状态失败则直接结束方法。 2.不满足的情况下就会判断任务是否为中断，如果中断的话就把线程的状态也设置为中断，并改变最终的状态。 3.最终也都要释放等待的线程（具体留在后面说明）。 get方法get方法主要有两种，一种是一直等待，一种是设置超时的时间。 1234567891011121314public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x); &#125; 如果任务的状态还小于COMPLETING，说明任务还没有完成，不管是有没有发生意外的情况。此时都要把获取结果的线程加入到等待结果的链表中，如果是已完成则直接获取结果，很简单就不多描述了。 我们在继续看看带超时时间的get方法 12345678910public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125; 其实抛开awaitDone方法都是一致的，所以我们直接来看一下awaitDone方法。 awaitDone方法1234567891011121314151617181920212223242526272829303132333435363738private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; //如果线程被中断，直接移除 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; //再次检测状态，不满足就直接返回了 if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) //说明马上状态就改变了，那么此时肯定不会入队了，所以让出时间片 Thread.yield(); else if (q == null) //说明还在NEW状态， q = new WaitNode(); else if (!queued) //入队 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); //设置到队列头 else if (timed) &#123; //如果是设置了超时时间的 nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); //移除等待的线程 return state; &#125; LockSupport.parkNanos(this, nanos); //否则挂起指定时间 &#125; else LockSupport.park(this); &#125; &#125; 好，这里的所及还算是比较复杂，在这里我们简单的总结一下 1.判断线程是否有被中断，如果被中断了直接结束等待。否则 2.判断state的状态是否COMPLETING，如果大于说明要么执行完要么出了状况，可以去拿值了。直接返回，如果不满足 3.在判断是否为COMPLETING，也说明该执行的也执行了，现在在修改状态中，马上就可以拿值，所以放弃时间片，等下次来再判断。如果不满足 4.否则没有入队就入队，否则如果是设置超时时间，就判断是否已经超时，超时就移除，否则就把线程挂起指定时间。 说了那么多，很多方法都调用了finishCompletion方法，都需要释放等待结果的线程，接下来我们就一起看看其中的逻辑。 finishCompletion方法其实实现的逻辑还是很简单的， 123456789101112131415161718192021222324private void finishCompletion() &#123; // 处理等待的线程链表 for (WaitNode q; (q = waiters) != null;) &#123; //清除等待线程 if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; //解锁等待的线程 Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t); &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; done(); //留着扩展的，什么都没做 callable = null; // to reduce footprint &#125; 这里的逻辑也是非常简单就是唤醒所有等待的线程，如果还没处理完毕，又会被挂起。 总结本文从run方法，get方法，cancel方法以及他们所涉及到的方法总体上弄清楚了FutureTask的功能。 1.FutureTask只是任务的包装类，真正的执行的逻辑不在其中。 2.一定要弄清楚FutureTask的几种状态值，非常重要。 3.只有NEW状态的任务才能被执行，run方法运行后正常情况下会改变state的值，而runAndReset不会，因为两种方法的场景不同。 4.runAndReset调度任务，发生异常任务就会终止后面的调度。 目前FutureTask主要是用于线程池中，用于异步获取执行结果和线程池的调度上。 最后此文章都是个人的理解并整理，如果存在什么逻辑上的疏漏或者表述不当，欢迎吐槽反馈！！ 与君共勉！！！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.eumji025.com/tags/java/"}]},{"title":"不得不懂的线程池 - ThreadPoolExecutor","slug":"threadPool-analysis","date":"2018-02-01T00:41:37.000Z","updated":"2018-03-02T12:36:20.776Z","comments":true,"path":"2018/02/01/threadPool-analysis/","link":"","permalink":"http://www.eumji025.com/2018/02/01/threadPool-analysis/","excerpt":"","text":"简介线程池的诞生于JDK1.5，主要的目的是解决我们在使用线程的时候通常都是重复的创建和销毁，为了让线程能够得到复用，避免我们重复的创建和销毁，提高我们的效率，降低内存的开销。没错又是Doug Lea大神又搞出了线程池这一强力工具。 我们最熟悉的线程池使用案例应该就是数据库连接池，以及我们任务调度都是会使用线程池的。 Executors用来创建和管理我们具体的ThreadPoolExecutor，这里使用了典型的设计模式 - 工厂模式。ThreadPoolExecutor是真正线程池，继承了AbstractExecutorService类，Java集合类和并发类都大量的使用了抽象类实现部分通用的功能。此处的AbstractExecutorService就实现了ExecutorService部分接口功能。最关键的execute方法交给子类去实现。和集合类的套路基本上是一模一样。 看一下Executors的具体实现。 123456789public static ExecutorService newFixedThreadPool(int var0) &#123; return new ThreadPoolExecutor(var0, var0, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue());&#125;public static ExecutorService newSingleThreadExecutor(ThreadFactory var0) &#123; return new Executors.FinalizableDelegatedExecutorService(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue(), var0));&#125;public static ScheduledExecutorService newScheduledThreadPool(int var0) &#123; return new ScheduledThreadPoolExecutor(var0);&#125; 随便列举了其中的几个例子，这里具体描述一下构造函数的几个参数作用。 1public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler) &#123; corePoolSize =&gt; 指代默认创建的线程数。 maximumPoolSize =&gt; 创建线程的最大数量。 keepAliveTime =&gt; 线程存活时间 unit =&gt; 存活的时间，应该都很熟悉，包含日，时，分，秒等 workQueue =&gt; 存放线程的阻塞队列 threadFactory =&gt; 创建线程的工厂，默认为DefaultThreadFactory，主要是重写ThreadFactory接口的newThread的方法。 handler =&gt; 拒绝策略，主要是指工作任务超过了workQueue的大小后，该执行哪种策略进行处理。主要有一下几种： 1.AbortPolicy =&gt; 默认的策略，直接抛出异常 2.DiscardPolicy =&gt; 放弃被拒绝的任务，其实就是啥也不干 3.DiscardOldestPolicy =&gt; 放弃最老的任务，也就是马上要执行的任务 4.CallerRunsPolicy =&gt; 直接执行被放弃的任务，个人不喜欢，赤裸裸的插队（而且根本就没有拒绝） 上面简单的介绍了线程池的各个参数，现在就看一下到底可以生成哪些线程池。 fixedThreadPoolfixedThreadPool =&gt; 固定大小线程池，一旦创建，数量就不会再改变，如果任务超过线程的数量，就会进入等待的队列,使用的LinkedBlockingQueue就可以认为是无界的队列了因为capacity等于Integer.MAX_VALUE 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 我们简单的测试一下就可以发现其中的功能 1234567891011121314151617static class MyThread extends Thread&#123; @Override public void run() &#123; try &#123; Thread.sleep(500L); System.out.println(Thread.currentThread().getName() +\" running !!!\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;static void fixedThreadPoolTest()&#123; ExecutorService executorService = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 20; i++) &#123; executorService.submit(new MyThread()); &#125;&#125; 执行这个test方法的时候，会发现只会有5种线程名称被打印。说明没有没有获得线程的任务就等待，而且是复用的。后续的例子都将使用MyThread做测试。 cachedThreadPoolnewCachedThreadPool =&gt; 大小不固定，为达到最大值时可以动态生成线程，默认使用的是SynchronousQueue队列，是一种同步队列，指只能存放一个元素，添加了必须被消费了才能再添加。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 下面简单的使用一个例子进行说明。 1234567891011static void cachedThreadPoolTest() throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) &#123; executorService.submit(new MyThread()); &#125; Thread.sleep(1000L); for (int i = 0; i &lt; 20; i++) &#123; executorService.submit(new MyThread()); &#125;&#125; 上面测试的例子将复用前五个线程，并再新建15个线程，结果就不展示了。 singleThreadExecutorsingleThreadExecutor =&gt; 大小固定的且只有一个线程的线程池，可以理解为一个元素的fixedThreadPool。 12345public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 就不进行测试代码的展示了，因为和fixedThreadPool的道理相同,只不过只有一个线程。 scheduledThreadPoolscheduledThreadPool =&gt; 是一种大小不固定的定时任务线程池。使用的DelayedWorkQueue延时队列进行任务记录。DelayedWorkQueue是ScheduledThreadPoolExecutor的内部类 1234public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue());&#125; 下面演示一个简单的例子演示如何。需要注意的是延时任务调用的方法会有点不同。 123456789static void singleThreadScheduledTest()&#123; ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor(); for (int i = 0; i &lt; 2; i++) &#123; //延迟5秒执行,只执行一次 executorService.schedule(new MyThread(),1,TimeUnit.SECONDS); //延迟5秒 执行5个周期执行 //executorService.scheduleAtFixedRate(new MyThread(),5,3, TimeUnit.SECONDS); &#125;&#125; 上面测试里的1代表延时1秒执行，且只执行一次，如果想周期执行，可调用下面注释的方法scheduleAtFixedRate方法，表示第一次延时5秒执行，后面的是以3秒为一个周期的执行。 需要注意的是： 1.不会自动出现停止，除非发生异常或者手动的取消掉。 2.假如执行的周期比线程的执行时间短，则会以延时的任务的执行时间长度为准。 singleThreadScheduledExecutor1234public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1));&#125; 可以看出来singleThreadScheduledExecutor和ScheduledThreadPoolExecutor还是有一定的区别的，singleThreadScheduledExecutor是单独的一个实现类，不过本文不做具体分析。 方法解读上面大概的介绍了线程池中的几种线程池，接下来我们将介绍一下如何其中到底是如何实现的。我们只说一下常规的线程池的执行逻辑。 从上面的代码我们可以看到，各种线程池的不同主要体现在线程的数量范围和使用的workQueue不同。最终都会调用submit方法，首先看一下线程池中几种不同参数的submit方法。 1234567891011121314public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null);&#125;public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result);&#125;public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125; submit方法支持多种类型的任务，最终都会包装成RunnableFuture的task。这里体现了一个重要的设计模式 - 适配器模式，下面看一下详细代码 123456789101112protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125;public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125; 其实目的很简单就是把Runnable最终包装成Callable。 在介绍具体的方法之前，首先我们看一下线程池中几种状态，因为后续会使用到。 12345678910111213141516 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); //最小的负数 private static final int COUNT_BITS = Integer.SIZE - 3; public static final int SIZE = 32;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;//29个1 // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //11100000000000000000000000000000 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;//0 private static final int STOP = 1 &lt;&lt; COUNT_BITS;//100000000000000000000000000000 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;//1000000000000000000000000000000 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;//1100000000000000000000000000000 // c &amp; 29个0 其实就是获取高三位 private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 这是一个非常经典的设计，我们可以看出，我们的低29位都是用来记录任务的。高3位表示状态 RUNNING =&gt; 高3位值是111。 此状态表示可以接受新任务 SHUTDOWN =&gt; 高3位值是000。 此状态不能接受新任务，但会继续已有的任务 STOP =&gt; 高3位值是001。 此状态的线程不接受也不处理任务，并且会中断处理中的任务 TIDYING =&gt; 高3位值是010。 线程池所有的任务都已经终止，并且worker数量为0，即将运行terminated方法 TERMINATED =&gt; 高3位值是011。在TIDYING状态上，已经运行了terminated方法，线程池完全的停止。 上面的这些数字很重要，一定要记住。 接着上面的讲，最终不管是哪种submit的方法，都会交给execute方法去执行真正的逻辑。 1234567891011121314151617181920212223public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //如果还没有超过线程池的线程容量，直接分配线程执行 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //否则判断线程池的状态，如果是正在运行状态，加入到workQueue等待执行 //2018-02-24补充一点：对于 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //再次校验状态，如果线程池不在运行状态，移除任务，并执行拒绝策略。 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //如果没有正在运行的线程，添加一个线程。但是对于我们指定了corePoolSize大小的情况下，基本上很难满足 else if (workerCountOf(recheck) == 0) addWorker(null, false); //直接开启一个线程，因为任务已经在workQueue上了 &#125; //如果workQueue添加失败（添加失败的原因一般都发生在扩容的线程池，详情需要了解synchronousQueue的offer方法），尝试直接起一个worker，用于coreSize和MaxSize不等的情况 else if (!addWorker(command, false)) reject(command);&#125; 简单的概述一下上述代码所做的事情： 1.如果当前的活动的线程小于设置的核心线程数，则直接启动新线程执行任务，否则 2.如果线程池是处于运行状态，尝试把任务加入到等待队列中（注意使用synchronousQueue不会成功），如果执行成功，再次检查线程的运行状态，如果不处于运行状态移除任务并执行拒绝策略，或者如果没有可用的线程就会分配线程， 3.如果第二步进行不成功，则直接尝试分配一个线程处理任务，如果还是失败（很有可能超过了线程的范围），说明线程池已经到极限了和或者是已经关闭了线程池。 补充：（重点小笔记）这里需要注意第二步的设计和cachedTgreadPool之间的矛盾，因为如果我们使用默认的cachedThreadPool，那么使用的是synchronousQueue，这时候我们看他的offer方法的实现123456789101112131415161718public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); return transferer.transfer(e, true, 0) != null;&#125;E transfer(E e, boolean timed, long nanos) &#123; SNode s = null; // constructed/reused as needed int mode = (e == null) ? REQUEST : DATA; //肯定为data for (;;) &#123; SNode h = head; //默认为null if (h == null || h.mode == mode) &#123; // empty or same-mode if (timed &amp;&amp; nanos &lt;= 0) &#123; // 上面设置的time = true，也没有取消 if (h != null &amp;&amp; h.isCancelled()) casHead(h, h.next); // pop cancelled node else //所以始终返回null return null; &#125;&#125; 从上述的方法可以看出，使用offer添加是不会成功的，所以在这里我们使用cachedTgreadPool时候必然会进入到第三步，直接尝试分配一个线程。这也是这里为什么要这么设计的原因 所以自己在自定义cachedTgreadPool时候一定要注意，如果您想自己定义可扩展的线程池，一定要注意容量和使用的queue。默认的不是一种完美解决方式。 接下来需要看一下第一步中的addWorker方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // 线程的状态，running状态的无法进入 //需要注意其中不能添加一个woker的条件。SHUTDOWN状态下且不同时满足firstTask为null，workQueue为空的条件 if (rs &gt;= SHUTDOWN &amp;&amp;! (rs == SHUTDOWN &amp;&amp;firstTask == null &amp;&amp;! workQueue.isEmpty())) return false; //思考能够到达这里的条件 for (;;) &#123; //线程的数量 int wc = workerCountOf(c); //超出了最大容量，或者线程超过规定的数量，失败 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //数量+1，跳出循环 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); if (runStateOf(c) != rs) continue retry; &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; //添加一个worker 里面有玄机，后面介绍 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //再次检查线程池的状态 int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 如果线程已经在运行中， throw new IllegalThreadStateException(); //添加一个worker记录 workers.add(w); int s = workers.size(); //增加最大数量 ，默认为0 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; // 添加成功则启动任务 if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; addWorker方法看起来比较长，其实做的事情非常简单。 1.判断线程池的状态，如果不是正常状态（rs &gt;= SHUTDOWN &amp;&amp;! (rs == SHUTDOWN &amp;&amp;firstTask == null &amp;&amp;! workQueue.isEmpty())）则添加失败，否则进行第二步 2.根据条件判断是否还能在添加线程，可以则workCount加1成功跳出循环，执行worker逻辑，否则重试或者结束。 3.第二步成功，配置Worker，并在此检查线程池的状态，如果没有问题，则设置worker相关信息，并启动线程。 然后我们在来看一下execute方法中的remove方法，我相信remove方法不仅仅是从workQueue移除元素，不然也不会单独写个方法。 12345public boolean remove(Runnable task) &#123; boolean removed = workQueue.remove(task); tryTerminate(); // In case SHUTDOWN and now empty return removed;&#125; 首先从workQueue移除元素，然后尝试关闭线程池。具体逻辑还是在tryTerminate方法中。 12345678910111213141516171819202122232425262728293031323334final void tryTerminate() &#123; for (;;) &#123; int c = ctl.get(); //如果是运行状态，或者已经停止，或者是存于shutdown状态，但是任务没有处理完，都直接结束，也就证明尝试停止失败 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; //如果还有工作的线程，把worker的中断状态设为true，ONLY_ONE表示只中断一个 if (workerCountOf(c) != 0) &#123; // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; &#125; //没有工作的线程了真的药停止了 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //设置为TIDYING状态 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; //留给子类扩展的 terminated(); &#125; finally &#123; //最终设置为TERMINATED状态 ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); &#125; return; &#125; &#125; finally &#123; mainLock.unlock(); &#125; &#125; &#125; tryTerminate是任何从workerQueue移除任务都会调用的方法，用来判断当前线程池是否已经没有活着的线程了，如果没有了就关闭线程池。 再次回到execute方法中，reject方法就是调用拒绝策略中的rejectedExecution方法，默认的AbortPolicy就是抛个异常仅此而已。 后面也只是一些相同的方法就不再多介绍了，最重要的还是条件判断。 shutdown方法在看一下线程池的shutdown相关的方法。 主要包含三个方法： 1.shutdown方法 =&gt; 将线程池的状态设置为shutdown状态 2.shutdownNow方法 =&gt; 直接停止线程池。 3.isShutdown方法 =&gt; 判断当前线程池的状态是否不是running状态 下面跟随着源码分别看看这几个方法的详情。 123456public boolean isShutdown() &#123; return ! isRunning(ctl.get());&#125;private static boolean isRunning(int c) &#123; return c &lt; SHUTDOWN;&#125; isShutdown方法还是老套路，直接判断是否小于SHUTDOWN状态就可以判断是否为Running状态。 12345678910111213public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); //检查权限， advanceRunState(SHUTDOWN); //设置为SHUTDOWN状态 interruptIdleWorkers(); //中断等待任务的线程 onShutdown(); // 空方法，为ScheduledThreadPoolExecutor留的方法 &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); //尝试关闭线程池&#125; shutdown方法是将线程池的状态设置为SHUTDOWN,并且设置线程的中断状态，注意这里的中断只会中断在等待中的线程（没有上锁的线程）。比较简单里面的详情就不展示出来了。 123456789101112131415public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(STOP); //设置为STOP状态 interruptWorkers(); //中断所有运行中的且没有被设置中断标志的线程 tasks = drainQueue(); //获取等待中的任务列表 &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125; shutdownNow方法和上面的shutdown方法很相似，只是不同的是，shutdownNow更彻底，直接将线程池的状态设置为STOP，并且会移除有所有的等待中的task，而且这里设置的是所有运行中线程的中断状态。下面看一下drainQueue方法 12345678910111213private List&lt;Runnable&gt; drainQueue() &#123; BlockingQueue&lt;Runnable&gt; q = workQueue; ArrayList&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); q.drainTo(taskList);//将workQueue的对象转移到taskList（会清空q里的元素） if (!q.isEmpty()) &#123; //如果q还有新offer的元素 for (Runnable r : q.toArray(new Runnable[0])) &#123; if (q.remove(r)) taskList.add(r); //添加到taskList中 &#125; &#125; return taskList;&#125; 主要做的事情就是从workQueue中获取所有的任务放到taskList中，并从workQueue中删除。 补充前面我们了解线程是如何执行任务和关闭线程池的方法，但是我们需要思考这样一个场景，就是当我们有任务被放在workQueue里的时候，上述的方法并没有讲述这样的情况下是如何执行的，这里需要介绍一下其中的逻辑。这时候就可以看一下留在addWorker的玄机了。。。 123456 private final class Worker extends AbstractQueuedSynchronizer implements RunnableWorker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this);&#125; 可以从构造函数看出，thread对象其实指向的就是当前的worker，所以addWorker方法后面的thread.start就会调用worker.run方法。还有一点值得注意的是Worker继承了AbstractQueuedSynchronizer，下面详细看一下run方法中的实现 12345678910111213141516171819202122232425262728293031323334353637383940414243public void run() &#123; runWorker(this);&#125;final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; //取出worker中的任务 w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; //获取任务， while (task != null || (task = getTask()) != null) &#123; w.lock(); //如果线程池停止了，当前 线程没有终端，将当前线程设为中断状态 if ((runStateAtLeast(ctl.get(), STOP) ||(Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; //空方法，留给子类的 beforeExecute(wt, task); Throwable thrown = null; try &#123; //执行task的逻辑 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 从上面的方法可以看出，worker的run方法主要做了几件事。 1.循环获取任务，并执行，发生异常则抛出异常 2.如果没有问题最终关闭worker。 首先看一下getTask方法是如何操作的。 123456789101112131415161718192021222324252627282930313233343536373839private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //检查队列是否为空，或者线程池是否处理关闭状态 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; //递减worker的数量 decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // 判断是否已经设置超时 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //线程超过了最大数量或者超时，说明不可用了，干掉 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //获取任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; //否则获取任务超时 timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 上述获取任务的方法还是比较复杂的，特别是状态的判断，简单的总结一下： 1.如果线程池的状态是STOP或者工作的队列为空，循环去一个一个的减少worker的数量，此处只是减少数量。并没有结束里面的worker。 2.如果不满足第一条，开始校验是否设置了超时关闭线程或者说线程数超过了设置的值。这时候判断去判断线程1.是否超过了线程数的最大值或者满足了超时的条件 2.线程数大于1或者已经没有待处理的工作了。满足这些条件就去掉一个worker 3.如果2也没有满足，就尝试获取task，获取到了就返回，否则就设置timeOut为true，说明取task失败了。 上面介绍了如何获取任务和管理worker的getTask方法，下面我们在看一下任务执行完后的processWorkerExit方法。 12345678910111213141516171819202122232425262728293031private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; //如果completedAbruptly为true就减少worker的数量，产生于runWorker发生异常。 if (completedAbruptly) decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; //删除这个worker workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; //完成任务了就尝试关闭线程池 tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; //判断有没有设置超时 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; //判断还有没有线程可以工作 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; //执行addworker addWorker(null, false); &#125;&#125; 上述的方法主要是worker进行退出，主要做的几件事如下 1.判断是否正常的结束，如果不是就要删减worker。 2.记录完成任务的数量并移除worker。 3.尝试关闭线程池，然后判断线程池的状态，如果还没有处于停止的状态，继续判断是不是正常的结束，如果是的话去检查线程池里线程的状态，如果正常就结束，如果不满足最好都添加一个worker。 总结1.本文首先介绍了线程池的几种类型的线程池，从代码都可以看到其实共用用的同一个构造方法，不同的只是参数的不用。 2.分析了线程池的几种状态，这里是比较重要的，特别是高三位表示状态，低29位表示线程数。 3.分析了submit和execute方法，通过corePoolSize，maximumPoolSize，workQueue来判断新任务是新启一个线程还是加入到workQueue中，或是执行拒绝策略。 4.分析了shutdown相关的方法逻辑 5.分析了worker到底是如何工作的，这里主要是对内部类worker的run及其涉及的方法进行解读。 本篇只是个人看源码的一些观点，如果存在不清晰或者表述错误的观点欢迎大家反馈。 与君共勉！！！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.eumji025.com/tags/java/"}]},{"title":"MyBatis专栏 - 总体流程回顾","slug":"mybatis-epitome","date":"2018-01-21T01:35:17.000Z","updated":"2018-03-11T02:31:05.769Z","comments":true,"path":"2018/01/21/mybatis-epitome/","link":"","permalink":"http://www.eumji025.com/2018/01/21/mybatis-epitome/","excerpt":"","text":"前言长期都是用Spring+Mybatis整合的方式操作，使得我们都脱离了MyBatis的实现细节，很多东西都不一定能接触到或者去思考。最近也因为SQL的原因重新看了一下MyBatis的源码。由于之前也看过没写笔记忘得也比较快，所以这次再看的时候记录一下看MyBatis源码的心得。 总体流程首先我们回顾一下MyBatis执行流程，建议在此之前先阅读一下mybatis官方文档-快速入门。 构建SqlSessionFactory对象并读取配置文件（myBatis-conf.xml）解析成ConfiguratimyBatis-conf.xmlon对象； SQLSessionFactory创建sqlSession，可以指定提交方式（是否自动提交），执行器类型（个人关注的东西），数据隔离等级等信息 sqlSession执行具体的CURD语句。 前两步属于构建环境，第三步则是拿到可用的sqlSession执行我们具体的sql。当然第三步我们可以再拆解一下就可以得到以下内容： SqlSession的具体的方法包装和转换，如insert，delete方法都转换成update方法，并使用Executor对象执行； 缓存相关的处理，如是否要从缓存中获取，不命中从数据库查询更新缓存等操作（一级缓存和二级缓存）； paramter处理，statement准备以及sql执行等操作； 执行后resultHandler的结果处理，映射等。 案例演示也许上面的说明无法勾起回忆，那么直接看看我们以前的测试代码也许更明了。123456789101112InputStream resourceAsStream = LocalDemo.class.getClassLoader().getResourceAsStream(\"mybatis-conf.xml\"); SqlSessionFactory build = new SqlSessionFactoryBuilder().build(resourceAsStream); SqlSession sqlSession = build.openSession(false); User user = new User(\"zhangsan\",10); int count = sqlSession.insert(\"com.eumji.mybatis.mapper.UserMapper.insertUser\", user); if (count &gt; 0 )&#123; System.out.println(\"ok\"); sqlSession.commit(); &#125;&#125; 我们就以上面这个方法为例结合之前的总结的步骤去追溯一下整个流程。但是本文不会详细介绍，每一个步骤都只会点到为止，目的就是理清大致流程。 SqlSessionFactory和configuration加载123456789101112131415161718public SqlSessionFactory build(InputStream inputStream) &#123; return build(inputStream, null, null);&#125;public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; try &#123; XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);//xmlParser用来解析xml return build(parser.parse()); //通过configuration构建sqlSessionFactory &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; inputStream.close(); &#125; catch (IOException e) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125;&#125; 上面的这一段代码主要做的事情就是：1.从mybatis-conf.xml中加载所有的配置2.构建SQLSessionFactory对象 首先看一下parse方法是如何加载的 123456789101112131415161718192021222324252627282930public Configuration parse() &#123; if (parsed) &#123; throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); &#125; parsed = true; parseConfiguration(parser.evalNode(\"/configuration\")); //从configuration开始解析 return configuration;&#125;//详细内容的解析private void parseConfiguration(XNode root) &#123; try &#123; //issue #117 read properties first propertiesElement(root.evalNode(\"properties\")); Properties settings = settingsAsProperties(root.evalNode(\"settings\")); loadCustomVfs(settings); typeAliasesElement(root.evalNode(\"typeAliases\")); pluginElement(root.evalNode(\"plugins\")); objectFactoryElement(root.evalNode(\"objectFactory\")); objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); reflectorFactoryElement(root.evalNode(\"reflectorFactory\")); settingsElement(settings); // read it after objectFactory and objectWrapperFactory issue #631 environmentsElement(root.evalNode(\"environments\")); databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); typeHandlerElement(root.evalNode(\"typeHandlers\")); mapperElement(root.evalNode(\"mappers\")); &#125; catch (Exception e) &#123; throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); &#125;&#125; 通过上述代码了解到配置文件被加载的信息，根据每个标签然后再具体的加载对应的子标签，在此我们就不详细介绍，知道配置是在这里被加载就OK了，后续我们需要具体了解某个标签时候再看实现。 然后我们接着看Build方法构建sqlSessionFactory对象。 123public SqlSessionFactory build(Configuration config)&#123; return new DefaultSqlSessionFactory(config); &#125; SqlSessionFactory有两个实现类DefaultSqlSessionFactory和SqlSessionManager，不过到目前为止都还只用了DefaultSqlSessionFactory。 sqlSession加载上面介绍到了配置的加载和sqlSessionFactory的构建，接下来就是SqlSession的创建了。 123456789101112131415161718public SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false);&#125;private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);//创建事务工厂 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);//初始化事务 final Executor executor = configuration.newExecutor(tx, execType); //创建执行器 return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 从上面的方法中可以看到，openSession方法主要做了这样几件事1.加载事务工厂；2.加载执行器，用来后续执行sql的重要组件；3.根据上述条件创建sqlSession对象。默认不指定情况下Executor的时候，Mybatis将默认使用simpleExecutor来作为执行器，我们后续也是以simpleExecutor进行分析的。 sqlSession执行前面已经打开了sqlSession，就等同于一个connector，那么接下来就是真正的执行了，我们以查询为例来看一下具体的使用流程。 123456789101112131415public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement);//加载sql信息 return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);//包装sql并执行 &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125;public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameter); //sql绑定参数 CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); //缓存key构建 return query(ms, parameter, rowBounds, resultHandler, key, boundSql);&#125; 上面就是执行操作前的一系列参数包装和条件的构建。继续向下看 12345678910111213141516171819202122public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity(\"executing a query\").object(ms.getId()); if (closed) &#123; throw new ExecutorException(\"Executor was closed.\"); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); //是否情况缓存 &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; //读缓存 if (list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); //存在直接处理 &#125; else &#123;//从数据库查询 list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; return list;&#125; 这个方法也不是真正执行的方法，主要就是判断是否能从缓存中拿，如果拿到的话就直接返回了，否则从数据库中查询。当然这里的缓存和配置有关系，具体的我会在另外一篇文章详细讲解缓存的问题。再接着看从数据库查询数据的操作。 1234567891011121314private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123;//callable有额外的缓存 localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; 依旧是包装方法，用于添加缓存的。逻辑继续延伸到doQuery方法中。这个方法是需要子类实现的，我们就以最常用的simpleExecutor为例查看一下实现。 1234567891011public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); //构造statement，注意会加载插件 stmt = prepareStatement(handler, ms.getStatementLog()); //编译statement return handler.&lt;E&gt;query(stmt, resultHandler); //执行 &#125; finally &#123; closeStatement(stmt); &#125;&#125; 这里是创建真正处理的statement，然后编译，最后通过statementHandler执行。 12345public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; String sql = boundSql.getSql(); //获取sql statement.execute(sql);//执行语句 return resultSetHandler.&lt;E&gt;handleResultSets(statement); //包装结果&#125; 所以最终发现执行还是通过statement的去操作的，Executor也只是一个中间的包装类，做了一些缓存，statement处理的操作。但是需要注意的是不同类型的执行器最终构造的statement是有区别的。执行后会交给resultHandler去进行结果的映射和包装。 123456789101112131415161718192021public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity(\"handling results\").object(mappedStatement.getId()); final List&lt;Object&gt; multipleResults = new ArrayList&lt;Object&gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); //包装resultSet List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); //处理结果 rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; ... return collapseSingleResultList(multipleResults);&#125; 其实结果处理和映射是非常复杂的一个过程，在这里我们只需要知道处理的地方就可以了。整体的流程就是这个样子，本文没有细说任何一个细节，后面我会根据每个部分进行详细的分析。 参考文档Mybatis思维导图 Mybatis官方文档 结语通过本文回顾了Mybatis的总体加载和执行流程，结合Mybatis的官方文档。能让我们快速回忆起之前学习过的Mybatis相关执行，并通过源码追踪了相关信息，当然其中有非常多有待深入去学习和理解的细节。 与君共勉！！！","categories":[{"name":"Mybatis解析专栏","slug":"Mybatis解析专栏","permalink":"http://www.eumji025.com/categories/Mybatis解析专栏/"}],"tags":[{"name":"Mybatis概括","slug":"Mybatis概括","permalink":"http://www.eumji025.com/tags/Mybatis概括/"}]},{"title":"AbstractQueuedSynchronizer源码分析","slug":"AbstractQueuedSynchronizer-analysis","date":"2018-01-18T13:56:36.000Z","updated":"2018-02-16T03:43:22.161Z","comments":true,"path":"2018/01/18/AbstractQueuedSynchronizer-analysis/","link":"","permalink":"http://www.eumji025.com/2018/01/18/AbstractQueuedSynchronizer-analysis/","excerpt":"","text":"AQS简介AbstractQueuedSynchronizer是一个基于first-in-first-out (FIFO)队列实现阻塞锁和同步器功能的框架。简称AQS,此类的设计目标是成为依靠单个原子 int 值来表示状态。子类必须定义更改此状态的方法（如tryReleaseShared），并定义哪种状态对于此对象意味着被获取或被释放。 我们首先看一下AQS类中FIFO队列的真实面貌 12345678910111213static final class Node &#123; static final AbstractQueuedSynchronizer.Node SHARED = new AbstractQueuedSynchronizer.Node(); static final AbstractQueuedSynchronizer.Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile AbstractQueuedSynchronizer.Node prev; volatile AbstractQueuedSynchronizer.Node next; volatile Thread thread; AbstractQueuedSynchronizer.Node nextWaiter;&#125; 可以看出其实就是一个双向队列，应该是非常容易理解的。在这个对象里面设置了好几种状态值，这主要用于设置锁的状态值。 CANCELLED =&gt; 取消状态 SIGNAL =&gt; 等待触发状态 CONDITION =&gt; 等待条件状态 PROPAGATE =&gt; 状态需要向后传播 后面具体在介绍其中的含义，不过我倒是觉得这几个状态值应该自己用个枚举维护会更好。。。 而SHARED对象是用于共享锁如(CountDownLatch),EXCLUSIVE则是用于独占锁(ReentrantLock) 方法原理本文将从独占式和非独占是锁两部分分别讲述一下AQS的工作原理。 独占式锁首先介绍一下acquire方法，此方法是以独占模式获取对象，忽略中断。tryAcquire方法尝试获取锁，需要子类自己实现。 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 这里主要是三个步骤： 1.首先直接先尝试获取锁(tryAcquire)，如果获取到就结束了，如果获取不到;2.则会将这个线程加入到等待队列(addWaiter(Node.EXCLUSIVE), arg));3.进行自旋，尝试获取锁(acquireQueued)。这也是和synchronized方法不同的地方。 当获取失败的时候就需要将线程加入到等待的队列中，看一下addWaiter方法的具体实现。 1234567891011121314151617private Node addWaiter(Node mode) &#123; //将当前线程包装成一个节点 Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 如果存在等待的队列，直接加入到队尾 if (pred != null) &#123; node.prev = pred; //使用CAS方式设置tail节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //不存在的时候创建队列 enq(node); return node;&#125; 这里总共做了三件事情 1.首先把当前对象包装成一个node 2.判断等待队列是否为空，如果等待队列已经存在，直接添加到队列末尾 3.如果为空的话，需要尝试新建一个等待队列 为什么说是尝试新建队列，下面看一下具体enq方法的实现就能知道 12345678910111213141516private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; //初始化队列头 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //如果已经初始化了就添加到队尾 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 此处为什么要这么设计，因为AQS的方法都是没有加锁的，所以很有可能进入enq方法的时候别的线程初始化过等待队列了。所以此处也是用CAS操作，都是为了防止发生错误的可能性。关于CAS的详细介绍，可以自己查阅相关的资料。 上面介绍完加入队列后，下面就要看一下acquireQueued方法的实现了，大概也能猜到是怎么进行自旋的。 123456789101112131415161718192021222324final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //获取node的前一个元素，满足条件就直接设置为新的队头，p就要被干掉 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //如果不满足条件，就需要把线程挂起并检查中断状态 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; //如果最终都没有找到合适的，取消等待的节点 if (failed) cancelAcquire(node); &#125;&#125; 上面的方法是线程自旋获取锁的方法,主要做了一下几件事情 1.首先检查当前节点是否为head的下一个节点,如果是=&gt;第二步,否则=&gt;第三步2.尝试获取锁,如果获取失败则可能被别人插队了…则进行第三步,如果成功将当前线程设置为头节点,返回3.如果没有获得锁,则挂起当前线程并检查中断状态,此状态主要用于wait方法 此处节点会一直检查当前是否为下一个被唤醒的位置。如果没有到就会检测中间元素是否已经被取消，如果取消了就去除中间这个节点。 具体看一下实现shouldParkAfterFailedAcquire和parkAndCheckInterrupt方法的实现 1234567891011121314151617181920212223private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取前面节点的状态值 int ws = pred.waitStatus; //表示等待被唤醒，直接返回 if (ws == Node.SIGNAL) return true; //大于0代表CANCELLED状态，将会被取消，此处就会移除节点， if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //否则设置为SIGNAL状态，表示等待被唤醒，获取锁 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;//真正的挂起锁，并检测是否被中断了private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 此处就是使用到了文章开始所说的那几个状态值， 1.当node前一个节点的状态值为SIGNAL，表示这个节点是可以等待锁的。 2.如果不满足ws&gt;0，表示前一个节点已经被取消，则干掉取消的节点。（他只管在他前面的那个节点，至于更前面的，就交给前面节点的线程去检测了） 3.否则就把pred的状态设置为SIGNAL。 最后如果失败了，会执行finally中的cancelAquire方法,先用一张图来看一下（来自百度） 1234567891011121314151617181920212223242526272829303132private void cancelAcquire(Node node) &#123; if (node == null) return; node.thread = null; Node pred = node.prev; //清除节点前面的已经取消的节点 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; Node predNext = pred.next; node.waitStatus = Node.CANCELLED; //如果节点在末尾，直接将前一个不为cancel的节点设置为末尾节点 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; //前节点不是队头，并且是等待的状态，设置连接的状态 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; //pred.next的pred =&gt; node.pred if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; //否则就是获得锁 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 在自旋中发生意外进入到finally的取消方法，其中的主要逻辑再次梳理一下： 1.如果当前的节点是空的，直接返回 2.如果上一个节点被取消，改变节点的连接状态，如果当前元素是tail，尝试将pred的下一个节点设置为null 3.如果不是tail元素，当前元素也不是head，将pred.next设置为node.next 4.否则帮助一下个元素获取锁(处于队列头了)。 具体看一下我们的unparkSuccessor方法 12345678910111213141516171819private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; //如果node小于0 设置为0，为什么有这一步？ if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; //如果当前节点的下一个节点也是被取消的 if (s == null || s.waitStatus &gt; 0) &#123; s = null; //从后往前找到node后的第一个没取消的节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //解锁这个节点 if (s != null) LockSupport.unpark(s.thread);&#125; 自己到了下一个被唤醒的线程时，需要分情况的进行解锁，因为unparkSuccessor方法是多个地方都要被使用的，所以虽然在我们的cancelAquire方法中，node已经设置为CANCEL状态，但是其他方法调用的时候node的状态就不确认了，所以这也是为什么还要继续判断状态的理由。 并且找到自己的下一个元素没被取消的节点，让他获得锁。需要注意的是如果下一个节点取消的话,就会采取从后往前找的方式,知道排列在最前面的那个节点.为什么采用这种方式,因为我们在之前的代码也可以看到,在进行设置next节点的时候都上用CAS的方式,所以next节点设置成不成功也都是不确定的,而且没有一直进行尝试.从后往前保证了不会出现问题. 释放锁看完获得锁之后，我们看一下如何进行锁释放的。 12345678910public final boolean release(int arg) &#123; //尝试释放锁 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 和获得锁一样tryRelease方法也是需要子类自己进行实现的。如果释放锁成功的话，就开始unparkSuccessor 方法为head的下一个节点获得锁。 这里就也用到了unparkSuccessor方法。同时我们再次看unparkSuccessor方法就会清晰很多,明白为什么要那么多判断了。 非独占式锁1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 和上面独占式锁的流程非常类似，我们再看一下doAcquireShared方法所做的事情。 1234567891011121314151617181920212223private void doAcquireShared(int arg) &#123; //添加一个非独占式的节点 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); //判断是否到了一下个解锁的位置了 if (p == head) &#123; int r = tryAcquireShared(arg); //拿到锁，设置了当前的线程 //如果成功获取锁，就设置head并传播 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); //设置头并且传播 p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; ...省略&#125; 此处和独占式不同的地方主要在tryAcquireShared和setHeadAndPropagate方法，因为独占式获取了只会更改自己的状态。tryAcquireShared方法如果设置成功则会把线程设置为当前的线程，然后用共享式方法setHeadAndPropagate则会传播到其他的节点。 1234567891011private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); //把自己设置为头 //满足条件调用doReleaseShared方法 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) //记住要满足是共享锁，才会传播 doReleaseShared(); &#125; &#125; 哈哈看到这里，就直接到释放锁的方法了 12345678910111213141516171819private void doReleaseShared() &#123; //循环释放锁 for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; //因为前面只是设置了头并没有改变状态 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 看懂了独占式，看非独占式就很简单了。 结语为什么我们需要了解AQS，这是因为Lock锁，线程池，信号量（Semaphore）就是基于AQS实现的。 所以AQS是基础，当时我看ReentrantLock的时候就是一脸懵逼，当看完AQS之后再次看的时候就清晰很多了。同时不得不佩服Doug Lea大神。 本文主要的是基于自己的一些观点写的，如有表达不当或者描述错误的地方，欢迎给我反馈。 与君共勉！！ 参考文献 占小狼-深入浅出java同步器AQS java8-AbstractQueuedSynchronizer文档","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.eumji025.com/tags/java/"}]},{"title":"Go 初学者成长之路","slug":"go-learn-material","date":"2018-01-12T05:36:18.000Z","updated":"2018-02-16T03:43:18.973Z","comments":true,"path":"2018/01/12/go-learn-material/","link":"","permalink":"http://www.eumji025.com/2018/01/12/go-learn-material/","excerpt":"","text":"本文转载自Halfrost-Field 冰霜之地,以获取授权 开源书籍 书籍名 地址 推荐理由 Go 指南 https://tour.go-zh.org/ 初学者熟悉 Go 语法的 palyground,无须搭建本地 Go 的环境，在线就编写 Go 的代码 Go实战开发 https://github.com/astaxie/go-best-practice 这本书还没有完成，但是基础的基本都讲完了，这个书的作者就是著名的 Go 开源项目 beego 的作者 @astaxie，他的最佳实践非常值得阅读 Go Web 编程 https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/preface.md gitbooks地址 这个本的作者也是上本书的作者 @astaxie，从开发环境搭建到构建一个 Web 应用，讲解的都非常详细，@astaxie 的这两本书非常值得深度学习和阅读，本书已经完全写完了 GO 命令教程 https://github.com/hyper0x/go_command_tutorial 《Go并发编程实战》作者郝林书中的示例 Go入门指南 https://github.com/Unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md 这本书也非常适合初学者，不过看了上面几本书以后，看这本书，前面一些基础内容都可以很快的刷过去了，这本书可以主要看高级编程和实际应用这两大部分 Go语言圣经 http://docs.ruanjiadeng.com/gopl-zh/index.html 这本书是 Go 语言著名书籍《The Go Programming Language》的中文翻译版，如果觉得翻译的书不好，可以直接去看原著 Go by Example https://gobyexample.com/ 推荐这个网站的原因是这里有好多值得初学者学习的例子，这里可以作为初学者“抄”(学习)代码的地方 Go-SCP https://checkmarx.gitbooks.io/go-scp/content/ 这本书是关于 Go 安全相关的，本人还没有读过，为何放在这里？因为是我老大推荐的? 编译器1. Vim党Vim党当然是不需要 IDE 的，直接 Vim + Vim-go（或者 Emacs） 2. 文本编辑器 + 插件目前最常用最火的文本编辑器有 VSCode、Sublime、Atom 他们都可以安装相应的插件，就可以支持 Go 的编码了。我暂时用的是 Atom + go-plus，界面还比较美，如下图： 3. IDE目前用的比较多的 IDE 有：IntelliJ idea、Goland、LiteIDE。 学习网站 网站名 地址 推荐理由 The Go Programming Language https://golang.org/ Go 的官方网站 Go 编程语言 https://go-zh.org/ Go 官网对应的中文网站 The Go Blog https://blog.golang.org/ Go 的官方博客 The Go Packages https://golang.org/pkg/ Go 的包官方文档 Go 标准库中文文档 http://cngolib.com/ Go 标准库中文文档 视频这个也看个人吧，有些人不喜欢看文档，或者有时候文档看累了看会视频。下面这些视频本人看过开头的，觉得讲的还可以，不过后面的我没有继续看下去了，因为觉得看视频学习有点慢，我还是选择看刷书刷题啦~? 网站名 地址 推荐理由 Go 编程基础 https://github.com/Unknwon/go-fundamental-programming 这套视频适合初学者 Go Web 基础 https://github.com/Unknwon/go-web-foundation 这是一套针对 Google 出品的 Go 语言的视频语音教程，主要面向完成《Go 编程基础》教程后希望进一步了解有关 Go Web 开发的学习者。 Go名库讲解 https://github.com/Unknwon/go-rock-libraries-showcases 这是一套针对 Google 出品的 Go 语言的第三方库进行评测讲解的集博客、示例与语音视频为一体的综合教程，适合完成学习完成《Go编程基础》教程的学习者。 Go语言第一课 慕课网上的课程 这个课程的录制者是郝林，如果你是他的粉丝，可能你就不想错过这个课程 社区 Go语言社区（排名不分先后） https://gocn.io http://studygolang.com http://www.golangtc.com http://www.golangweb.com 最后，多多练习，多多实践 Go，只要功夫深，铁杵磨成针！ GitHub Repo：Halfrost-Field Follow: halfrost · GitHub Source: https://halfrost.com/new_gopher/ 结语go语言初学者,个人喜欢goland. 与君共勉!!!","categories":[{"name":"Golang基础","slug":"Golang基础","permalink":"http://www.eumji025.com/categories/Golang基础/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://www.eumji025.com/tags/golang/"}]},{"title":"HashMap源码分析","slug":"hashmap-analysis","date":"2018-01-06T03:06:50.000Z","updated":"2018-03-13T11:11:17.002Z","comments":true,"path":"2018/01/06/hashmap-analysis/","link":"","permalink":"http://www.eumji025.com/2018/01/06/hashmap-analysis/","excerpt":"","text":"HashMap介绍HashMap是基于hash表的map的实现,使用key-value形式存储键值对，并允许使用 null 值和 null 键,但是key只能有一个为null. Map不保证映射的顺序，其内部是根据hash值去模运算去排列的。HashMap内部使用entry数组作为存储的介质. 本文是基于Java8版本写的,因为Java8对HashMap有较大的改变,采用数组+链表+红黑树方式来记录键值对.而且Java8还重写了resize方法,Java8之前很有可能造成扩容时,链表的循环问题. 源码解读本文中的代码比较多,大多数的说明都在注释上体现了,所以可能文字上表述的不是很多,本文也尽可能介绍了一些java8中的新方法.需要注意的是其中很多地方都进行了修改和补充,看完本篇文章一定和之前看的Java7 HashMap有非常多的不同之处,也可以思考一下为什么Java8要做这么多改变. Node介绍Node是map的接口中的内部接口Map.Entry的实现类,用于存储HashMap中键值对的对象,是HashMap中非常重要的一个内部类,随便提一下,HashMap中有非常多的内部类,本文没做过多的介绍,读者可以自己翻看一下源码,因为篇幅实在太长了…在这里就简单的讲一下,大部分的内部类都是用于集合操作的,如keySet,values,entrySet等方法. 内部组成 12345678910static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;//key是不可变的final K key;//valueV value;//指向下一个entry对象,具体作用后面介绍Node&lt;K,V&gt; next;//hash值int hash;&#125; HashMap组成HashMap主要参数 12345678static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //默认初始容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //最大容量static final float DEFAULT_LOAD_FACTOR = 0.75f; //默认负载因子,相当于只有多少可用transient Node&lt;K,V&gt;[] table;//要存储值的hash表transient int size; //实际大小int threshold; //阈值final float loadFactor;//负载因子transient int modCount; //记录操作次数的 相比之前版本的HashMap,Java8更钟爱与位操作.>&gt; 表示逻辑右移>&gt;&gt; 表示无符号逻辑右移.高位补零 HashMap构造方法 123456789101112131415161718//为空时候使用默认分配的大小16,负载因子0.75f,默认的容量为12,当size&gt;threshold默认容量时候就会去扩容public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125;//构造方法 初始化负载因子和阈值public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity);//容量判断 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //负载银子判断 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; HashMap方法本文主要挑选几个比较常用且重要的方法进行分析.因为这写方法已经涵盖了大部分的方法调用关系. hash方法使用hashcode 异或 hashcode右移16位 得到hash值,等同于高位都取零随带提一句,int类型的hashcode就是本身.1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; put方法解析put方法,是HashMap中非常重要的方法,其中牵涉到了非常多的知识点,需要仔细的阅读. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;/** * onlyIfAbsent 是否替换,为true时,如果存在值则替换 * evict 主要用于LinkedHashMap移除最近未使用的节点 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //未初始化则扩容(扩容包括新建和扩容) if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果不存在,直接put if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //根据条件获取不同的node节点,有可能tab[i]就是存在的元素 if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //否则判断是树,添加 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //否则普通的链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; //到尾都没找到,添加一个节点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //判断是否转化为树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //转换成树的具体内容就不描述了,篇幅太长 treeifyBin(tab, hash); break; &#125; //找到记录 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //存在,替换 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; //用于linkedHashMap,本文不做介绍 afterNodeAccess(e); return oldValue; &#125; &#125; //添加成功,判断是否要扩容 ++modCount; if (++size &gt; threshold) resize(); //用于linkedHashMap afterNodeInsertion(evict); return null;&#125; 下面详细介绍一下扩容的方法.看起来非常庞大.其实逻辑不复杂123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * 有几种情况 * 1.当为空的时候,也就是没有初始化的时候 * 2.当到达最大值时候 * 3.普通扩容时候 */final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //存在旧值 if (oldCap &gt; 0) &#123; //大于2&lt;&lt;30 最大容量设置为2&lt;&lt;32 - 1 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; //但是不移动.,没有空间移动 threshold = Integer.MAX_VALUE; return oldTab; &#125; //如果属于正常范围的扩容 容量 x2 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //用户自己设定了初始化大小 else if (oldThr &gt; 0) &#123; newCap = oldThr; &#125; //如果没使用,使用默认值初始化 else &#123; newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //用户自定义了map的初始化操作 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //新的容量 threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果是扩容操作 if (oldTab != null) &#123; //遍历map的数据 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果当前位置只有一个元素,直接移动到新的位置 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果是红黑树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //如果没超过8个 是链表 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //此处的操作是这样子的 因为是扩容一倍的操作,所以与旧的容量进行与操作后只有两个值0 和 1 //如果是0就位置不变,如果是1就移动n+old的位置, //个人认为这么做的好处是: /** * 1.不会像之前1.7发生循环依赖的问题 * 2.从概率的角度上来看可以均匀分配,(一般来说高位和低位比例差不多) * 3.提高效率 */ do &#123; next = e.next; //如果和旧容量位运算后的值是0,记得当前节点和存放在链表的尾部 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //同上 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //为0的还是存放在当前位置 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //为1的就放在扩容的j + oldCap那边去 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 因为不像Java8之前的HashMap有初始化操作,此处选择将初始化和扩容放在了一起,并且又增加了红黑树的概念,所以导致整个方法的判断次数非常多,也是这个方法比较庞大的主要原因. 值得一体的是,在扩容后重新计算位置的时候,对链表进行优化,有兴趣可以搜索一下HashMap导致cpu百分之百的问题而在Java中通过巧妙的进行&amp;操作,然后获得高位是为0还是1.最终移动的位置就是低位的链表留在原地,高位的放在index+oldsize的地方就可以了,不用为每一个元素计算hash值,然后移动到对应的位置,再判断是否是链表,是否需要转换成树的操作.如下所示.12hashcode: 1111111111111101212oldcap: 0000000000000010000 很容易知道这个&amp;操作之后就是为0,因为oldcap都是2的倍数,只有高位为1,所以通过&amp;确认高位要比%取余高效.此时在看一下上面的扩容操作也许就更清晰了. 下面介绍一些newNode方法.就是新建一个节点.可以思考一下为什么要把newNode抽离出来?文章末尾给答案.123Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(hash, key, value, next);&#125; 添加节点到红黑树的方法是Java8中新添加的,需要满足链表的长度到8,才会转换成红黑树,其主要目的是防止某个下标处的链表太长,导致在找到的时候速度很慢,下面看一下实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//尝试着往树节点添加值final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; //找到根节点 TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; //存在的话直接返回,用于替换 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; //判断节点类型是否相同,不相同 else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; //没有搜索过,搜索子节点,搜过了说明没有就跳过. if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; //去子节点去找 if (((ch = p.left) != null &amp;&amp;(q = ch.find(h, k, kc)) != null) ||((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; //对比hash值,决定查找的方向 dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; //找到子节点为空,就可以加进去,设置层级关系 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125; 这里简单的梳理一下流程.1.从根节点查找,找到了返回,如果没找到,找字节点2.判断往哪个方向去查找3.如果不存在,在子节点末端添加新节点 下面再看一下树的split方法,主要是扩容操作,重新结算位置需要分裂树,之前讲过,扩容会根据和旧map容量进行&amp;操作,移动高位为1的节点.并且验证新的节点列表是否需要重新转换成链表的形式. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // 设置记录高低位的node,和链表一样都是计算高位是0还是1 TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; //还是和旧的容量做位运算,为0的放在lo中 if ((e.hash &amp; bit) == 0) &#123; //判断是否为头部 if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; //获取为1的放在hi中 else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; //lo链表的处理 if (loHead != null) &#123; //如果小于7,那么当做链表处理 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; //转换成树 tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; //同上 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125;//把树转换成链表final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125; 转化成红黑树的详情本文就没详细介绍了,我相信很容易看懂.这里借｀美团点评技术团队｀的一张图来展示一下put方法的流程 get方法 逻辑其实很简单,就是首先通过hashcode确认位置,然后分数据结构类型继续不同方式的查找1234567891011121314151617181920212223public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //找到位置,并且当且位置存在元素 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;(first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp;((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //链表或者树,遍历子节点 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; remove方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;/** * 1.寻找是否存在,如果存在分数据类型分别处理 * 2.如果为树,稍微复杂一点,需要判断是否要转换成链表,然后就是树的移动 */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //找到节点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;(p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; //从树节点获取 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //找到了对应的节点 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //树节点处理 主要是两点,存在删除,删除了是否需要转换成链表 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //一个元素 else if (node == p) tab[index] = node.next; else //指向node的下一个 p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 本文就不看树的详细删除过程了,内容太多太长.可以自己想象一下树的删除过程.replace方法12345678910111213@Overridepublic V replace(K key, V value) &#123; Node&lt;K,V&gt; e; //找到节点替换 if ((e = getNode(hash(key), key)) != null) &#123; V oldValue = e.value; e.value = value; //与linkedHashMap有关 afterNodeAccess(e); return oldValue; &#125; return null;&#125; 从基本的方法中我们可以看出,最复杂的就是put方法,put方法设计非常多的方法,后续的get,replace,remove都是建立在put方法基础之上. 补充方法上面介绍了几个基本的方法,另外现在介绍一些有用的小方法.都是在Java8新增的. merge方法merge方法的主要作用是如果不存在就进行添加,如果存在的话按照自己指定的remappingFunction进行操作,如果操作之后value为null的话删除元素,否则替换,下面是代码详情 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V merge(K key, V value,BiFunction&lt;? super V, ? super V, ? extends V&gt; remappingFunction) &#123; if (value == null) throw new NullPointerException(); if (remappingFunction == null) throw new NullPointerException(); int hash = hash(key); Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first; int n, i; int binCount = 0; TreeNode&lt;K,V&gt; t = null; Node&lt;K,V&gt; old = null; //扩容操作 if (size &gt; threshold || (tab = table) == null ||(n = tab.length) == 0) n = (tab = resize()).length; //通过key找到元素,分为树和链表两种情况 if ((first = tab[i = (n - 1) &amp; hash]) != null) &#123; if (first instanceof TreeNode) old = (t = (TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); else &#123; Node&lt;K,V&gt; e = first; K k; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; old = e; break; &#125; ++binCount; &#125; while ((e = e.next) != null); &#125; &#125; //存在旧的结点,进行合并操作 if (old != null) &#123; V v; if (old.value != null) //具体的合并操作 v = remappingFunction.apply(old.value, value); else v = value; //合并成功,执行afterNodeAccess方法,子类linkedHashMap有用 if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; //合并之后没有值,删除元素 else removeNode(hash, key, null, false, true); return v; &#125; //没有旧结点,直接添加,考虑扩容,链表和树的情况 if (value != null) &#123; if (t != null) t.putTreeVal(this, tab, hash, key, value); else &#123; tab[i] = newNode(hash, key, value, first); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); &#125; ++modCount; ++size; afterNodeInsertion(true); &#125; return value;&#125; compute方法123456789101112131415161718192021public V compute(K key,BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; //省略部分基本和merge方法的前半段一直,不重复展示 //获取旧元素 V oldValue = (old == null) ? null : old.value; //计算出新值 V v = remappingFunction.apply(key, oldValue); //存在旧元素,旧赋值到旧元素上 if (old != null) &#123; if (v != null) &#123; old.value = v; afterNodeAccess(old); &#125; //计算结果为空则删除 else removeNode(hash, key, null, false, true); &#125; //r如果没有旧元素,但计算出的值不为空,添加操作,和merge方法相同,省略 return v;&#125; 看到这里我相信大家都有疑问,为什么要放两个几乎相同的两个方法, 我们详细对比一下两个方法,发现会有几点不同: 参数不同,merge方法要求value不为null,compute方法没有要求; merge方法要求old.value也不为null.compute的方法依然没有要求. 另外compute还有两个扩展方法,简单介绍一下. computeIfAbsent方法如果oldvalue不为null就不替换,如果计算后的值不存在直接返回,否则如果old不为null,通过key计算出值替换,否则添加到map中12345678910111213141516171819public V computeIfAbsent(K key,Function&lt;? super K, ? extends V&gt; mappingFunction) &#123; //扩容等操作省略,同上 V oldValue; if (old != null &amp;&amp; (oldValue = old.value) != null) &#123; afterNodeAccess(old); return oldValue; &#125; //注意这里 V v = mappingFunction.apply(key); if (v == null) &#123; return null; &#125; else if (old != null) &#123; old.value = v; afterNodeAccess(old); return v; &#125; //添加操作省略&#125; computeIfPresent方法不进行扩容的判断(因为不存在找不到就添加这样的操作).直接通过key查找,如果找到,且计算的结果不为null,替换,否则就直接删除12345678910111213141516171819public V computeIfPresent(K key,BiFunction&lt;? super K, ? super V, ? extends V&gt; remappingFunction) &#123; if (remappingFunction == null) throw new NullPointerException(); Node&lt;K,V&gt; e; V oldValue; int hash = hash(key); if ((e = getNode(hash, key)) != null &amp;&amp; (oldValue = e.value) != null) &#123; //注意这里 V v = remappingFunction.apply(key, oldValue); if (v != null) &#123; e.value = v; afterNodeAccess(e); return v; &#125; else removeNode(hash, key, null, false, true); &#125; return null; &#125; 再次总结一下三个compute方法的异同点 compute方法和computeIfPresent方法都需要oldValue,computeIfAbsent不需要 compute的remappingFunction.apply方法不限制oldvalue是否为null,但是computeIfPresent限制必须不为null才进行,computeIfAbsent方法必须要old或者oldvalue为null才会进行后续操作 computeIfPresent只有oldvalue存在则进行apply方法,然后根据条件替换或者删除操作,而compute和computeIfAbsent方法则是如果old不存在,还会根据条件额外进行添加操作 简单点说就是: 如果是不存在oldvalue才进行操作,这也可以认为我们在声明了String a = null这样的操作,现在需要进行初始化,选择computeIfAbsent方法, 如果必须存在oldvalue才操作,而且只进行删除或者修改的操作则选择computeIfPresent方法,类似看看还有没有修改的价值,没价值就干掉了. 其他选择compute方法 快速失败和安全失败问题 12345678910一：快速失败（fail—fast） 在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。 注意：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。 场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。二：安全失败（fail—safe） 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。 原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。 缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。 解答解释一下刚才在文章设置的悬念,为什么要把newNode方法单独提出来,其实这里很大一部分原因是因为Linkedhashnap会需要重写此方法进行额外的操作.具体是什么可以自己查看一下源码,或者看我的另一篇文章,map集合类总结. 总结改版后的HashMap看起来更加的庞大和神秘了,因为相比之前看起来可能方法更大而且还有红黑树这个数据结构,看到代码就会让人感觉好难受,同时也呼吁每个人都不要写这么庞大的方法.尽可能将方法拆小.变得更加的简洁明了.但是Java8对HashMap的改变,使得HashMap在一定程度上提升了性能,并且还新填了不少的方法. 当然本文只是个人的一些看法,如果存在不足或者错误的地方,欢迎大家指正!!! 结语与君共勉!!!","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.eumji025.com/tags/java/"}]},{"title":"Java基础 - ThreadLocal分析篇","slug":"threadlocal-analysis","date":"2018-01-05T23:44:42.000Z","updated":"2018-03-18T02:19:12.546Z","comments":true,"path":"2018/01/06/threadlocal-analysis/","link":"","permalink":"http://www.eumji025.com/2018/01/06/threadlocal-analysis/","excerpt":"","text":"前言我们在使用ThreadLocal的是否产生过疑问,为何ThreadLocal能将我们的变量与我们的线程对应呢,它内部是怎么实现的呢.今天我就参照源码对threadlocal的工作机制进行分析.我相信大家或多或少在工作和学习中都遇到过ThreadLocal,举一个最简单的例子来讲,SimpleDateFormat在多线程中会存在不安全的情况.导致这个情况发生的原因是因为calb.establish(calendar).getTime()方法不是线程安全的,所以导致多个线程同时操作的时候calendar.setTime会把别的线程的数据给覆盖掉,其中一种解决方案就是使用ThreadLocal具体代码如下:12345678910111213141516171819202122public class FormatDateUtil &#123; private static final String date_format = \"yyyy-MM-dd HH:mm:ss\"; private static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;(); public static DateFormat getDateFormat() &#123; DateFormat df = threadLocal.get(); if(df==null)&#123; df = new SimpleDateFormat(date_format); threadLocal.set(df); &#125; return df; &#125; public static String formatDate(Date date) throws ParseException &#123; return getDateFormat().format(date); &#125; public static Date parse(String strDate) throws ParseException &#123; return getDateFormat().parse(strDate); &#125;&#125; 应用场景从上面的介绍中我们应该也能了解到ThreadLocal的应用场景有如下几种: 有变量或者对象示例需要在线程中多个地方和多次被使用 不希望线程之间共享,也不希望每次使用时都重新创建,加大内存的开销 源码结构 现在介绍一下ThreadLocalMap类,这个类是用来以键值对的方式存储我们的变量的，key为threadLocal对象，value为对应的存储的值，看一下具体的代码 12345678910111213static class ThreadLocalMap &#123; private static final int INITIAL_CAPACITY = 16; //初始化大小 private ThreadLocal.ThreadLocalMap.Entry[] table; //内部数组 private int size; //大小 private int threshold; //阈值 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125;&#125; 从上面的信息我们可以看出ThreadLocalMap这个内部类的结构很像HashMap,在ThreadLocalMap也有一个存放数据的entry类.如果有兴趣大家可以去看看HashMap的源码,本人之前也做过HashMap源码分析的解读. 补充: 为什么要创建一个数组来存放值,自己刚开始看源码的时候有过这个疑惑,所以记录一下,这是因为ThreadLocalMap是和thread绑定的,每一个thread的可以使用多个theadLocal对象存储值,每一个threadLocal对象只能存放一个值,每个threadLocal的hashCode值都是在原有的基础上加0x61c88647,所以这样设计是为了更好的使用局部变量和扩充,如果不理解请继续往下看,看完再梳理一次. 在这里总结一下: 每个threadLocal同一个线程下只可以存放一个值(一个hash值只能对应一个位置),而一个线程可以绑定多个threadlocal对象,ThreadLocalMap又是和thread一一对应,所以一个threadLocalMap存放多个threadLocal的值 下面我们主要针对ThreadLocal的set,get,remove方法进行内部解读.弄清楚里面到底是如何进行存储和获取数据的,相应的会牵涉到使用其他相关的方法 set方法解读set方法的主要代码 1234567891011public void set(T value) &#123; //获取当前的线程 Thread t = Thread.currentThread(); //获取当前线程的threadLocalMap对象 ThreadLocalMap map = getMap(t); //不为空更新map中的值,否则创建一个新的map if (map != null) map.set(this, value); else createMap(t, value); &#125; 在我们的thread类中有一个未实例化的threadLocalMap,具体下代码所示. 1ThreadLocal.ThreadLocalMap threadLocals = null; 在我们第一次调用set方法时会调用createMap(t, value)方法初始化这个map,且这个map是和线程绑定的,并初始化这个map里面的table大小和阈值(默认是数组大小的2/3),并进行赋值,key即为当前threadLocal对象,创建threadLocal对象时中会初始化threadLocal的threadLocalHashCode.内部调用AtomicInteger.getAndAdd(0x61c88647)方法. 1234567891011121314151617181920212223//创建mapvoid createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125;//初始化threadLocalMapThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; //hashcode和数组长度减一进行取模运算确定存放变量的位置 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; //设置阈值大小 默认2/3 setThreshold(INITIAL_CAPACITY); &#125;private final int threadLocalHashCode = nextHashCode();//下一个hashcode HASH_INCREMENT = 0x61c88647 为了让哈希码能均匀的分布在2的N次方的ENTRY数组里 使用了线性探测法private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; //阈值private void setThreshold(int len) &#123; threshold = len * 2 / 3; &#125; 从上面的代码也就验证了每个线程只有一个threadLocalMap的理论，而每个threadLocal对象的threadLocalHashCode也是在初始化时候就已经确定了。 如果已经被初始化过,则调用map.set(this, value)方法进行值的更新.具体如下代码 12345678910111213141516171819202122232425262728//因为数组是可以扩容的,所以很容易导致位置发生移动.因此方法里面包含了大量的数据验证 private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; //取模确定位置 int i = key.threadLocalHashCode &amp; (len-1); //尝试着插入值 for (Entry e = tab[i]; e != null;e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //如果已经存在当前key,直接替换值 if (k == key) &#123; e.value = value; return; &#125; //如果当前下标处不存在值,可能移动了位置 if (k == null) &#123; //尝试替换值 replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; //没有清空,而且超过阀值 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) //调整 rehash(); &#125; 更新的逻辑就是，首先通过threalLocal.threadLocalHashCode去找是否存在，如果存在就替换值。如果不存在继续后面的逻辑。最后判断是否要扩容。 下面详细介绍一下replaceStaleEntry方法.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 此方法是ThreadLocal中非常重要的方法，它做的事情很简单： * 就是从staleSlot开始遍历，向前遍历将无效（弱引用指向对象被回收）清理，即对应entry中的value置为null，将指向这个entry的table[i]置为null，直到扫到空entry。 * 另外，在过程中还会对非空的entry作rehash。 * 可以说这个函数的作用就是从staleSlot开始清理连续段中的slot（断开强引用，rehash slot等） */ private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; Entry[] tab = table; int len = tab.length; Entry e; int slotToExpunge = staleSlot; //向前查找到最前面的没有元素的位置 for (int i = prevIndex(staleSlot, len);(e = tab[i]) != null;i = prevIndex(i, len)) //找到没有的元素 if (e.get() == null) slotToExpunge = i; //向后找到,找到自己key所在得到位置,替换值 for (int i = nextIndex(staleSlot, len);(e = tab[i]) != null;i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); //找到当前threadLocal 替换值并且交换位置,将staleSlot移到本来的下标处 if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; //替换slotToExpunge的位置 if (slotToExpunge == staleSlot)&#123; slotToExpunge = i; &#125; //删除失效位置的引用 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; // If key not found, put new entry in stale slot tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125; 移除不存在的条目,分为两种情况, 如果key已经被设置为null,直接清空, 如果key不为空,移动到离自己目标位置最近的地方,有可能被占用了. 在继续往下看一下expungeStaleEntry方法的内容12345678910111213141516171819202122232425262728293031323334//移除或者移动private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // 移除指定位置的数据 tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; //向后移除空的threadlocal for (i = nextIndex(staleSlot, len);(e = tab[i]) != null;i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); //引用设置为null 加快gc回收 if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; //移动自己到最接近本来的位置, while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i; &#125; 关于Entry的介绍1static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; 关于引用强度的具体描述在深入理解java虚拟机中有介绍,暂时你可以理解为,这是一种很弱的引用类型,很快就会被GC掉.因为如果线程可以活很长的时间，并且该线程保存的线程局部变量持续增加，那么就涉及到在线程的生命期内如何回收 ThreadLocalMap 的内存了，随着Entry对象越多，那么ThreadLocalMap 就会越来越大，占用的内存就会越来越多，所以对于已经不需要了的线程局部变量，就应该清理掉其对应的Entry对象。为了防止这样的情况,所以entry使用的是弱引用类型,实现了weekreference接口.通过将tab[i]设为null,对象不可达的情况下就会很快被回收 接着上面的内容,看一下cleanSomeSlots方法的详情.1234567891011121314151617private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; //循环清空,每次折半 do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; //同上 i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed; &#125; 最后看一下当没有删除并且超过阀值时的处理123456789private void rehash() &#123; //清空 expungeStaleEntries(); // 还是超过3/4 if (size &gt;= threshold - threshold / 4) /扩容 resize();&#125; 具体看一下清空的实现,道理非常简单,就是把过期的遍历移除12345678910 private void expungeStaleEntries() &#123; Entry[] tab = table; int len = tab.length; for (int j = 0; j &lt; len; j++) &#123; Entry e = tab[j]; //只要是不为空,且过期,统统的尝试移除 if (e != null &amp;&amp; e.get() == null) expungeStaleEntry(j); &#125;&#125; 再看一下具体扩容的措施12345678910111213141516171819202122232425262728//翻倍private void resize() &#123; Entry[] oldTab = table; int oldLen = oldTab.length; int newLen = oldLen * 2; Entry[] newTab = new Entry[newLen]; int count = 0; //遍历所有,把没有过期的全部移动到新的entry,过期的删掉 for (int j = 0; j &lt; oldLen; ++j) &#123; Entry e = oldTab[j]; if (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; // Help the GC &#125; else &#123; int h = k.threadLocalHashCode &amp; (newLen - 1); while (newTab[h] != null) h = nextIndex(h, newLen); newTab[h] = e; count++; &#125; &#125; &#125;//设置新的阀值 setThreshold(newLen); size = count; table = newTab;&#125; 可以看出整个追踪是否过期的过程是很复杂的,需要去考虑扩容的清空去查找和替换. get方法解读外层的get方法内容123456789101112131415public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //从线程获取threadlocalmap ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 首先是判断threadLocalMap是否已经初始化过,若没有这调用setInitialValue()方法. 12345678910private T setInitialValue() &#123; T value = initialValue(); //返回null Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; 在setInitialValue()方法中,会返回一个默认值null,如果初始化map,和上面的描述的set方法时是一致的.加入已经初始化过,则会去调用getEntry()方法获取值.具体如下. 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 将threadlocal的hashcode和table长度减一进行取模运算,获取当前entry所在的位置,然后返回entry,如果发生了扩容或者垃圾回收,会导致原来的值丢失,如果获取不到entry或者entry的key和原来的key无法匹配,则进行entry消失后的操作. 123456789101112131415161718private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); //存在直接获取 if (k == key) return e; if (k == null) //删除 expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null; &#125; remove 方法解读remove方法首先判断是否存在threadlocalmap如果存在,进行remove操作 12345678910111213141516171819public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125; &#125; 总体的原理和get和set方法中一样,就不多的描述了. ThreadLocal内存泄露提一下我对于ThreadLocal的内存泄漏理解,threadLocal的内存泄露产生的主要原因是某个线程发生阻塞,无法释放资源,我们可以看一下引用关系 thread =&gt; threadLocalMap =&gt; threadLocal =&gt; entry,线程不结束,引用关系就一直存在,根据可达性的原则,就无法进行内存回收,随着线程增多就会发生内存泄露的问题,要解决这样的问题及时调用remove方法,或者set(null)等方法解除引用关系,同时,减少在threadLocal中放入大对象也是一种好的方式. 总结通过对threadLocalMap的源码解读,使我个人对threadLocal这个类以及thread类有了进一步的认识,文章中可能存在错误的描述和解读不到位的地方,本文中entry的移动还是理解不够透彻,需要再加以理解.欢迎留言告知或者发邮件给我eumji025@gmail.com 与君共勉!!!","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.eumji025.com/tags/ThreadLocal/"}]},{"title":"动态代理及Proxy源码分析","slug":"dynamic-proxy","date":"2018-01-02T03:23:46.000Z","updated":"2018-02-25T05:08:41.312Z","comments":true,"path":"2018/01/02/dynamic-proxy/","link":"","permalink":"http://www.eumji025.com/2018/01/02/dynamic-proxy/","excerpt":"","text":"前言 代理是java中非常重要的一种设计模式,动态代理则可以认为是一种动态代理的最佳实践,本文将由浅及深的介绍动态代理及其proxy源码分析,文章写的不一定都对,请各位看官带着批判的态度阅读此文章. 代理模式是设计模式中的一种,而且在实际的开发中使用的频率非常高 ,比如spring AOP,mybatis代理都是我们经常使用的. 代理模式的定义: 当无法直接访问某个对象或访问某个对象存在困难时可以通过一个代理对象来间接访问，为了保证客户端使用的透明性，所访问的真实对象与代理对象需要实现相同的接口。 静态代理从上面的介绍中可以看出代理模式其实本意是为了解决访问存在困难或者为了保证透明性的一种工具,有点类似于我们无法访问google,需要一个中间代理商的帮助是一致的.下面通过一个简单的例子来介绍: 12345678910111213141516171819202122232425262728293031323334353637383940public class ProxyDemo &#123; static interface BaseUser&#123; void info(); void real(); &#125; static class ProxyUser implements BaseUser&#123; BaseUser baseUser; public ProxyUser(BaseUser baseUser) &#123; this.baseUser = baseUser; &#125; public void info() &#123; System.out.println(\"I'm Proxy,I can help you\"); &#125; public void real() &#123; System.out.println(\"I will help you visit google\"); baseUser.real(); System.out.println(\"I had help you visit google\"); &#125; &#125; static class TargetUser implements BaseUser&#123; public void info() &#123; System.out.println(\"I'm google,what you what do?\"); &#125; public void real() &#123; System.out.println(\"I.m google,this is searched info\"); &#125; &#125; public static void main(String[] args) &#123; BaseUser targetUser = new TargetUser(); BaseUser proxyUser = new ProxyUser(targetUser); proxyUser.info(); proxyUser.real(); &#125;&#125; 在这里我们也可以认为代理者是两者访问或者交互的载体,需要对双方都非常的熟悉,才能帮你做具体的事,就像如果我现在需要代购,可能就需要找新的代理人!!! 这里也就是我们所说的静态代理 虽然静态代理也能帮我实现一些功能,但是只能说不够强大,此时我们就可以使用动态代理来帮我们更加灵活的去搞事情 动态代理动态代理的优势：1. 降低各个功能模块之间的耦合度，提高开发的效率和方便程序的维护度。 2. 减少代码量。 3. 不关注目标的具体实现。 动态代理的实现JDK动态代理 jdk自带的动态代理主要是通过实现InvocationHandler InvocationHandler的主要方法 Object invoke(Object proxy, Method method,Object[] args)throws Throwable 在代理实例上处理方法调用并返回结果。在与方法关联的代理实例上调用方法时，将在调用处理程序上调用此方法。即调用真实业务的方法都会进入到此invoke方法,至于为什么,稍后再说明 方法详细介绍 参数：proxy - 调用方法的代理实例对象 method - 代理实例对象调用的接口方法的 Method 实例对象。 Method-指代具体被代理的方法。 args -包含传入代理实例上方法调用的参数，如果接口方法不使用参数，则为 null。 return：从代理实例的方法调用返回的值。 throws： Throwable - 从代理实例上的方法调用抛出的异常。 ​ 案例本案例演示的是最常用的拦截方法然后记录日志的功能。 3.1 业务接口 123public interface Base &#123; public void hello(String name);&#125; 3.2 业务实现类 LoginImpl 123456public class LoginImpl implements Base&#123; @Override public void hello(String name) &#123; System.out.println(&quot;welcome &quot;+name+&quot;, success !!1&quot;); &#125;&#125; 3.3 代理类 LoginProxy 123456789101112131415161718192021222324252627282930313233343536373839404142class DynamicProxy implements InvocationHandler &#123; Object originalObj; Object bind(Object originalObj) &#123; this.originalObj = originalObj; return Proxy.newProxyInstance(originalObj.getClass().getClassLoader(), originalObj.getClass().getInterfaces(), this); &#125; /** * 切入点 对所有对象的方法都进行调用 * method.invoke方法对应代理对象调用login方法 * @param proxy 代理对象 * @param method 代理对象的方法 * @param args 代理对象调用接口方法的参数值 * @return 代理对象调用方法的返回值 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; before(); Object invoke = method.invoke(originalObj, args); if (invoke != null)&#123; result(invoke); &#125; after(); return invoke; &#125; private void before() &#123; System.out.println(&quot;方法执行之前&quot;); &#125; private void after() &#123; System.out.println(&quot;方法执行之后&quot;); &#125; private void result(Object o) &#123; o.toString(); &#125;&#125; 3.4 测试类 LoginClient 1234567public class LoginClient &#123; public static void main(String[] args) &#123; //用于生成代理文件 //System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); Base hello = (Base) new DynamicProxy().bind(new LoginImpl()); hello.hello(&quot;zhangsan&quot;); &#125;&#125; 3.5 执行结果： 123方法执行之前Hello zhangsan方法执行之后 从上面的例子我们可以看到动态代理有效的减少了各个模块的耦合度,用于实现日志功能的代码和用于实现登陆功能的代码相互隔离。对两者都没有条件限制,.只有在真正调用业务的时候并需要日志功能时候二者才发生联系。任何业务需要日志功能只需要通过代理类创建代理对象即可,不需要重复创建代理类. 究其原理System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;);取消掉此方法的注释,我们运行或编译代码后将生成代理的文件,默认是项目根目录下的于包名同名的文件夹下。下面我们看一下生成的代理类反编译后的内容: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import ProxyDemo.Base;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;//$Proxy0是生成代理的格式决定的final class $Proxy0 extends Proxy implements Base &#123; //将基础的tostring,equils,hashcode,还有base接口的方法生成method的对象 private static Method m1; private static Method m2; private static Method m4; private static Method m3; private static Method m0; public $Proxy0(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return ((Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;)).booleanValue(); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final void hello(String var1) throws &#123; try &#123; super.h.invoke(this, m4, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final void out() throws &#123; try &#123; super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final int hashCode() throws &#123; try &#123; return ((Integer)super.h.invoke(this, m0, (Object[])null)).intValue(); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; //具体的实现 static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); m4 = Class.forName(\"ProxyDemo$Base\").getMethod(\"hello\", Class.forName(\"java.lang.String\")); m3 = Class.forName(\"ProxyDemo$Base\").getMethod(\"out\"); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 首先从类的继承关系就很容易理解Proxy.newProxyInstance(originalObj.getClass().getClassLoader(),originalObj.getClass().getInterfaces(), this);方法的作用了. 即继承了proxy类也实现了Base接口.这也是Base hello = (Base) new DynamicProxy().bind(new LoginImpl());这也是为什么可以强转为Base对象的原因.同时在代理中将object类中的equils,tostring,hashcode以及所有base接口的方法生成对应的代理方法. 以hello方法为例介绍一下,h表示的是proxy类中的InvocationHandler其实也就是指代我们之前的DynamicProxy对象,然后调用invoke方法就回到DynamicProxy的invoke方法.我们就可以再次做很多中间的操作。 12345678910public final void hello(String var1) throws &#123; try &#123; super.h.invoke(this, m4, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125;&#125; Proxy解读看完了代理类的内容后,接下来我们就需要去详细的看一下Proxy是如何生成$Proxy0这个代理类的.了解一下其中的工作流程和原理。 首先看newProxyInstance方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) throws IllegalArgumentException &#123; Objects.requireNonNull(h); //获取需要代理类的所有实现的接口 final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; //检查是否有生成代理类的权限 checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; //查找或者生成代理类 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); //生成构造函数 try &#123; if (sm != null) &#123; //检查是否有权限 checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; //public $Proxy0(InvocationHandler var1) final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; //访问修饰符设置 if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; //返回代理类的对象 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException | InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125;&#125; 具体的实现逻辑在getProxyClass0方法中，最外面的方法只是描述了生成代理后然后创建对应的代理对象。首先看一下checkProxyAccess方法的具体内容 123456789101112131415161718192021222324252627282930//主要作用检查权限是否可以操作 private static void checkProxyAccess(Class&lt;?&gt; caller, ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; ClassLoader ccl = caller.getClassLoader(); //classloader验证 if (VM.isSystemDomainLoader(loader) &amp;&amp; !VM.isSystemDomainLoader(ccl)) &#123; sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); &#125; // ReflectUtil.checkProxyPackageAccess(ccl, interfaces); &#125; &#125; //检查接口的包权限 public static void checkProxyPackageAccess(ClassLoader var0, Class... var1) &#123; SecurityManager var2 = System.getSecurityManager(); if (var2 != null) &#123; Class[] var3 = var1; int var4 = var1.length; for(int var5 = 0; var5 &lt; var4; ++var5) &#123; Class var6 = var3[var5]; ClassLoader var7 = var6.getClassLoader(); if (needsPackageAccessCheck(var0, var7)) &#123; checkPackageAccess(var6); &#125; &#125; &#125; &#125; 当验证完权限之后,查看如何获取代理类的getProxyClass0方法123456789private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; //从缓存中获取,如果不存在就创建 return proxyClassCache.get(loader, interfaces); &#125; 使用proxyClassCache做缓存，其目的是为了复用，同时防止多线程重复创建。在weekCache类中使用了多个map进行记录,稍后我们再做详细介绍. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//获取或生成代理类 此处因为不是线程安全的做了多次判断public V get(K key, P parameter) &#123; Objects.requireNonNull(parameter); //删除过期条目 expungeStaleEntries(); //创建cacheKey Object cacheKey = CacheKey.valueOf(key, refQueue); //查看key是否已经存在valuemaps中 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) &#123; //不存在的话通过,再次尝试尝试获取,如果没有就插入 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; //生成代理对象的key 为弱引用类型 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); //尝试从valuemap中获取 Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; while (true) &#123; //如果确实已经有线程创建了 if (supplier != null) &#123; //直接获取 supplier might be a Factory or a CacheValue&lt;V&gt; instance V value = supplier.get(); if (value != null) &#123; //最终返回value return value; &#125; &#125; // 不存在创建一个supplier factory实现了supplier if (factory == null) &#123; factory = new Factory(key, parameter, subKey, valuesMap); &#125; if (supplier == null) &#123; //如果不存在则保存到valuemap中 supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; // 添加成功 supplier = factory; &#125; // 创建的时候发现已经有了,尝试替换 &#125; else &#123; if (valuesMap.replace(subKey, supplier, factory)) &#123; //替换成功 supplier = factory; &#125; else &#123; // retry with current supplier supplier = valuesMap.get(subKey); &#125; &#125; &#125;&#125; get方法首先去查看是否存在缓存过期的情况,存在则清除掉.如果不存在,尝试的生成key和value的相关元数据, 下面介绍key的生成方法KeyFactory.apply方法123456789//根据接口个数的不同选择生成不同的key对象public Object apply(ClassLoader classLoader, Class&lt;?&gt;[] interfaces) &#123; switch (interfaces.length) &#123; case 1: return new Key1(interfaces[0]); // the most frequent case 2: return new Key2(interfaces[0], interfaces[1]); case 0: return key0; default: return new KeyX(interfaces); &#125;&#125; 然后在判断是否存在同时其他线程生成,然后就是尝试着保存添加信息,如果已经有了就尝试替换.最终通过supplier.get()方法获取,最终实际的逻辑在supplier.get()方法中,下面看一下具体的过程123456789101112131415161718192021222324252627282930313233public synchronized V get() &#123; // serialize access // 再次检查是否匹配 Supplier&lt;V&gt; supplier = valuesMap.get(subKey); if (supplier != this) &#123; //因为此方法调用之前有可能发生valuesMap.replace(subKey, supplier, factory) return null; &#125; // 创建 V value = null; try &#123; //真正的逻辑,重点方法 value = Objects.requireNonNull(valueFactory.apply(key, parameter)); &#125; finally &#123; if (value == null) &#123; // 如果最终没能生成代理对象,从valuemap移除 valuesMap.remove(subKey, this); &#125; &#125; // the only path to reach here is with non-null value assert value != null; //包装value为acacheValue CacheValue&lt;V&gt; cacheValue = new CacheValue&lt;&gt;(value); // 保存到reverseMap reverseMap.put(cacheValue, Boolean.TRUE); // 尝试这替换valuemap中的cacheValue if (!valuesMap.replace(subKey, this, cacheValue)) &#123; throw new AssertionError(\"Should not reach here\"); &#125; return value; &#125; 下面详细介绍value的ProxyClassFactory.apply方法.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 //apply方法详解public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; Class&lt;?&gt; interfaceClass = null; try &#123; //使用给定的类加载器加载接口 interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; //验证是否为接口 if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; //验证接口不是重复的 if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; String proxyPkg = null; //修饰符 int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * 验证接口的可见性 * 如果不是public类型的接口又不在同一个包下抛出异常 */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; //如果不是public类型的接口又不在同一个包下抛出异常 else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // 没有包使用默认的包 com.sun.proxy proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; /* * 代理类的名称 按顺序递增 =&gt; $proxy0 */ long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * 生成代理类的字节数组 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; //调用native方法生成Class return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; throw new IllegalArgumentException(e.toString()); &#125; &#125;&#125; 主要的步骤如下 1.尝试着用现有的类加载器加载接口,如果成功 2.验证是否为接口,接口是否重复 ,如果成功 3.验证接口访问权限,如果成功 4.获取包的信息,和类名设置, 5.生成代理的字节数组 6.通过native方法defineClass0获取字节数字的具体的Class 这里着重讲解一下如何生成字节数组的 1234567891011121314151617181920212223242526272829303132333435363738394041 //生成代理类public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) &#123; ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); /** * 生成具体文件字节数组 * 1.找到所有接口的方法 * 2.添加object类的三个方法 tostring hashcode equils * 3.遍历生成具体的代理方法,代理方法的逻辑都想似,回调我们的代理类 */ final byte[] var4 = var3.generateClassFile(); // private static final boolean saveGeneratedFiles = GetBooleanAction(\"sun.misc.ProxyGenerator.saveGeneratedFiles\"))).booleanValue(); //这就是我们为什么设置sun.misc.ProxyGenerator.saveGeneratedFiles = true的原因,设置后就会生成代理类的文件 if (saveGeneratedFiles) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; int var1 = var0.lastIndexOf(46); Path var2; if (var1 &gt; 0) &#123; //生成path 将.替换成系统文件分隔符 Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar)); //创建文件夹 Files.createDirectories(var3); //具体文件 var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); &#125; else &#123; //没包就放在项目根目录下 var2 = Paths.get(var0 + \".class\"); &#125; //写入到文件中 Files.write(var2, var4, new OpenOption[0]); return null; &#125; catch (IOException var4x) &#123; throw new InternalError(\"I/O exception saving generated file: \" + var4x); &#125; &#125; &#125;); &#125; return var4;&#125; 主要的方法是通过ProxyGenerator对象生成字节数组,具体生成的步骤可以如下几步: 1231.找到所有接口的方法2.添加object类的三个方法 tostring hashcode equils3.遍历生成具体的代理方法,代理方法的逻辑都想似,回调我们的代理类 我可以通过之前展示的一个代理方法即可才想到其中的大概流程. 123456789public final void hello(String var1) throws &#123; try &#123; super.h.invoke(this, m4, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; 最主要不同的地方就是方法名,方法参数,invoke方法的参数。其他的几乎都相同。本文就不做代码上的具体介绍. 然后通过sun.misc.ProxyGenerator.saveGeneratedFiles 的值,来决定是否生成代理文件到磁盘. 如果生成,则生成包信息,类信息,然后将字节数组写入到文件中.默认情况下和在项目的根据下,创建和包名的文件夹和$proxy+i的代理文件. 缓存从我们的代码中我们可以看到WeekCache中使用多个map进行记录12345678910111213//cachekey的引用队列,于JVM关系密切详细介绍请看这篇文章http://blog.csdn.net/u012332679/article/details/57489179private final ReferenceQueue&lt;K&gt; refQueue = new ReferenceQueue&lt;&gt;(); // 最外层map,key=&gt;cacheKey,value =&gt; valueMap private final ConcurrentMap&lt;Object, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt;&gt; map = new ConcurrentHashMap&lt;&gt;(); //记录保存value的Supplier对象map private final ConcurrentMap&lt;Supplier&lt;V&gt;, Boolean&gt; reverseMap = new ConcurrentHashMap&lt;&gt;(); //key生成对象 private final BiFunction&lt;K, P, ?&gt; subKeyFactory; //value生成对象 private final BiFunction&lt;K, P, V&gt; valueFactory; map中的key是cacheKey,是一种弱应用类型的对象,reverseMap的key是cacheValue,同为一种弱应用类型的对象.两者也同时为内存回收的主要对象,当某个map中的key失效的时候,在下一次进行get,containsValue,size三个方法的时候都会触发expungeStaleEntries方法,然后将value从reverseMap中清除,valuemap从map中清除.而refQueue的回收,是由Reference中ReferenceHandler轮询去回收的.如果回收了,refQueue.poll会成功触发,然后就想清除操作.1234567891011121314151617181920private void expungeStaleEntries() &#123; CacheKey&lt;K&gt; cacheKey; while ((cacheKey = (CacheKey&lt;K&gt;)refQueue.poll()) != null) &#123; cacheKey.expungeFrom(map, reverseMap); &#125;&#125;void expungeFrom(ConcurrentMap&lt;?, ? extends ConcurrentMap&lt;?, ?&gt;&gt; map, ConcurrentMap&lt;?, Boolean&gt; reverseMap) &#123; // removing just by key is always safe here because after a CacheKey // is cleared and enqueue-ed it is only equal to itself // (see equals method)... ConcurrentMap&lt;?, ?&gt; valuesMap = map.remove(this); // remove also from reverseMap if needed if (valuesMap != null) &#123; for (Object cacheValue : valuesMap.values()) &#123; //移除弱应用CacheValue reverseMap.remove(cacheValue); &#125; &#125;&#125; valueMap是回记录真正的代理类相关信息key =&gt; subKeyFactory.apply(key, parameter) 通过classLoader和interface[]组成value=&gt; supplier=&gt;Factory 或者 CacheValue valuemap中value的两种形式1.刚创建时为factory对象2.factory.applay方法执行后会替换为CacheValue,并且将CacheValue保存到reverseMap中 小结总体的逻辑就是这样子, 通过源代码的阅读,对JDK的动态代理实现清晰很多。也从根本上对动态代理的实现过程有了更深的理解，我们此时就可以自己尝试着思考Spring AOP的具体实现。本文没有对缓存和代理生成的细节做详细分析和总结,还需要深入的研究 结语由于个人的能力有限，文章中存在错误的地方或者有宝贵的意见，欢迎大家留言评论。 之后会写Spring AOP 和 cglib动态代理的相关文章。 与君共勉！！","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"proxy","slug":"proxy","permalink":"http://www.eumji025.com/tags/proxy/"}]},{"title":"展望2018","slug":"2018-target","date":"2017-12-31T16:08:47.000Z","updated":"2018-03-02T12:38:56.831Z","comments":true,"path":"2018/01/01/2018-target/","link":"","permalink":"http://www.eumji025.com/2018/01/01/2018-target/","excerpt":"","text":"前言2017年已经成为过去，2018年已经来临，希望自己在新的一年能够得到更多的成长。同时对自己也有更多的要求，首先要形成自己的知识体系，不能总是抱着遇到什么学习什么的心态，这样总是学到的知识皮毛，一定要在某一个时间段内专注一个知识体系，如1-3月份，阅读java集合类的源码，学习更多自己没关注到的集合类和响应的数据结构。 总结2017 懵懵懂懂又一年,总的来说离目标还有一些距离. 展望2018往往都是计划赶不上变化,18年,还是把自己关键的主题方向列出来，某些具体的技术栈就随时间推荐进行学习. 概括 该做的事情还是得做 该看的书籍还是得看 该敲的代码还是得敲 该学的东西还是得学 基础目标1.go语言及简单爬虫，docker的精进。 2.JVM相关的技术还是要接着学，掌握常用的命令和参数。 3.Java常用类源码必须要看一遍，特别多线程相关的和并发包。 4.深入理解Java8的可用新特性。 5.技术类文章30篇(保质保量) 6.如果有余力，看一些Spring框架的源码。 7.沉淀自己，锻炼自己，提高自己！！！ 详情安排1月份-3月份 ： 完成Java通用类了解和源码阅读，最好都有笔记的产出，不要相信自己的记忆力。。。 4月份-6月份： 阅读《自己动手写Java虚拟机》，提高JVM的认识和go语言的学习，最好有笔记的产出。。。 7月份-9月份： 最好开源项目该动手了，已经docker技术的学习和应用。 10月份-12月份： 总结前三季度的不足和完善相关的任务。 update2018年03月02日20:37:02今年的项目是贡献代码到 数据一致性解决方法saga 总结新的一年,新的开始,也应该做一些新的尝试. 安逸的环境最致命，坚持自己的斗志，做好自己该做的事情。 前路漫漫,且行且思.","categories":[{"name":"其他","slug":"其他","permalink":"http://www.eumji025.com/categories/其他/"}],"tags":[{"name":"target","slug":"target","permalink":"http://www.eumji025.com/tags/target/"}]},{"title":"开源系统 - 博客简介篇","slug":"eumjiblog-introduce","date":"2017-06-25T05:03:44.000Z","updated":"2018-02-25T11:37:09.066Z","comments":true,"path":"2017/06/25/eumjiblog-introduce/","link":"","permalink":"http://www.eumji025.com/2017/06/25/eumjiblog-introduce/","excerpt":"","text":"前言​ 个人的第一个自主开发的开源项目，目的就是锻炼自己，因为在之前的工作中自己没能调整好状态。越发的感慨要静下心好好做点东西。四月份正式开始写本项目，之前也留意过一些相关的东西。此博客系统大部分都是在晚上或者周末抽空开发的，中间肯定存在着许多的不足和BUG，希望大家能踊跃的反馈给我。可以在issues提出以及发送邮件到eumji025@gmail.com目前代码已经托管在github，欢迎大家star和fork，也鼓励大家进行二次开发。 源码地址： https://github.com/eumji025/EumJi-blog 本站中使用了一些开源组件，在github中都有说明。 初衷​ 在做本博客之前个人使用过CSDN，hexo等一些博客，或多或少都有一些自己的想法，一直都想做自己的博客系统，无奈自己前端学的菜，给自己找了许多的借口去推辞，没有付出实际行动。 ​ 感觉自己也学习很多的时间，一直都是做一些很基础的东西，没有挑战自己的能力，更确切的说是自己太懒撒。下定决心做这个博客也是因为自己面临毕业，很多东西确实应该尝试。也是顺其自然应该进行的事情，只是取决于做一个什么样的东西。光说不练假把式这句话说的很有道理，道理谁都懂，只是能动手的人微乎其微。 ​ 在编写EumJi-blog（博客系统名称）之前，自己也在担心前端的问题，本来是打算和好朋友一起做的，只是工作上的问题大家都很忙，于是在没有办法的情况硬着头皮自己去做，其实大部分都是找的模板，各种模板拼凑而成的第一版博客。只是各种模板的兼容性不佳，导致期间也遇到了很多的困难，而且很多自己也不是很懂，于是花费了很大的精力去研究。至于为什么选择editor.md作为markdown编辑器，那是因为文档齐全，有教程简单易学。我想markdown是写博客的必备技能吧。 效果图首页展示部分 文章详情页 关于我 后端总览界面 markdown编辑器 技术栈后端 spring 服务 spring boot MVC mybatis ORM spring security 认证 redis（后续准备使用） 前端 bootstrap flavr（弹出层） hexo主题 editor.md (markdown编辑器) 部分jquery插件 thymeleaf模板 结语本篇主要简单介绍一下博客系统的基本情况，下一篇将对eumji-blog的部署和技术做总结。 与君共勉！！！ 源码地址eumji-blog源码","categories":[{"name":"开源项目","slug":"开源项目","permalink":"http://www.eumji025.com/categories/开源项目/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://www.eumji025.com/tags/blog/"}]},{"title":"spring-boot跳转页面","slug":"springboot-indexPage","date":"2017-03-26T00:04:54.000Z","updated":"2018-01-02T03:29:09.176Z","comments":true,"path":"2017/03/26/springboot-indexPage/","link":"","permalink":"http://www.eumji025.com/2017/03/26/springboot-indexPage/","excerpt":"","text":"前言 本篇博客记录spring boot如何跳转到静态首页.因为是初学的关系很多知识点都不懂,而且spring boot的项目没有webapp也没有配置文件.所以思考蛮久,经过查阅资料最终找到方法,做一次学习记录. Demo其实配置起来相对简单,只是一直没有找到配置的方法,翻看了官方文档,眼拙也没找到. 其实只需要在resources目录下新建static文件夹,并把html文件放在其中即可. 目录配置 Controller12345678@Controllerpublic class PageController &#123; @RequestMapping(\"indexPage\") public String indexPage()&#123; return \"index.html\"; &#125;&#125; 注: 在我暂时的尝试中,只能跳转一个页面,配多个也没用,可能是我自己学习的不够到位.后续学习中再做修改. 结果展示 结语与君共勉! BGM","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"http://www.eumji025.com/tags/spring-boot/"}]},{"title":"spring boot自定义端口","slug":"spring-boot-customport","date":"2017-02-26T12:19:56.000Z","updated":"2018-03-02T12:35:36.480Z","comments":true,"path":"2017/02/26/spring-boot-customport/","link":"","permalink":"http://www.eumji025.com/2017/02/26/spring-boot-customport/","excerpt":"","text":"Spring boot 自定义端口前言spring boot本身内置tomcat,我们不需要进行tomcat的配置,只需要引入tomcat的依赖即可. 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;&lt;/dependency&gt; 自定义端口1.spring boot中自定义端口需要入口类实现ConfigurableEmbeddedServletContainer接口.如下代码 1234567891011121314151617181920@RestController@EnableAutoConfigurationpublic class CustomPortController implements EmbeddedServletContainerCustomizer &#123; /** * 自定义端口 * @param container */ public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8888); &#125; @RequestMapping(\"/\") public String setPort()&#123; return \"自定义端口:8888\"; &#125; public static void main(String[] args) &#123; SpringApplication.run(CustomPortController.class,args); &#125;&#125; 2.直接自定义ConfigurableEmbeddedServletContainer.通过自己注册TomcatEmbeddedServletContainerFactory，JettyEmbeddedServletContainerFactory或UndertowEmbeddedServletContainerFactory 12345678@Beanpublic EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory factory = new TomcatEmbeddedServletContainerFactory(); factory.setPort(9000); factory.setSessionTimeout(10, TimeUnit.MINUTES); factory.addErrorPages(new ErrorPage(HttpStatus.NOT_FOUND, \"/notfound.html\"); return factory;&#125; 结语长路漫漫,与君共勉!","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"http://www.eumji025.com/tags/spring-boot/"}]},{"title":"spring boot开篇","slug":"spring-boot-helloworld","date":"2017-02-26T02:32:34.000Z","updated":"2018-03-02T12:36:05.044Z","comments":true,"path":"2017/02/26/spring-boot-helloworld/","link":"","permalink":"http://www.eumji025.com/2017/02/26/spring-boot-helloworld/","excerpt":"","text":"Spring boot介绍 Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置。通过这种方式，Spring Boot致力于在蓬勃发展的快速应用开发领域（rapid application development）成为领导者。 Spring boot 特点 创建独立的Spring应用程序 嵌入的Tomcat，无需部署WAR文件 简化Maven配置 自动配置Spring 提供生产就绪型功能，如指标，健康检查和外部配置 绝对没有代码生成和对XML没有要求配置 Spring boot第一个demo说明本文采用maven方式构建项目.(maven学习地址) 开发环境 maven intellij idea java8 (推荐java7及以上版本) 构建项目第一个项目相对简单,我们不做过多的配置,只需要简单的引入spring-boot提供默认parent就可以了. 123456789101112131415161718192021222324252627282930313233&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.springboot.demo&lt;/groupId&gt; &lt;artifactId&gt;FirstDemo&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;FirstDemo Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!--内置tomcat和springboot--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;FirstDemo&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 代码编写123456789101112@RestController@EnableAutoConfigurationpublic class HelloWorldController &#123; @RequestMapping(\"/hello\") public String helloWorld()&#123; return \"Hello world!\"; &#125; public static void main(String[] args) &#123; SpringApplication.run(HelloWorldController.class,args); &#125;&#125; 注: 1.@RestController和@RequestMapping注解是springMVC的注解,分别用来注册controller类和映射对应地址的http请求. 2.@EnableAutoConfiguration注解,Spring Boot根据添加的jar依赖自动配置spring. 3.main方法通过调用run， 将业务委托给了Spring Boot的SpringApplication类。 SpringApplication将引导我们的应用， 启动Spring， 相应地启动被自动配置的Tomcat web服务器。 启动服务12345678910111213141516171819202122232425262728293031 . ____ _ __ _ _ /\\\\ / ___&apos;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &apos;_ | &apos;_| | &apos;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &apos; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.1.RELEASE)2017-02-26 10:51:44.822 INFO 456 --- [ main] c.s.d.controller.HelloWorldController : Starting HelloWorldController on EumJi025 with PID 456 (E:\\workspace\\ideaWork\\Spring-boot\\FirstDemo\\target\\classes started by EumJi in E:\\workspace\\ideaWork\\Spring-boot)2017-02-26 10:51:44.833 INFO 456 --- [ main] c.s.d.controller.HelloWorldController : No active profile set, falling back to default profiles: default2017-02-26 10:51:44.934 INFO 456 --- [ main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9225652: startup date [Sun Feb 26 10:51:44 CST 2017]; root of context hierarchy2017-02-26 10:51:46.571 INFO 456 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)2017-02-26 10:51:46.594 INFO 456 --- [ main] o.apache.catalina.core.StandardService : Starting service Tomcat2017-02-26 10:51:46.595 INFO 456 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.5.52017-02-26 10:51:46.700 INFO 456 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2017-02-26 10:51:46.700 INFO 456 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 1768 ms2017-02-26 10:51:46.813 INFO 456 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: &apos;dispatcherServlet&apos; to [/]2017-02-26 10:51:46.817 INFO 456 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;characterEncodingFilter&apos; to: [/*]2017-02-26 10:51:46.817 INFO 456 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;hiddenHttpMethodFilter&apos; to: [/*]2017-02-26 10:51:46.817 INFO 456 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;httpPutFormContentFilter&apos; to: [/*]2017-02-26 10:51:46.817 INFO 456 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: &apos;requestContextFilter&apos; to: [/*]2017-02-26 10:51:47.044 INFO 456 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9225652: startup date [Sun Feb 26 10:51:44 CST 2017]; root of context hierarchy2017-02-26 10:51:47.099 INFO 456 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/hello]&#125;&quot; onto public java.lang.String com.springboot.demo.controller.HelloWorldController.helloWorld()2017-02-26 10:51:47.102 INFO 456 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error]&#125;&quot; onto public org.springframework.http.ResponseEntity&lt;java.util.Map&lt;java.lang.String, java.lang.Object&gt;&gt; org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)2017-02-26 10:51:47.102 INFO 456 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped &quot;&#123;[/error],produces=[text/html]&#125;&quot; onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)2017-02-26 10:51:47.128 INFO 456 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-02-26 10:51:47.128 INFO 456 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-02-26 10:51:47.163 INFO 456 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]2017-02-26 10:51:47.315 INFO 456 --- [ main] o.s.j.e.a.AnnotationMBeanExporter : Registering beans for JMX exposure on startup2017-02-26 10:51:47.373 INFO 456 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)2017-02-26 10:51:47.377 INFO 456 --- [ main] c.s.d.controller.HelloWorldController : Started HelloWorldController in 3.327 seconds (JVM running for 4.128) 测试 结语长路漫漫,与君共勉!","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"http://www.eumji025.com/tags/spring-boot/"}]},{"title":"Spring cloud笔记 - config 外部配置","slug":"springcloud-config-introduce","date":"2017-02-25T12:02:52.000Z","updated":"2018-02-25T12:12:18.868Z","comments":true,"path":"2017/02/25/springcloud-config-introduce/","link":"","permalink":"http://www.eumji025.com/2017/02/25/springcloud-config-introduce/","excerpt":"","text":"Spring cloud config介绍 原文:Spring Cloud Config provides server and client-side support for externalized configuration in a distributed system. With the Config Server you have a central place to manage external properties for applications across all environments. The concepts on both client and server map identically to the Spring Environment and PropertySource abstractions, so they fit very well with Spring applications, but can be used with any application running in any language. As an application moves through the deployment pipeline from dev to test and into production you can manage the configuration between those environments and be certain that applications have everything they need to run when they migrate. The default implementation of the server storage backend uses git so it easily supports labelled versions of configuration environments, as well as being accessible to a wide range of tooling for managing the content. It is easy to add alternative implementations and plug them in with Spring configuration. 译文:Spring Cloud Config为分布式系统中的外部配置提供服务器和客户端支持。使用Config Server，您可以在所有环境中管理应用程序的外部属性。客户端和服务器映射的概念与Spring Environment和PropertySource抽象相同，因此它们与Spring应用程序非常契合，但可以与任何以任何语言运行的应用程序一起使用。随着应用程序通过从开发人员到测试和生产的部署流程，您可以管理这些环境之间的配置，并确定应用程序具有迁移时需要运行的一切。服务器存储后端的默认实现使用git，因此它轻松支持标签版本的配置环境，以及可用于管理内容的各种工具。可以轻松添加替代实现，并使用Spring配置将其插入。 简单说两句对于官网给的第一个Demo也是煞费苦心，刚看到第一句话的时候我是崩溃的,具体如下: Start the server:12$ cd spring-cloud-config-server$ ../mvnw spring-boot：run The server is a Spring Boot application so you can run it from your IDE instead if you prefer (the main class is ConfigServerApplication). Then try out a client: 12345$ curl localhost:8888/foo/development&#123;\"name\":\"development\",\"label\":\"master\",\"propertySources\":[ &#123;\"name\":\"https://github.com/scratches/config-repo/foo-development.properties\",\"source\":&#123;\"bar\":\"spam\"&#125;&#125;, &#123;\"name\":\"https://github.com/scratches/config-repo/foo.properties\",\"source\":&#123;\"foo\":\"bar\"&#125;&#125;]&#125; demo上来就直接就是运行步骤,很容易让人翻车,下面我就按照自己的流程简单介绍一下spring cloud config的第一个demo config案例流程从上面官网的介绍也可以看处,spring cloud config是为分布式系统提供外部配置,通过配置一个config server作为中间载体,去加载外部属性,这些外部属性可以放在git,svn等服务器上,spring cloud默认是使用git作为属性存储. 外部属性配置首先将我们的外部属性配置到git服务器上,具体操作流程如下,相信使用过git的朋友都很熟悉. 1234567mkdir config-repositorycd config-repositorygit initvim foo-development.propertiesgit add foo-development.propertiesgit commit -m &quot;add foo-development.properties&quot;git push origin master 注意: 使用vim foo-development.properties命令后添加如下内容,或者也可以不用命令直接自己新建文件,然后在把下面的内容放在文件中.12bar: spamfoo: from foo development 外部配置已经创建完毕.如果你你只是自己测试一下,也可以不使用git的方式, 设置这个属性使用 file:前缀,Config Server 是从本地配置库中取数据,这种方式可以不使用Git的情况下,快速和简单的运行起来 config-server配置首先使用idea或者eclipse创建一个名为config-server的maven项目,使用idea的spring initializr可以配一步到位.配置时候勾选中cloud config 的config server即可.eclipse则可以使用spring STS插件. pom.xml在pom文件中追加如下配置.说明一下,本文中使用的都是最新版的spring boot和spring cloud1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Dalston.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; SpringCloudConfigServerApplication.javaserver端可以使用@EnableConfigServer注释轻松嵌入到Spring boot应用程序中。12345678@SpringBootApplication@EnableConfigServerpublic class SpringCloudConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigServerApplication.class, args); &#125;&#125; application.yml跟所有Spring Boot应用程序一样，它默认在端口8080上运行，而默认客户端请求的是8888端口,我们可以通过各种方式将其切换到常规端口8888。关于端口的几种方式可参加我前面写的文章spring boot自定义端口然后我们需要在server端配置加载外部配置的git路径.具体如下所示.12345678910#访问外部配置的git路径spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo#自定义端口server: port: 8888 config-client配置基本类似这里不做过多的描述,直接上代码. pom文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Dalston.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; SpringCloudConfigClientApplication.java1234567891011public class SpringCloudConfigClientApplication &#123; @RequestMapping(\"/\") public String home() &#123; return \"Hello World!\"; &#125; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigClientApplication.class, args); &#125;&#125; application.yml这里主要是指明要加载的外部文件和环境.12345spring: application: name: foo profiles: active: development ###运行服务 1.启动server服务 2.启动client服务 ###结果 在开启client之后,可以在log中国看到如下类似的信息123Fetching config from server at: http://localhost:88882017-04-30 10:53:42.637 INFO 12948 --- [ restartedMain] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=foo, profiles=[development], label=null, version=null, state=null2017-04-30 10:53:42.638 INFO 12948 --- [ restartedMain] b.c.PropertySourceBootstrapConfiguration : Located property source: CompositePropertySource [name='configService', propertySources=[MapPropertySource [name='https://github.com/spring-cloud-samples/config-repo/foo-development.properties']] 或者直接在浏览器输入 localhost:8888/foo/development 此处的地址和我们client的配置是有关联的,他决定了server去加载什么外部配置.具体介绍如下 1234567#请求路径 label是可选的/ &#123;application&#125; / &#123;profile&#125; [/ &#123;label&#125;]#资源路径/&#123;application&#125;-&#123;profile&#125;.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties ##结语 我相信经过上面的例子,再去看官网的文档,思路应该清晰很多了. 与君共勉!!!! ###参考资料spring-cloud文档 ###源码地址config-clientconfig-server","categories":[{"name":"Spring cloud 专栏","slug":"Spring-cloud-专栏","permalink":"http://www.eumji025.com/categories/Spring-cloud-专栏/"}],"tags":[{"name":"spring-cloud config","slug":"spring-cloud-config","permalink":"http://www.eumji025.com/tags/spring-cloud-config/"}]},{"title":"checksty配置","slug":"checkstyle","date":"2017-01-18T14:39:13.000Z","updated":"2018-02-16T03:43:20.801Z","comments":true,"path":"2017/01/18/checkstyle/","link":"","permalink":"http://www.eumji025.com/2017/01/18/checkstyle/","excerpt":"","text":"配置文件由于checkstyle默认是使用google的开发规范,相对来说比较严格,因此采用自定义的规范.本文的配置文件来源于网络,后续将会进行改动. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE module PUBLIC \"-//Puppy Crawl//DTD Check Configuration 1.2//EN\" \"http://www.puppycrawl.com/dtds/configuration_1_2.dtd\"&gt;&lt;module name=\"Checker\"&gt; &lt;!-- 消息提示等级 --&gt; &lt;property name=\"severity\" value=\"warning\"/&gt; &lt;!-- 字符集限制 --&gt; &lt;property name=\"charset\" value=\"UTF-8\"/&gt; &lt;module name=\"TreeWalker\"&gt; &lt;!-- javadoc的检查 --&gt; &lt;!-- 检查所有的interface和class --&gt; &lt;module name=\"JavadocType\"/&gt; &lt;!-- 检查所有方法的javadoc，可以不声明RuntimeException --&gt; &lt;module name=\"JavadocMethod\"&gt; &lt;property name=\"allowUndeclaredRTE\" value=\"true\"/&gt; &lt;property name=\"allowMissingPropertyJavadoc\" value=\"true\"/&gt; &lt;/module&gt; &lt;!-- 检查变量的javadoc --&gt; &lt;module name=\"JavadocVariable\"&gt; &lt;property name=\"scope\" value=\"public\"/&gt; &lt;/module&gt; &lt;!-- 命名方面的检查，它们都使用了Sun官方定的规则。 --&gt; &lt;!-- 类名(class 或interface) 的检查 --&gt; &lt;module name=\"TypeName\"/&gt; &lt;!-- 变量的检查 --&gt; &lt;module name=\"MemberName\"/&gt; &lt;!-- 方法名的检查 --&gt; &lt;module name=\"MethodName\"/&gt; &lt;!-- 方法的参数名 --&gt; &lt;module name=\"ParameterName \"/&gt; &lt;!-- 常量名的检查 --&gt; &lt;module name=\"ConstantName\"/&gt; &lt;!-- 长度方面的检查 --&gt; &lt;!-- 文件长度不超过1500行 --&gt; &lt;!-- 每行不超过120个字--&gt; &lt;module name=\"LineLength\"&gt; &lt;property name=\"max\" value=\"120\"/&gt; &lt;/module&gt; &lt;!-- 方法不超过30行 --&gt; &lt;module name=\"MethodLength\"&gt; &lt;property name=\"tokens\" value=\"METHOD_DEF\"/&gt; &lt;property name=\"max\" value=\"30\"/&gt; &lt;/module&gt; &lt;!-- 方法的参数个数不超过3个。 --&gt; &lt;module name=\"ParameterNumber\"&gt; &lt;property name=\"max\" value=\"3\"/&gt; &lt;/module&gt; &lt;!-- 多余的关键字 --&gt; &lt;module name=\"RedundantModifier\"/&gt; &lt;!-- 对区域的检查 --&gt; &lt;!-- 不能出现空白区域 --&gt; &lt;module name=\"EmptyBlock\"/&gt; &lt;!-- 所有区域都要使用大括号。 --&gt; &lt;module name=\"NeedBraces\"/&gt; &lt;!-- 多余的括号 --&gt; &lt;module name=\"AvoidNestedBlocks\"&gt; &lt;property name= \"allowInSwitchCase\" value=\"true\"/&gt; &lt;/module&gt; &lt;!-- 编码方面的检查 --&gt; &lt;!-- 不许出现空语句 --&gt; &lt;module name=\"EmptyStatement\"/&gt; &lt;!-- 每个类都实现了equals()和hashCode() --&gt; &lt;module name=\"EqualsHashCode\"/&gt; &lt;!-- 不许使用switch --&gt; &lt;module name=\"IllegalToken\"&gt; &lt;property name=\"tokens\" value=\"LITERAL_SWITCH\"/&gt; &lt;/module&gt; &lt;!-- 不许内部赋值 --&gt; &lt;module name=\"InnerAssignment\"/&gt; &lt;!-- 绝对不能容忍魔法数 --&gt; &lt;module name=\"MagicNumber\"/&gt; &lt;!-- 循环控制变量不能被修改 --&gt; &lt;module name=\"ModifiedControlVariable\"/&gt; &lt;!-- 多余的throw --&gt; &lt;!-- &lt;module name=\"RedundantThrows\"/&gt; --&gt; &lt;!-- 不许使用未被简化的条件表达式 --&gt; &lt;module name=\"SimplifyBooleanExpression\"/&gt; &lt;!-- 不许使用未被简化的布尔返回值 --&gt; &lt;module name=\"SimplifyBooleanReturn\"/&gt; &lt;!-- String的比较不能用!= 和 == --&gt; &lt;module name=\"StringLiteralEquality\"/&gt; &lt;!-- if最多嵌套3层 --&gt; &lt;module name=\"NestedIfDepth\"&gt; &lt;property name=\"max\" value=\"3\"/&gt; &lt;/module&gt; &lt;!-- try最多被嵌套1层 --&gt; &lt;module name=\"NestedTryDepth\"/&gt; &lt;!-- clone方法必须调用了super.clone() --&gt; &lt;module name=\"SuperClone\"/&gt; &lt;!-- finalize 必须调用了super.finalize() --&gt; &lt;module name=\"SuperFinalize\"/&gt; &lt;!-- 不能catch java.lang.Exception --&gt; &lt;module name=\"IllegalCatch\"&gt; &lt;property name=\"illegalClassNames\" value=\"java.lang.Exception\"/&gt; &lt;/module&gt; &lt;!-- JUnitTestCase 的核心方法存在。 --&gt; &lt;!-- &lt;module name=\"JUnitTestCase\"/&gt; --&gt; &lt;!-- 一个方法中最多有3个return --&gt; &lt;module name=\"ReturnCount\"&gt; &lt;property name=\"max\" value=\"3\"/&gt; &lt;/module&gt; &lt;!-- 不许对方法的参数赋值 --&gt; &lt;module name=\"ParameterAssignment\"/&gt; &lt;!-- 不许有同样内容的String --&gt; &lt;module name=\"MultipleStringLiterals\"/&gt; &lt;!-- 同一行不能有多个声明 --&gt; &lt;module name=\"MultipleVariableDeclarations\"/&gt; &lt;!-- 各种量度 --&gt; &lt;!-- 布尔表达式的复杂度，不超过3 --&gt; &lt;module name=\"BooleanExpressionComplexity\"/&gt; &lt;!-- 类数据的抽象耦合，不超过7 --&gt; &lt;module name=\"ClassDataAbstractionCoupling\"/&gt; &lt;!-- 类的分散复杂度，不超过20 --&gt; &lt;module name=\"ClassFanOutComplexity\"/&gt; &lt;!-- 函数的分支复杂度，不超过10 --&gt; &lt;module name=\"CyclomaticComplexity\"/&gt; &lt;!-- NPath复杂度，不超过200 --&gt; &lt;module name=\"NPathComplexity\"/&gt; &lt;!-- 杂项 --&gt; &lt;!-- 禁止使用System.out.println --&gt; &lt;!-- &lt;module name=\"GenericIllegalRegexp\"&gt; &lt;property name=\"format\" value=\"System\\.out\\.println\"/&gt; &lt;property name=\"ignoreComments\" value=\"true\"/&gt; &lt;/module&gt; --&gt; &lt;!-- 不许使用与代码同行的注释 --&gt; &lt;module name=\"TrailingComment\"/&gt; &lt;!-- 不允许存在todo标签 --&gt; &lt;module name=\"TodoComment\"&gt; &lt;property name=\"severity\" value=\"warning\"/&gt; &lt;property name=\"format\" value=\"TODO\"/&gt; &lt;/module&gt; &lt;/module&gt; &lt;module name=\"FileLength\"&gt; &lt;property name=\"max\" value=\"1500\"/&gt; &lt;/module&gt; &lt;!-- 检查翻译文件 --&gt; &lt;module name=\"Translation\"/&gt;&lt;/module&gt; 注未完待续","categories":[{"name":"工具专栏","slug":"工具专栏","permalink":"http://www.eumji025.com/categories/工具专栏/"}],"tags":[{"name":"tools","slug":"tools","permalink":"http://www.eumji025.com/tags/tools/"}]},{"title":"web开发常用注解","slug":"annotation","date":"2017-01-11T15:14:31.000Z","updated":"2018-02-16T03:43:21.573Z","comments":true,"path":"2017/01/11/annotation/","link":"","permalink":"http://www.eumji025.com/2017/01/11/annotation/","excerpt":"","text":"简介概念 Annotation(注解)是JDK1.5及以后版本引入的。它可以用于创建文档，跟踪代码中的依赖性，甚至执行基本编译时检查。注解是以‘@注解名’在代码中存在的，根据注解参数的个数，我们可以将注解分为：标记注解、单值注解、完整注解三类。它们都不会直接影响到程序的语义，只是作为注解（标识）存在，我们可以通过反射机制编程实现对这些元数据（用来描述数据的数据）的访问。另外，你可以在编译时选择代码里的注解是否只存在于源代码级，或者它也能在class文件、或者运行时中出现（SOURCE/CLASS/RUNTIME）。 分类①编写文档：通过代码里标识的元数据生成文档【生成文档doc文档】 ② 代码分析：通过代码里标识的元数据对代码进行分析【使用反射】 ③编译检查：通过代码里标识的元数据让编译器能够实现基本的编译检查【Override】 WEB开发中常用的注解Spring篇@Controller@Controller 定义控制器，映射页面URL的请求,只有被@Controller声明的类才会到对应类下找到对应@Requestmapping配置的URL 开启扫描@Controller注解需要在spring-mvc.xml中配置 1234&lt;!-- 扫描web相关的Bean 使用Annotation自动注册Bean,只扫描@Controller --&gt; &lt;context:component-scan base-package=\"com.jsu.controller\" use-default-filters=\"false\"&gt;&lt;!-- base-package 如果多个，用“,”分隔 --&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;!-- 子标签是用来添加扫描注解的 --&gt; &lt;/context:component-scan&gt; 简化配置版 1&lt;context:component-scan base-package=\"com.jsu.controller\"/&gt; ### @RequestMapping @RequestMapping 注解将类似 “/index”这样的URL映射到整个类或特定的处理方法上。类级别的注解映射特定的请求路径到表单控制器上，而方法级别的注解只是映射为一个特定的HTTP方法请求（“GET”，“POST”等）或HTTP请求参数。简而言之,公共的请求路径使用@RequestMapping放在类声明上,而特有的请求放在方法上,如下例: 12345678910111213141516@RequestMapping(\"/perm/permission\")public class PermissionController extends BaseController &#123; @Autowired private IPermissionService permissionService; @RequestMapping(\"/list\") public String list(Model model) &#123; return \"/permission/list\"; &#125; @RequestMapping(\"/getPermissionList\") @ResponseBody public String getPermissionList() &#123; Page&lt;Permission&gt; page = getPage(); return jsonPage(permissionService.selectPage(page, null)); &#125;&#125; 补充:随着Spring的发展,在@RequestMapping的注解基础之上又发展了几个新的类似注解: @GetMapping =&gt; get方式的请求表示;@PustMapping =&gt; post方式的请求;@DeleteMapping =&gt; delete方式的请求;@PutMapping =&gt; put方式的请求;@PatchMapping =&gt; patch方式的请求. @PathVariableURI 模版是一个类似于 URI 的字符串，其中包含了一个或多个变量。当你将这些变量替换掉市，就变回了 URI。 URI 模版格式 proposed RFC 定义了如何参数化 URI。比如，URI 模版 http://www.example.com/users/{userId}，包含了变量 userId，设置此变量为 __fred，就会变成http://www.example.com/users/fred。 可在方法入参上使用注解 @PathVariable 绑定 URI 的模版参数: 123456@RequestMapping(value=\"/owners/&#123;ownerId&#125;\", method=RequestMethod.GET)public String findOwner(@PathVariable String ownerId, Model model) &#123; Owner owner = ownerService.findOwner(ownerId); model.addAttribute(\"owner\", owner); return \"displayOwner\";&#125; @PathVariable 参数可以是任意的简单类型（如 int，long，Date 等），Spring 会自动将其进行类型转换，转换出错会抛出 TypeMismatchException. @RequestBody常用语接受前台请求的json格式数据,可以转化成对象接受. 12345@Controller@RequestMapping(value = \"/pets\", method = RequestMethod.POST, consumes=\"application/json\")public void addPet(@RequestBody Pet pet, Model model) &#123; // 实现省略&#125; @ResponseBody@ResponseBody 的使用类似于 @RequestBody。此注解用在方法上，用来表示直接将返回数据写到 HTTP 响应体里。注意，不是将数据放到 Model 中，或解析为视图名称。如下例: 12345@RequestMapping(value = \"/something\", method = RequestMethod.PUT)@ResponseBodypublic String helloWorld() &#123; return \"Hello World\";&#125; 常用于ajax请求. Bean相关@Service,@Controller,@Repository,@Component@Service =&gt; 通常用于服务层声明Bean@Controller =&gt; 通常用于控制层声明Bean@Repository =&gt; 用于持久层声明Bean(是JPA的注解)@Component =&gt; 声明通用Bean,也就是当你无法把一个Bean合理归类到上述三种情况时,使用此注解. @Bean@Bean是一种代替xml声明Bean的方式,具体如下所示:1234@Beanpublic HelloServiceImpl transferService()&#123; return new HelloServiceImpl();&#125; 上述描述就等同于如下的xml123&lt;beans&gt; &lt;bean id=\"helloServiceImpl\" class=\"com.eumji.HelloServiceImpl\"/&gt;&lt;/beans&gt; 因为Spring4之后,鼓励大家使用注解的方式去声明一些Bean. 详情请参考spring官方文档-bean @Autowire@Autowire是spring官方提供的一种装配方式。(默认byType) ＠Resource＠Resource是java自带的一种装配方式。默认按名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行名称查找。 ## @Qualifier正因为＠Autowired注解使用的byType方式进行注入的,所以当如果一个Service有多个实现类的时候,就会出现不知所措的局面,因此@Qualifier的主要目的就是指定Bean的名称. 所以选择使用那种注解,需要自己去权衡. JPA实体类注解### @Entity 标注于实体类上，通常和@Table是结合使用的，代表是该类是实体类 @Table标注在实体类上,表示该实体类对应数据库中的一张表 @Id 标注于属性上，通常是在get方法上，也可以在属性的声明上。用于表示该属性作为ID主键. @GeneratedValue12345678910//源码@Target(&#123;METHOD, FIELD&#125;)@Retention(RUNTIME)public @interface GeneratedValue &#123; GenerationType strategy() default AUTO; //默认是AUTO String generator() default \"\";&#125; 12345678910111213141516171819202122public enum GenerationType &#123; /** * 自增长 */ TABLE, /** * 通过序列 */ SEQUENCE, /** * 由数据库维护 */ IDENTITY, /** * 自动选择合适的方案分配 */ AUTO&#125; 即主键生成策略,通常和@Id配合使用. @Column标注于属性上，有很多功能，例如指定长度、是否为空，列名以及对应到数据库汇中的类型等,具体如下源码所示 12345678910111213141516@Target(&#123;METHOD, FIELD&#125;)@Retention(RUNTIME)public @interface Column &#123; //设置对应数据库名 String name() default \"\"; //是否唯一 boolean unique() default false; //是否可以为空 boolean nullable() default true; //是否可以掺入 boolean insertable() default true; //设置长度 int precision() default 0; //精度 int scale() default 0;&#125; @OrderBy设置排序.ASC和DESC.默认ASC 12345@Target(&#123;METHOD, FIELD&#125;)@Retention(RUNTIME)public @interface OrderBy &#123; String value() default \"\";&#125; ### @ManyToMany&amp;&amp;@OneToMany 设置对应关系,多对多,一对多 @DateTimeFormat格式化时间,放在属性上 1234567891011121314151617181920@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD, ElementType.FIELD, ElementType.PARAMETER, ElementType.ANNOTATION_TYPE&#125;)public @interface DateTimeFormat &#123; String style() default \"SS\"; DateTimeFormat.ISO iso() default DateTimeFormat.ISO.NONE; String pattern() default \"\"; public static enum ISO &#123; DATE, //日期 TIME, //时间 DATE_TIME, //时间+日期 NONE; //无 private ISO() &#123; &#125; &#125;&#125; ## Jackson注解 JsonProperty设置某个属性在转成json后的名称 1234public class Name &#123; @JsonProperty(\"sex\") public String t_sex;&#125; 转化成json格式后是这样的: 将会生成如下所示的JSON数据结果：{ “sex” : “man” } @JsonIgnoreProperties此注解是类注解，作用是json序列化时将Java bean中的一些属性忽略掉，序列化和反序列化都受影响. @JsonIgnore 此注解用于属性或者方法上（最好是属性上），作用和上面的@JsonIgnoreProperties一样。示例: 12345public class KeyValue &#123; public int value; @JsonIgnore public int key;&#125; 12转成json字符串后://将会忽略key&#123; &quot;value&quot; : 42 &#125; @JsonFormat此注解用于属性或者方法上（最好是属性上），可以方便的把Date类型直接转化为我们想要的模式，比如@JsonFormat(pattern = “yyyy-MM-dd HH-mm-ss”) @JsonSerialize 此注解用于属性或者getter方法上，用于在序列化时嵌入我们自定义的代码. @JsonDeserialize 此注解用于属性或者setter方法上，用于在反序列化时可以嵌入我们自定义的代码. Mybatis注解### @Alias ＠Alias是mybatis中一个注解,类型别名是为 Java 类型设置一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余。xml中通常这样配置. 1234&lt;typeAliases&gt; &lt;typeAlias alias=\"Author\" type=\"com.eumji025.vo.Author\"/&gt; &lt;typeAlias alias=\"Blog\" type=\"com.eumji025.vo.Blog\"/&gt;&lt;/typeAliases&gt; 也可以在xml中直接指定包名如下: 123&lt;typeAliases&gt; &lt;package name=\"com.eumji025.vo\"/&gt;&lt;/typeAliases&gt; 每一个在包 com.eumji025.vo 中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名。比如 com.eumji025.vo.Author 的别名为 author 如通过注解已经设置别名则按照注解的别名来使用: 1234@Alias(\"author\")public class Author &#123; ...&#125; 当然mybatis为了使用方便,已经为许多常见的 Java 类型内建了相应的类型别名。它们都是大小写不敏感的，需要注意的是由基本类型名称重复导致的特殊处理。具体如下: 别名 映射的类型 _byte byte _long long _short short _int int _integer int _double double _float float _boolean boolean string String byte Byte long Long short Short int Integer integer Integer double Double float Float boolean Boolean date Date decimal BigDecimal bigdecimal BigDecimal object Object map Map hashmap HashMap list List arraylist ArrayList collection Collection iterator Iterator 注后续继续补充","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://www.eumji025.com/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.eumji025.com/tags/java/"}]},{"title":"Idea-Maven项目的创建和部署","slug":"Idea-Maven项目的创建和部署","date":"2016-11-21T12:12:40.000Z","updated":"2018-02-16T03:43:17.745Z","comments":true,"path":"2016/11/21/Idea-Maven项目的创建和部署/","link":"","permalink":"http://www.eumji025.com/2016/11/21/Idea-Maven项目的创建和部署/","excerpt":"","text":"前言由于Intellij Idea创建项目方式和eclipse有一定的区别，所有maven项目也是一样。 目的学会使用idea创建和部署Maven项目。 过程创建空的项目 创建maven module1.点击+号创建 2.选择maven webapp 3输入groupId和ArtifactId 4.陪著maven相关信息。 5设置名字 完成。6.等待一段时间，maven自动加载web项目相关的配置7 修改pom文件 注意添加packaging 8 修改项目配置 提示maven-tomcat插件配置 发布 右键项目 run maven-maven-tomcat即可 结语 与君共勉！","categories":[{"name":"工具专栏","slug":"工具专栏","permalink":"http://www.eumji025.com/categories/工具专栏/"}],"tags":[{"name":"Intellij Idea","slug":"Intellij-Idea","permalink":"http://www.eumji025.com/tags/Intellij-Idea/"}]},{"title":"推荐的markdown编辑器","slug":"推荐的markdown编辑器","date":"2016-11-05T01:26:54.000Z","updated":"2018-02-16T03:43:22.801Z","comments":true,"path":"2016/11/05/推荐的markdown编辑器/","link":"","permalink":"http://www.eumji025.com/2016/11/05/推荐的markdown编辑器/","excerpt":"","text":"介绍Typora是一款非常优雅的markdown编辑器 因为它将「写字」和「预览」合并，你输入的地方，也是输出的地方，即现在很流行的 WYSIWYG（What You See Is What You Get）。其实转念一想，这不就是回到了 Office Word 嘛，只不过编辑文本时不用再去工具栏上点选，一切的格式都能通过符号来控制。 用 Typora 官方的介绍视频，你就懂这一切是多么的自然。没错，所有的行内元素（如加粗、斜体）都会根据当前是否在编辑态而智能地在编辑态和预览态切换，而区块级元素（如标题、列表）则会在按下 Enter 后即时渲染，不能再次编辑。 一切都变得如此干净、纯粹。 官网 传送门： hexo官网 安装windows 下载地址 安装没有难度 linux sudo apt-key adv –keyserver keyserver.ubuntu.com –recv-keys BA300B7755AFCFAE sudo add-apt-repository ‘deb https://typora.io ./linux/‘ sudo apt-get update sudo apt-get install typora mac 解压安装 功能介绍表格编辑其他的markdown表格编辑方式 12345| Left-Aligned | Center Aligned | Right Aligned || :------------ |:---------------:| -----:|| col 3 is | some wordy text | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 十分复杂的操作有木有 Typora表格操作方式 CTRL+T快捷键直接生成 图片操作插入图片的语法 1![logo](http://typora.io/img/favicon-128.png) typora语法 CTRL+SHIFT+I 更简单的直接将图片拖拽进来即可。 目录大纲 Typora 还可以根据当前文档的标题层级，自动生成显示大纲， 点击软件左下角圆圈即可，就会出现字数统计和大纲预览。 圆圈旁边是切换视图按钮。 主题 ypora 默认提供了六套主题样式： Github风格、 默认主题 Gothic、 出版风格的 Newsprint、 夜间模式 Night、 Pixyll、 Whitey. 结语与君共勉！！！","categories":[{"name":"工具专栏","slug":"工具专栏","permalink":"http://www.eumji025.com/categories/工具专栏/"}],"tags":[{"name":"写作","slug":"写作","permalink":"http://www.eumji025.com/tags/写作/"}]},{"title":"springMVC 几种页面跳转方式","slug":"springMVC-几种页面跳转方式","date":"2016-10-28T04:45:00.000Z","updated":"2018-01-02T03:29:09.176Z","comments":true,"path":"2016/10/28/springMVC-几种页面跳转方式/","link":"","permalink":"http://www.eumji025.com/2016/10/28/springMVC-几种页面跳转方式/","excerpt":"","text":"前言前面已经了解了Controller的几种配置方式今天主要写一下响应界面跳转的几种方式 在注解的方式中通过HttpServletResponse的API直接输出（不需要配置渲染器）controller类的主要代码 12345678@Controllerpublic class RequestController&#123; @RequestMapping(\"/resp\") public void handleRequest(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; resp.getWriter().println(\"hello HttpServletResponse\"); &#125; web.xml配置 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\"&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; dispatcher-servlet.xml主要代码 12345678910111213&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd\"&gt; &lt;!--作用是扫描指定包下所有的包含注解的类--&gt; &lt;context:component-scan base-package=\"com.jsu.mvc\"/&gt;&lt;/beans&gt; 使用HttpServletResponse 重定向到另一个视图(其他不变 )1234567 @RequestMapping(\"/resp\") public void handleRequest(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; resp.sendRedirect(\"index.jsp\"); &#125;&#125; 使用HttpServletRequest 转发（默认访问/下的index.jsp页面 不受渲染器的影响）12345@RequestMapping(\"/resp\") public void handleRequest(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123; req.setAttribute(\"message\",\"it's forword \"); req.getRequestDispatcher(\"index.jsp\").forward(req,resp); &#125; 直接返回jsp页面的名称（无渲染器）其他的配置不变 123456789@RequestMapping(\"/nice\") public String hello1()&#123;//转发方式1 return \"home.jsp\"; //转发方式2 return \"forward:index.jsp\"; //重定向方式 return \"redirect:index.jsp\"; &#125; 当有渲染器指定123456789@RequestMapping(\"/nice\") public String hello1()&#123; //转发方式1 return \"home\"; //转发方式2 return \"forward:index\"; //重定向方式 hello指的是requsrmapping return \"redirect:hello\"; &#125; 使用view使用modelandview需要视图解析器 能指定跳转页面 12345678910111213141516public class HelloController implements Controller &#123; @Override public ModelAndView handleRequest(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception &#123; ModelAndView mv = new ModelAndView(); //封装要显示到视图的数据 mv.addObject(\"msg\",\"hello myfirst mvc\"); //视图名 mv.setViewName(\"hello\"); return mv; &#125;&#125; [servlet-name]-servlet.xml 12345678910111213&lt;!--配置渲染器--&gt; &lt;!--配置hellocontroller中页面的位置--&gt; &lt;bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\" /&gt; &lt;bean id=\"viewResolver\" class=\"org.springframework.web.servlet.view.UrlBasedViewResolver\"&gt; &lt;property name=\"viewClass\" value=\"org.springframework.web.servlet.view.JstlView\"/&gt; &lt;!--结果视图的前缀--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\"/&gt; &lt;!--结果视图的后缀--&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt;&lt;/bean&gt; &lt;bean name=\"/hello.do\" class=\"com.jsu.mvc.HelloController\"&gt;&lt;/bean&gt; 使用modelview不需要视图解析器 不能指定跳转页面 12345678//通过modelmap方式 @RequestMapping(\"/modelmap\") public String modelHello(String name,ModelMap map)&#123; map.addAttribute(\"name\",name); System.out.println(name); return \"index.jsp\"; &#125; 结语与君共勉！","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://www.eumji025.com/tags/Spring-MVC/"}]},{"title":"使用idea开发srpingMVC第一个Demo","slug":"使用idea开发srpingMVC第一个Demo","date":"2016-10-28T04:24:48.000Z","updated":"2018-02-16T03:43:23.429Z","comments":true,"path":"2016/10/28/使用idea开发srpingMVC第一个Demo/","link":"","permalink":"http://www.eumji025.com/2016/10/28/使用idea开发srpingMVC第一个Demo/","excerpt":"","text":"主要目的是熟悉intellij的web项目操作和springMVC的基本概念,纯属个人学习的笔记,有写的不当的地方欢迎指正 ###操作环境说明操作系统： win10ide版本： 2017.1.5 开发过程本文原始的版本是在个人学习写的，所以很多东西写的不够详细。本次重新归纳总结，下面开始具体操作： 创建项目创建一个empty projectFile -&gt; new -&gt; project -&gt; empty project ###创建module说明一下，在实际开发中我们喜欢一个项目一个project，但是学习之中，为了方便来回切换，所以我们每一个demo都写成module的形式。 创建 module(在此之前需要创建entity project)在新版本中，会提示你是下载勾选的mvc的依赖。 然后填写module名 点击确认 module创建完毕（作者因为乱码的关系 ￥代表 /） 结构预览并修改配置在module的web-WEB-INF下新建 classes和lib文件夹（新版本中的lib在根目录下） 1.IDEA默认是不会像eclipse那样在web-inf下生成lib文件夹和classes文件夹的的，需要我们手动的创建，并将我们根目录下的lib目录下的内容复制到web-inf/lib文件夹内。并且还需要进行额外配置。 点击file-&gt;Project Struture 修改Modules下的paths 修改完毕点击OK（主要是为了跟ecilpse结构相似，也可以不改） 2.然后点击dependencis - &gt; 绿色的+ -&gt; 选择第一项，选择刚才我们在WEB-INF下创建的lib文件夹，和eclipse的导包一个性质。 3.回到主界面，配置tomcat 点击run-&gt;edit configurations‘点绿色的十字图标 创建tomcat并配置 选择自己的tomcat位置点击deployment -&gt; 绿色+号 -&gt; 选择我们的项目 代码编写 web,xml 不需要进行修改，有默认的就行了。 修改dispatcjer-servlet.xml 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd\"&gt; &lt;!--对应src下的报名，需要自己新建--&gt; &lt;context:component-scan base-package=\"com.eumji.mvc\" /&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\"&gt; &lt;!-- 这个配置是配置JSP页面的位置，按照你自己的配置来配 --&gt; &lt;!--jsp文件夹需要自己手动创建--&gt; &lt;value&gt;/WEB-INF/jsp/&lt;/value&gt; &lt;/property&gt; &lt;property name=\"suffix\"&gt; &lt;value&gt;.jsp&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 3.在jsp目录下新建hello.jsp123456789&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;hello mvc&lt;/title&gt;&lt;/head&gt;&lt;body&gt;$&#123;msg &#125;&lt;/body&gt;&lt;/html&gt; 4.在src中编写controller类需要和dispatcher-servlet.xml配置的路径一致12345678@Controllerpublic class HelloController &#123; @RequestMapping(value=&quot;/hello&quot;,method = RequestMethod.GET) public String printWelcome(ModelMap model) &#123; model.addAttribute(&quot;msg&quot;, &quot;Spring 3 MVC Hello World&quot;); return &quot;hello&quot;; &#125;&#125; 5.点击右上角的绿色三角形进行运行，最后进行测试 第一个小demo到此结束！ 最后说几句Intellij IDEA和eclipse的使用有很大的不同，本文只是带领着使用IDEA进行web项目的创建和测试。并没有对spring MVC框架本身的内容进行过多的讲解。IDEA创建普通的web 项目确实比较麻烦，使用maven的方式更佳。 补充还是补充一下创建maven项目的姿势 创建maven module 1.点击+号创建 2.选择maven webapp3输入groupId和ArtifactId4.陪著maven相关信息。最好是设置一下maven的setting文件,无论是自带的还是自己配置的maven,修改一下maven的镜像地址.在maven的settings.xml 文件里配置mirrors的子节点，添加如下mirror &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; 5.文件夹名称,创建完成.6.加载 等待一段时间，maven自动加载web项目相关的配置 7 .修改pom文件注意添加packaging8 修改项目配置 maven-tomcat插件配置 发布右键项目 run maven-maven-tomcat即可 spring boot特别推荐一下使用spring boot,对新手非常友好,而且可以使用spring initialize生成项目,并且不需要配置tomcat. 源码地址https://github.com/eumji025/my-demo/tree/master/hello-mvc","categories":[{"name":"Spring专栏","slug":"Spring专栏","permalink":"http://www.eumji025.com/categories/Spring专栏/"}],"tags":[{"name":"Intellij Idea","slug":"Intellij-Idea","permalink":"http://www.eumji025.com/tags/Intellij-Idea/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"http://www.eumji025.com/tags/Spring-MVC/"}]}]}